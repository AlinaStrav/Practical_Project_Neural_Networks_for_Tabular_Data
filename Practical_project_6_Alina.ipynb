{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlinaStrav/Practical_Project_Neural_Networks_for_Tabular_Data/blob/main/Practical_project_6_Alina.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJEZ7AiW4Gt2",
        "outputId": "e7aaa361-63b1-4095-df7e-aa56dc723a40"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(404, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from keras import models\n",
        "from keras import layers\n",
        "import numpy as np\n",
        "from keras.datasets import boston_housing\n",
        "\n",
        "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()\n",
        "\n",
        "mean = train_data.mean(axis=0)\n",
        "train_data -= mean\n",
        "std = train_data.std(axis=0)\n",
        "train_data /= std\n",
        "\n",
        "test_data -= mean\n",
        "test_data /= std\n",
        "\n",
        "train_data.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwghYcUvgEbY",
        "outputId": "1ee918bf-a2ba-4296-e9e7-933e0995ed58"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "train_data.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRRorDzogOUp"
      },
      "outputs": [],
      "source": [
        "def build_model():\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Dense(64, activation='relu', input_shape=(train_data.shape[1],)))\n",
        "  model.add(layers.Dense(64, activation='relu'))\n",
        "  model.add(layers.Dense(32, activation='relu'))\n",
        "  model.add(layers.Dense(32, activation='relu')) \n",
        "  model.add(layers.Dense(1)) # no activation\n",
        "  model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "#   RMSprop = tf.keras.optimizers.experimental.RMSprop(learning_rate=0.001)\n",
        "#   model.compile(optimizer=RMSprop, loss='mse', metrics=['mae'])\n",
        "#   model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iy-n87_M4vy8",
        "outputId": "cf377a82-b3e7-479e-872b-5d20ce3190f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processing fold # 0\n",
            "Epoch 1/65\n",
            "152/152 [==============================] - 2s 2ms/step - loss: 249.8922 - mae: 12.2043\n",
            "Epoch 2/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 24.7764 - mae: 3.3658\n",
            "Epoch 3/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 19.8118 - mae: 2.9921\n",
            "Epoch 4/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 16.8080 - mae: 2.8800\n",
            "Epoch 5/65\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 14.0875 - mae: 2.6203\n",
            "Epoch 6/65\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 13.0300 - mae: 2.5361\n",
            "Epoch 7/65\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 12.3403 - mae: 2.4691\n",
            "Epoch 8/65\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 11.2718 - mae: 2.4037\n",
            "Epoch 9/65\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 11.2852 - mae: 2.4392\n",
            "Epoch 10/65\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 10.4923 - mae: 2.3021\n",
            "Epoch 11/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 9.7825 - mae: 2.1939\n",
            "Epoch 12/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 8.6962 - mae: 2.1285\n",
            "Epoch 13/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 9.0273 - mae: 2.1520\n",
            "Epoch 14/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 9.7200 - mae: 2.2170\n",
            "Epoch 15/65\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 8.8129 - mae: 2.1079\n",
            "Epoch 16/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 8.2274 - mae: 2.0192\n",
            "Epoch 17/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 7.7920 - mae: 1.9340\n",
            "Epoch 18/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 9.9190 - mae: 2.3816\n",
            "Epoch 19/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 7.4942 - mae: 2.0506\n",
            "Epoch 20/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 7.5457 - mae: 1.9847\n",
            "Epoch 21/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 6.7972 - mae: 1.8891\n",
            "Epoch 22/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 7.7292 - mae: 1.9372\n",
            "Epoch 23/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 8.6686 - mae: 2.0894\n",
            "Epoch 24/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 8.0623 - mae: 2.0806\n",
            "Epoch 25/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 5.7005 - mae: 1.7660\n",
            "Epoch 26/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 6.6726 - mae: 1.8601\n",
            "Epoch 27/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 6.6695 - mae: 1.9200\n",
            "Epoch 28/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 5.1533 - mae: 1.6627\n",
            "Epoch 29/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 5.9265 - mae: 1.8242\n",
            "Epoch 30/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 5.2269 - mae: 1.7271\n",
            "Epoch 31/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 5.9953 - mae: 1.7316\n",
            "Epoch 32/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 5.4948 - mae: 1.7753\n",
            "Epoch 33/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 5.5664 - mae: 1.7407\n",
            "Epoch 34/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 4.5679 - mae: 1.6116\n",
            "Epoch 35/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 4.2041 - mae: 1.5631\n",
            "Epoch 36/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 4.4221 - mae: 1.5379\n",
            "Epoch 37/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 5.1640 - mae: 1.6282\n",
            "Epoch 38/65\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 4.7771 - mae: 1.6776\n",
            "Epoch 39/65\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 4.4578 - mae: 1.6425\n",
            "Epoch 40/65\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 4.8727 - mae: 1.6356\n",
            "Epoch 41/65\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 3.7037 - mae: 1.4602\n",
            "Epoch 42/65\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 4.1022 - mae: 1.5671\n",
            "Epoch 43/65\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 5.2142 - mae: 1.6447\n",
            "Epoch 44/65\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 3.7441 - mae: 1.4610\n",
            "Epoch 45/65\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 3.6972 - mae: 1.4273\n",
            "Epoch 46/65\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 3.4795 - mae: 1.3799\n",
            "Epoch 47/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.6114 - mae: 1.3587\n",
            "Epoch 48/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.7654 - mae: 1.4290\n",
            "Epoch 49/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.1120 - mae: 1.3227\n",
            "Epoch 50/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 2.9970 - mae: 1.3168\n",
            "Epoch 51/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.8193 - mae: 1.4670\n",
            "Epoch 52/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 2.9578 - mae: 1.2944\n",
            "Epoch 53/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.0984 - mae: 1.3123\n",
            "Epoch 54/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.3100 - mae: 1.3682\n",
            "Epoch 55/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.0440 - mae: 1.3311\n",
            "Epoch 56/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 4.4242 - mae: 1.6215\n",
            "Epoch 57/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.1827 - mae: 1.3363\n",
            "Epoch 58/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 2.5439 - mae: 1.2111\n",
            "Epoch 59/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 2.7753 - mae: 1.2396\n",
            "Epoch 60/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 4.7262 - mae: 1.6390\n",
            "Epoch 61/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 2.8463 - mae: 1.2264\n",
            "Epoch 62/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.6609 - mae: 1.4015\n",
            "Epoch 63/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.8190 - mae: 1.3992\n",
            "Epoch 64/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 2.5331 - mae: 1.1453\n",
            "Epoch 65/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 2.6260 - mae: 1.1945\n",
            "processing fold # 1\n",
            "Epoch 1/65\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 212.7737 - mae: 10.3922\n",
            "Epoch 2/65\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 26.6178 - mae: 3.4080\n",
            "Epoch 3/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 20.0166 - mae: 3.0594\n",
            "Epoch 4/65\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 14.3741 - mae: 2.5613\n",
            "Epoch 5/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 13.4977 - mae: 2.4817\n",
            "Epoch 6/65\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 12.4112 - mae: 2.3710\n",
            "Epoch 7/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 12.9120 - mae: 2.4878\n",
            "Epoch 8/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 11.1823 - mae: 2.3207\n",
            "Epoch 9/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 9.8504 - mae: 2.2406\n",
            "Epoch 10/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 11.4188 - mae: 2.4210\n",
            "Epoch 11/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 9.5261 - mae: 2.1308\n",
            "Epoch 12/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 9.6210 - mae: 2.2007\n",
            "Epoch 13/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 9.2397 - mae: 2.1258\n",
            "Epoch 14/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 7.9139 - mae: 1.9852\n",
            "Epoch 15/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 8.2974 - mae: 1.9948\n",
            "Epoch 16/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 8.1816 - mae: 2.0615\n",
            "Epoch 17/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 8.0556 - mae: 2.0638\n",
            "Epoch 18/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 7.3765 - mae: 1.9193\n",
            "Epoch 19/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 7.5395 - mae: 1.9411\n",
            "Epoch 20/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 6.7146 - mae: 1.8873\n",
            "Epoch 21/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 6.7957 - mae: 1.9490\n",
            "Epoch 22/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 7.0332 - mae: 1.9224\n",
            "Epoch 23/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 6.3178 - mae: 1.7742\n",
            "Epoch 24/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 6.3689 - mae: 1.8706\n",
            "Epoch 25/65\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 6.3707 - mae: 1.8398\n",
            "Epoch 26/65\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 5.7730 - mae: 1.8368\n",
            "Epoch 27/65\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 5.2268 - mae: 1.7293\n",
            "Epoch 28/65\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 6.2436 - mae: 1.8547\n",
            "Epoch 29/65\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 4.9188 - mae: 1.6834\n",
            "Epoch 30/65\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 4.7132 - mae: 1.6277\n",
            "Epoch 31/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 4.5464 - mae: 1.6503\n",
            "Epoch 32/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 4.8329 - mae: 1.6758\n",
            "Epoch 33/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.9724 - mae: 1.5031\n",
            "Epoch 34/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.7677 - mae: 1.4821\n",
            "Epoch 35/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.7523 - mae: 1.4945\n",
            "Epoch 36/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.8720 - mae: 1.5173\n",
            "Epoch 37/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.4000 - mae: 1.3840\n",
            "Epoch 38/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.3222 - mae: 1.3750\n",
            "Epoch 39/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.3198 - mae: 1.4307\n",
            "Epoch 40/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 4.0618 - mae: 1.4801\n",
            "Epoch 41/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.3137 - mae: 1.4275\n",
            "Epoch 42/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.0620 - mae: 1.3572\n",
            "Epoch 43/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 2.8716 - mae: 1.3003\n",
            "Epoch 44/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.1051 - mae: 1.3403\n",
            "Epoch 45/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 4.3947 - mae: 1.5222\n",
            "Epoch 46/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.0206 - mae: 1.3174\n",
            "Epoch 47/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 2.4033 - mae: 1.1851\n",
            "Epoch 48/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 2.5771 - mae: 1.2253\n",
            "Epoch 49/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 2.5288 - mae: 1.1990\n",
            "Epoch 50/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 2.9856 - mae: 1.2817\n",
            "Epoch 51/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 2.7358 - mae: 1.2787\n",
            "Epoch 52/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.0705 - mae: 1.2971\n",
            "Epoch 53/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 2.9624 - mae: 1.2741\n",
            "Epoch 54/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 2.4181 - mae: 1.1748\n",
            "Epoch 55/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 2.2508 - mae: 1.1609\n",
            "Epoch 56/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.8397 - mae: 1.5199\n",
            "Epoch 57/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 2.7181 - mae: 1.3007\n",
            "Epoch 58/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 2.5467 - mae: 1.2524\n",
            "Epoch 59/65\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.1661 - mae: 1.1124\n",
            "Epoch 60/65\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.4421 - mae: 1.1763\n",
            "Epoch 61/65\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.3534 - mae: 1.1624\n",
            "Epoch 62/65\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.9368 - mae: 1.2745\n",
            "Epoch 63/65\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 3.1508 - mae: 1.2547\n",
            "Epoch 64/65\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.1890 - mae: 1.1338\n",
            "Epoch 65/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.2542 - mae: 1.3514\n",
            "processing fold # 2\n",
            "Epoch 1/65\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 239.0143 - mae: 11.2246\n",
            "Epoch 2/65\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 26.8340 - mae: 3.7412\n",
            "Epoch 3/65\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 18.0836 - mae: 3.0572\n",
            "Epoch 4/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 13.3210 - mae: 2.6303\n",
            "Epoch 5/65\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 12.7830 - mae: 2.6646\n",
            "Epoch 6/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 10.6426 - mae: 2.3711\n",
            "Epoch 7/65\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 9.4286 - mae: 2.1850\n",
            "Epoch 8/65\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 9.3150 - mae: 2.2376\n",
            "Epoch 9/65\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 8.2580 - mae: 2.0982\n",
            "Epoch 10/65\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 7.9390 - mae: 2.1024\n",
            "Epoch 11/65\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 7.4999 - mae: 2.0683\n",
            "Epoch 12/65\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 7.6100 - mae: 2.0345\n",
            "Epoch 13/65\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 7.3639 - mae: 2.0355\n",
            "Epoch 14/65\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 6.7136 - mae: 1.9576\n",
            "Epoch 15/65\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 6.1656 - mae: 1.8634\n",
            "Epoch 16/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 6.6049 - mae: 1.9739\n",
            "Epoch 17/65\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 5.7634 - mae: 1.8084\n",
            "Epoch 18/65\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 5.8651 - mae: 1.7988\n",
            "Epoch 19/65\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 6.4067 - mae: 1.9408\n",
            "Epoch 20/65\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 5.1653 - mae: 1.6864\n",
            "Epoch 21/65\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 5.2280 - mae: 1.6993\n",
            "Epoch 22/65\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 5.4702 - mae: 1.7645\n",
            "Epoch 23/65\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 4.5476 - mae: 1.5660\n",
            "Epoch 24/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 4.4666 - mae: 1.6157\n",
            "Epoch 25/65\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 4.0334 - mae: 1.5268\n",
            "Epoch 26/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 4.4210 - mae: 1.6165\n",
            "Epoch 27/65\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 5.1249 - mae: 1.6356\n",
            "Epoch 28/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 4.5186 - mae: 1.5951\n",
            "Epoch 29/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.9867 - mae: 1.4987\n",
            "Epoch 30/65\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 3.3489 - mae: 1.4011\n",
            "Epoch 31/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.4862 - mae: 1.4349\n",
            "Epoch 32/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 2.9998 - mae: 1.3113\n",
            "Epoch 33/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 4.5646 - mae: 1.6329\n",
            "Epoch 34/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.5339 - mae: 1.4035\n",
            "Epoch 35/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.7408 - mae: 1.5029\n",
            "Epoch 36/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.2401 - mae: 1.3800\n",
            "Epoch 37/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 2.8784 - mae: 1.3067\n",
            "Epoch 38/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.4560 - mae: 1.3743\n",
            "Epoch 39/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.5866 - mae: 1.4373\n",
            "Epoch 40/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.8912 - mae: 1.5520\n",
            "Epoch 41/65\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 4.3225 - mae: 1.6083\n",
            "Epoch 42/65\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 2.8445 - mae: 1.3093\n",
            "Epoch 43/65\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 3.1226 - mae: 1.3678\n",
            "Epoch 44/65\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.7456 - mae: 1.2807\n",
            "Epoch 45/65\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 3.0521 - mae: 1.3207\n",
            "Epoch 46/65\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 3.3000 - mae: 1.3982\n",
            "Epoch 47/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.0836 - mae: 1.3320\n",
            "Epoch 48/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 2.3991 - mae: 1.2275\n",
            "Epoch 49/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 2.9231 - mae: 1.3145\n",
            "Epoch 50/65\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.6802 - mae: 1.2262\n",
            "Epoch 51/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 2.2751 - mae: 1.1653\n",
            "Epoch 52/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 2.6009 - mae: 1.2264\n",
            "Epoch 53/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.3579 - mae: 1.3443\n",
            "Epoch 54/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 2.4547 - mae: 1.2051\n",
            "Epoch 55/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 2.7082 - mae: 1.2424\n",
            "Epoch 56/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 2.1262 - mae: 1.1211\n",
            "Epoch 57/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 2.4886 - mae: 1.1874\n",
            "Epoch 58/65\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.0330 - mae: 1.0737\n",
            "Epoch 59/65\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.5745 - mae: 1.1981\n",
            "Epoch 60/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 2.7990 - mae: 1.2979\n",
            "Epoch 61/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 2.2170 - mae: 1.1333\n",
            "Epoch 62/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 2.3339 - mae: 1.1584\n",
            "Epoch 63/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 2.3896 - mae: 1.2021\n",
            "Epoch 64/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 1.9243 - mae: 1.0546\n",
            "Epoch 65/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 2.3834 - mae: 1.1385\n",
            "processing fold # 3\n",
            "Epoch 1/65\n",
            "152/152 [==============================] - 2s 4ms/step - loss: 186.8688 - mae: 9.8365\n",
            "Epoch 2/65\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 19.6668 - mae: 3.1366\n",
            "Epoch 3/65\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 15.3260 - mae: 2.7910\n",
            "Epoch 4/65\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 13.5134 - mae: 2.6671\n",
            "Epoch 5/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 12.0610 - mae: 2.5184\n",
            "Epoch 6/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 10.2810 - mae: 2.3346\n",
            "Epoch 7/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 11.1318 - mae: 2.4300\n",
            "Epoch 8/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 10.6087 - mae: 2.3428\n",
            "Epoch 9/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 8.7618 - mae: 2.1381\n",
            "Epoch 10/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 7.9657 - mae: 2.0460\n",
            "Epoch 11/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 8.4444 - mae: 2.0867\n",
            "Epoch 12/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 7.1903 - mae: 1.9348\n",
            "Epoch 13/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 7.8963 - mae: 2.0768\n",
            "Epoch 14/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 7.7440 - mae: 2.0407\n",
            "Epoch 15/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 6.4063 - mae: 1.8852\n",
            "Epoch 16/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 6.6155 - mae: 1.8832\n",
            "Epoch 17/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 6.5793 - mae: 1.9109\n",
            "Epoch 18/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 7.4514 - mae: 1.9621\n",
            "Epoch 19/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 5.0939 - mae: 1.6163\n",
            "Epoch 20/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 4.7965 - mae: 1.6373\n",
            "Epoch 21/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 4.7505 - mae: 1.6360\n",
            "Epoch 22/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 5.8571 - mae: 1.7756\n",
            "Epoch 23/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 5.2878 - mae: 1.7225\n",
            "Epoch 24/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 4.5668 - mae: 1.5863\n",
            "Epoch 25/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 4.6514 - mae: 1.6243\n",
            "Epoch 26/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 4.9780 - mae: 1.6391\n",
            "Epoch 27/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.8716 - mae: 1.4218\n",
            "Epoch 28/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 4.1617 - mae: 1.4823\n",
            "Epoch 29/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 4.2132 - mae: 1.5122\n",
            "Epoch 30/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 4.0148 - mae: 1.5706\n",
            "Epoch 31/65\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 4.0581 - mae: 1.4931\n",
            "Epoch 32/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 4.5536 - mae: 1.5423\n",
            "Epoch 33/65\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 3.6777 - mae: 1.4521\n",
            "Epoch 34/65\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 4.0001 - mae: 1.5107\n",
            "Epoch 35/65\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 4.0961 - mae: 1.4989\n",
            "Epoch 36/65\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 3.9561 - mae: 1.4646\n",
            "Epoch 37/65\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 3.8867 - mae: 1.4442\n",
            "Epoch 38/65\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 4.0718 - mae: 1.4995\n",
            "Epoch 39/65\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 3.6490 - mae: 1.4378\n",
            "Epoch 40/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.5023 - mae: 1.4021\n",
            "Epoch 41/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 2.9831 - mae: 1.2692\n",
            "Epoch 42/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 4.3625 - mae: 1.5341\n",
            "Epoch 43/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.3611 - mae: 1.3059\n",
            "Epoch 44/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.6960 - mae: 1.4466\n",
            "Epoch 45/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.2493 - mae: 1.3854\n",
            "Epoch 46/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.0227 - mae: 1.3076\n",
            "Epoch 47/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 4.1062 - mae: 1.5731\n",
            "Epoch 48/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.2522 - mae: 1.3128\n",
            "Epoch 49/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 2.7951 - mae: 1.2491\n",
            "Epoch 50/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.0867 - mae: 1.2835\n",
            "Epoch 51/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.0911 - mae: 1.3474\n",
            "Epoch 52/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 2.9662 - mae: 1.2481\n",
            "Epoch 53/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 2.8493 - mae: 1.2310\n",
            "Epoch 54/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.7416 - mae: 1.4394\n",
            "Epoch 55/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.0827 - mae: 1.2900\n",
            "Epoch 56/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.7327 - mae: 1.3914\n",
            "Epoch 57/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 2.9956 - mae: 1.2705\n",
            "Epoch 58/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 2.9115 - mae: 1.2586\n",
            "Epoch 59/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.6248 - mae: 1.3799\n",
            "Epoch 60/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 2.7853 - mae: 1.2160\n",
            "Epoch 61/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 3.1541 - mae: 1.3104\n",
            "Epoch 62/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 2.8233 - mae: 1.2456\n",
            "Epoch 63/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 2.7162 - mae: 1.1987\n",
            "Epoch 64/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 2.4135 - mae: 1.1407\n",
            "Epoch 65/65\n",
            "152/152 [==============================] - 0s 2ms/step - loss: 2.5909 - mae: 1.1696\n",
            "All scores: [2.0464835166931152, 2.229228973388672, 2.364978551864624, 2.461731195449829], mean: 2.27560555934906\n",
            "min: 5.0, max: 50.0\n",
            "0.0455121111869812 % error\n"
          ]
        }
      ],
      "source": [
        "k = 4\n",
        "num_val_samples = len(train_data) // k\n",
        "num_epochs = 65\n",
        "all_scores = []\n",
        "\n",
        "for i in range(k):\n",
        "  print('processing fold #', i)\n",
        "  val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "  val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
        " \n",
        "  partial_train_data = np.concatenate([train_data[:i * num_val_samples], train_data[(i + 1) * num_val_samples:]], axis=0)\n",
        "  partial_train_targets = np.concatenate([train_targets[:i * num_val_samples], train_targets[(i + 1) * num_val_samples:]], axis=0)\n",
        " \n",
        "  model = build_model()\n",
        "  model.fit(partial_train_data, partial_train_targets, epochs=num_epochs, batch_size=2, verbose=1)\n",
        "  val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
        "  all_scores.append(val_mae)\n",
        "\n",
        "print(f\"All scores: {(all_scores)}, mean: {(np.mean(all_scores))}\")\n",
        "print(f\"min: {min(train_targets)}, max: {max(train_targets)}\") \n",
        "print(f\"{np.mean(all_scores) / max(train_targets)} % error\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZL0skqVVd3qL",
        "outputId": "9f00ecd6-d3a3-47dd-b83e-531440843537"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processing fold # 0\n",
            "Epoch 1/300\n",
            "152/152 [==============================] - 2s 6ms/step - loss: 247.4301 - mae: 11.6428 - val_loss: 28.7196 - val_mae: 3.6427\n",
            "Epoch 2/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 23.2954 - mae: 3.4265 - val_loss: 19.1985 - val_mae: 3.2098\n",
            "Epoch 3/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 19.8138 - mae: 3.1289 - val_loss: 14.8012 - val_mae: 2.7164\n",
            "Epoch 4/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 15.6729 - mae: 2.9001 - val_loss: 14.3589 - val_mae: 2.6340\n",
            "Epoch 5/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 14.9564 - mae: 2.7193 - val_loss: 13.0828 - val_mae: 2.7014\n",
            "Epoch 6/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 13.6947 - mae: 2.6506 - val_loss: 10.6429 - val_mae: 2.3714\n",
            "Epoch 7/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 12.0202 - mae: 2.4594 - val_loss: 10.4648 - val_mae: 2.5421\n",
            "Epoch 8/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 11.5951 - mae: 2.4392 - val_loss: 11.7142 - val_mae: 2.6957\n",
            "Epoch 9/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 11.4786 - mae: 2.3910 - val_loss: 10.0003 - val_mae: 2.1959\n",
            "Epoch 10/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 11.0077 - mae: 2.4356 - val_loss: 10.6447 - val_mae: 2.4586\n",
            "Epoch 11/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 12.0770 - mae: 2.4295 - val_loss: 9.1877 - val_mae: 2.2867\n",
            "Epoch 12/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 9.8459 - mae: 2.2333 - val_loss: 8.5337 - val_mae: 2.2178\n",
            "Epoch 13/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 10.0385 - mae: 2.3141 - val_loss: 8.2980 - val_mae: 2.0501\n",
            "Epoch 14/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 9.1057 - mae: 2.1218 - val_loss: 8.3668 - val_mae: 2.0189\n",
            "Epoch 15/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 8.8579 - mae: 2.1727 - val_loss: 8.0692 - val_mae: 2.1533\n",
            "Epoch 16/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 8.8033 - mae: 2.1758 - val_loss: 8.2945 - val_mae: 2.1959\n",
            "Epoch 17/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 8.1760 - mae: 2.0485 - val_loss: 8.9139 - val_mae: 2.3266\n",
            "Epoch 18/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 7.8973 - mae: 2.0332 - val_loss: 8.1939 - val_mae: 2.2756\n",
            "Epoch 19/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 7.7343 - mae: 2.0586 - val_loss: 9.8625 - val_mae: 2.4415\n",
            "Epoch 20/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 8.1150 - mae: 2.0884 - val_loss: 10.1612 - val_mae: 2.3984\n",
            "Epoch 21/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 7.0014 - mae: 1.9703 - val_loss: 6.6845 - val_mae: 1.9793\n",
            "Epoch 22/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 7.1384 - mae: 1.9320 - val_loss: 9.0663 - val_mae: 2.3469\n",
            "Epoch 23/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 7.1069 - mae: 1.9210 - val_loss: 10.6395 - val_mae: 2.5409\n",
            "Epoch 24/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 6.4127 - mae: 1.8798 - val_loss: 7.1189 - val_mae: 2.0789\n",
            "Epoch 25/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 5.6792 - mae: 1.7851 - val_loss: 7.7973 - val_mae: 1.8983\n",
            "Epoch 26/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 6.6156 - mae: 1.9269 - val_loss: 9.4387 - val_mae: 2.3015\n",
            "Epoch 27/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 6.7052 - mae: 1.9121 - val_loss: 8.2819 - val_mae: 2.2733\n",
            "Epoch 28/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 5.7522 - mae: 1.8005 - val_loss: 8.6299 - val_mae: 2.3946\n",
            "Epoch 29/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 5.9758 - mae: 1.8212 - val_loss: 11.8735 - val_mae: 2.7015\n",
            "Epoch 30/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 6.1869 - mae: 1.8125 - val_loss: 7.0555 - val_mae: 2.0740\n",
            "Epoch 31/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 5.6749 - mae: 1.7757 - val_loss: 8.3628 - val_mae: 2.1748\n",
            "Epoch 32/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 6.3583 - mae: 1.9228 - val_loss: 6.4206 - val_mae: 1.9404\n",
            "Epoch 33/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 5.3616 - mae: 1.7088 - val_loss: 6.5151 - val_mae: 1.8995\n",
            "Epoch 34/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 5.4163 - mae: 1.7733 - val_loss: 8.9990 - val_mae: 2.1796\n",
            "Epoch 35/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 5.4037 - mae: 1.7900 - val_loss: 6.5009 - val_mae: 1.9715\n",
            "Epoch 36/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 4.6519 - mae: 1.5814 - val_loss: 7.6441 - val_mae: 2.0152\n",
            "Epoch 37/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 4.9380 - mae: 1.6645 - val_loss: 7.2549 - val_mae: 1.9926\n",
            "Epoch 38/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 4.6877 - mae: 1.6796 - val_loss: 7.5986 - val_mae: 1.9423\n",
            "Epoch 39/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 4.3564 - mae: 1.5553 - val_loss: 6.7664 - val_mae: 1.8564\n",
            "Epoch 40/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 5.1576 - mae: 1.6675 - val_loss: 8.7787 - val_mae: 2.3371\n",
            "Epoch 41/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 6.3571 - mae: 1.9383 - val_loss: 9.0947 - val_mae: 2.2351\n",
            "Epoch 42/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 4.8193 - mae: 1.6323 - val_loss: 5.7640 - val_mae: 1.8369\n",
            "Epoch 43/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 4.3274 - mae: 1.5487 - val_loss: 5.9467 - val_mae: 1.8265\n",
            "Epoch 44/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 3.8014 - mae: 1.4524 - val_loss: 6.5211 - val_mae: 1.9580\n",
            "Epoch 45/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 4.2691 - mae: 1.5380 - val_loss: 6.6660 - val_mae: 1.9338\n",
            "Epoch 46/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 4.6461 - mae: 1.6490 - val_loss: 6.1984 - val_mae: 1.8472\n",
            "Epoch 47/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 3.6066 - mae: 1.4385 - val_loss: 6.7579 - val_mae: 1.9206\n",
            "Epoch 48/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 3.9256 - mae: 1.4979 - val_loss: 6.2010 - val_mae: 1.9499\n",
            "Epoch 49/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 3.4679 - mae: 1.4291 - val_loss: 5.9006 - val_mae: 1.8395\n",
            "Epoch 50/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 3.4735 - mae: 1.3954 - val_loss: 5.3948 - val_mae: 1.7778\n",
            "Epoch 51/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 4.0672 - mae: 1.5322 - val_loss: 6.9556 - val_mae: 1.9336\n",
            "Epoch 52/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 3.8880 - mae: 1.5118 - val_loss: 6.4514 - val_mae: 1.8415\n",
            "Epoch 53/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 3.3310 - mae: 1.3610 - val_loss: 6.0950 - val_mae: 1.8769\n",
            "Epoch 54/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.9529 - mae: 1.3430 - val_loss: 6.5988 - val_mae: 1.9179\n",
            "Epoch 55/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.8977 - mae: 1.3002 - val_loss: 6.7850 - val_mae: 1.9154\n",
            "Epoch 56/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 3.9273 - mae: 1.4568 - val_loss: 6.6280 - val_mae: 1.8670\n",
            "Epoch 57/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 4.0998 - mae: 1.5419 - val_loss: 8.1481 - val_mae: 2.1336\n",
            "Epoch 58/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 4.3469 - mae: 1.6209 - val_loss: 6.9514 - val_mae: 2.1296\n",
            "Epoch 59/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 3.0280 - mae: 1.3184 - val_loss: 6.3799 - val_mae: 1.9185\n",
            "Epoch 60/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 3.4694 - mae: 1.3423 - val_loss: 6.2330 - val_mae: 1.8809\n",
            "Epoch 61/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 2.8149 - mae: 1.2596 - val_loss: 6.2411 - val_mae: 1.8003\n",
            "Epoch 62/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 3.1688 - mae: 1.3130 - val_loss: 6.6383 - val_mae: 2.0293\n",
            "Epoch 63/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.6284 - mae: 1.2450 - val_loss: 6.0767 - val_mae: 1.9211\n",
            "Epoch 64/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 2.7123 - mae: 1.2265 - val_loss: 7.1002 - val_mae: 1.9310\n",
            "Epoch 65/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 3.1427 - mae: 1.3118 - val_loss: 7.9986 - val_mae: 2.1607\n",
            "Epoch 66/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 2.7037 - mae: 1.2648 - val_loss: 7.9663 - val_mae: 2.1221\n",
            "Epoch 67/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.9973 - mae: 1.2855 - val_loss: 7.3365 - val_mae: 2.0266\n",
            "Epoch 68/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 3.0309 - mae: 1.2261 - val_loss: 7.4461 - val_mae: 2.1229\n",
            "Epoch 69/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.9716 - mae: 1.3117 - val_loss: 6.7907 - val_mae: 1.9699\n",
            "Epoch 70/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 3.3947 - mae: 1.4297 - val_loss: 6.6147 - val_mae: 1.9099\n",
            "Epoch 71/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.6737 - mae: 1.1604 - val_loss: 5.8812 - val_mae: 1.8258\n",
            "Epoch 72/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 3.2677 - mae: 1.3523 - val_loss: 7.4004 - val_mae: 2.0219\n",
            "Epoch 73/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.2020 - mae: 1.1310 - val_loss: 9.1002 - val_mae: 2.1310\n",
            "Epoch 74/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.5033 - mae: 1.2117 - val_loss: 8.2780 - val_mae: 2.2607\n",
            "Epoch 75/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 3.2015 - mae: 1.3385 - val_loss: 6.8883 - val_mae: 1.9332\n",
            "Epoch 76/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.3005 - mae: 1.1023 - val_loss: 7.2447 - val_mae: 1.8978\n",
            "Epoch 77/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.2570 - mae: 1.1209 - val_loss: 7.4248 - val_mae: 2.0634\n",
            "Epoch 78/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.3793 - mae: 1.1524 - val_loss: 10.3186 - val_mae: 2.5966\n",
            "Epoch 79/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.6210 - mae: 1.2656 - val_loss: 6.6817 - val_mae: 1.9621\n",
            "Epoch 80/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.7793 - mae: 1.2626 - val_loss: 8.2215 - val_mae: 2.2067\n",
            "Epoch 81/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.7769 - mae: 1.2167 - val_loss: 6.5484 - val_mae: 1.9154\n",
            "Epoch 82/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.2154 - mae: 1.1313 - val_loss: 6.7977 - val_mae: 2.0588\n",
            "Epoch 83/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.2384 - mae: 1.0968 - val_loss: 7.3502 - val_mae: 2.1511\n",
            "Epoch 84/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.5161 - mae: 1.2084 - val_loss: 5.9758 - val_mae: 1.9065\n",
            "Epoch 85/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.8981 - mae: 1.0360 - val_loss: 6.1317 - val_mae: 1.8749\n",
            "Epoch 86/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.0033 - mae: 1.0535 - val_loss: 6.5030 - val_mae: 1.9119\n",
            "Epoch 87/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.3663 - mae: 1.1642 - val_loss: 8.8278 - val_mae: 2.1721\n",
            "Epoch 88/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.3716 - mae: 1.1606 - val_loss: 8.1653 - val_mae: 2.1610\n",
            "Epoch 89/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.4795 - mae: 1.1934 - val_loss: 7.9168 - val_mae: 2.1504\n",
            "Epoch 90/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.0086 - mae: 1.0963 - val_loss: 11.8368 - val_mae: 2.7197\n",
            "Epoch 91/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.3840 - mae: 1.1715 - val_loss: 7.4160 - val_mae: 2.0106\n",
            "Epoch 92/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.1289 - mae: 1.0937 - val_loss: 7.1670 - val_mae: 1.9625\n",
            "Epoch 93/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.1400 - mae: 1.1350 - val_loss: 7.0421 - val_mae: 2.0168\n",
            "Epoch 94/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 2.6007 - mae: 1.1656 - val_loss: 7.8492 - val_mae: 2.1387\n",
            "Epoch 95/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.2322 - mae: 1.1371 - val_loss: 8.2041 - val_mae: 2.1168\n",
            "Epoch 96/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.9167 - mae: 1.0445 - val_loss: 9.5767 - val_mae: 2.4481\n",
            "Epoch 97/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.5908 - mae: 1.1858 - val_loss: 8.7695 - val_mae: 2.2227\n",
            "Epoch 98/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.2372 - mae: 1.1752 - val_loss: 6.8900 - val_mae: 2.0131\n",
            "Epoch 99/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.9336 - mae: 1.0077 - val_loss: 6.8094 - val_mae: 1.9210\n",
            "Epoch 100/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.4398 - mae: 0.8907 - val_loss: 7.1041 - val_mae: 2.0604\n",
            "Epoch 101/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.4260 - mae: 0.9389 - val_loss: 7.6024 - val_mae: 2.0580\n",
            "Epoch 102/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.5014 - mae: 0.9218 - val_loss: 7.5727 - val_mae: 2.1044\n",
            "Epoch 103/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 2.1096 - mae: 1.1102 - val_loss: 11.3567 - val_mae: 2.4625\n",
            "Epoch 104/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 2.0607 - mae: 1.0709 - val_loss: 7.1727 - val_mae: 2.0616\n",
            "Epoch 105/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.7794 - mae: 1.0087 - val_loss: 8.4764 - val_mae: 2.1527\n",
            "Epoch 106/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 2.0214 - mae: 1.0294 - val_loss: 7.6928 - val_mae: 2.1183\n",
            "Epoch 107/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.0215 - mae: 1.1107 - val_loss: 6.8959 - val_mae: 2.0086\n",
            "Epoch 108/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.8406 - mae: 1.0571 - val_loss: 7.2575 - val_mae: 2.0312\n",
            "Epoch 109/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 2.1290 - mae: 1.1338 - val_loss: 7.2920 - val_mae: 2.1121\n",
            "Epoch 110/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.7473 - mae: 0.9929 - val_loss: 8.1785 - val_mae: 2.1935\n",
            "Epoch 111/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 2.1305 - mae: 1.0453 - val_loss: 7.1237 - val_mae: 2.0540\n",
            "Epoch 112/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.0117 - mae: 1.0539 - val_loss: 8.4084 - val_mae: 2.2856\n",
            "Epoch 113/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.5874 - mae: 0.9740 - val_loss: 7.6796 - val_mae: 2.0759\n",
            "Epoch 114/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.5913 - mae: 0.9409 - val_loss: 6.2548 - val_mae: 1.9773\n",
            "Epoch 115/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.4936 - mae: 0.9221 - val_loss: 8.4010 - val_mae: 2.1233\n",
            "Epoch 116/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.5780 - mae: 0.9204 - val_loss: 8.1905 - val_mae: 2.2217\n",
            "Epoch 117/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.8006 - mae: 1.0243 - val_loss: 9.3330 - val_mae: 2.2439\n",
            "Epoch 118/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.7436 - mae: 1.0026 - val_loss: 7.0040 - val_mae: 2.0018\n",
            "Epoch 119/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.4035 - mae: 0.8877 - val_loss: 7.6112 - val_mae: 2.0893\n",
            "Epoch 120/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.5020 - mae: 0.9417 - val_loss: 8.1803 - val_mae: 2.1040\n",
            "Epoch 121/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.2891 - mae: 0.8550 - val_loss: 7.0334 - val_mae: 1.9810\n",
            "Epoch 122/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.0960 - mae: 1.0684 - val_loss: 9.1057 - val_mae: 2.3215\n",
            "Epoch 123/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.9094 - mae: 0.9887 - val_loss: 7.6533 - val_mae: 2.1157\n",
            "Epoch 124/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.3328 - mae: 0.8602 - val_loss: 7.2843 - val_mae: 2.0403\n",
            "Epoch 125/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.1665 - mae: 0.8294 - val_loss: 6.5819 - val_mae: 1.9846\n",
            "Epoch 126/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.7700 - mae: 1.0199 - val_loss: 6.8768 - val_mae: 1.9437\n",
            "Epoch 127/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.2706 - mae: 0.8553 - val_loss: 7.8074 - val_mae: 2.1166\n",
            "Epoch 128/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.7308 - mae: 1.0046 - val_loss: 6.9258 - val_mae: 1.9902\n",
            "Epoch 129/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.7683 - mae: 0.9774 - val_loss: 7.9534 - val_mae: 2.1434\n",
            "Epoch 130/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.6708 - mae: 1.1589 - val_loss: 8.5288 - val_mae: 2.1673\n",
            "Epoch 131/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.7627 - mae: 1.0017 - val_loss: 7.4028 - val_mae: 2.0683\n",
            "Epoch 132/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.6146 - mae: 0.9450 - val_loss: 7.8598 - val_mae: 2.1892\n",
            "Epoch 133/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.2268 - mae: 0.8257 - val_loss: 7.2070 - val_mae: 2.0006\n",
            "Epoch 134/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.0035 - mae: 0.7661 - val_loss: 8.0319 - val_mae: 2.1376\n",
            "Epoch 135/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.3344 - mae: 0.8790 - val_loss: 7.7878 - val_mae: 2.1947\n",
            "Epoch 136/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.4178 - mae: 0.9137 - val_loss: 7.7722 - val_mae: 2.1424\n",
            "Epoch 137/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.1962 - mae: 0.8597 - val_loss: 8.2948 - val_mae: 2.1379\n",
            "Epoch 138/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.1972 - mae: 0.8397 - val_loss: 7.0481 - val_mae: 2.1152\n",
            "Epoch 139/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.1197 - mae: 0.7926 - val_loss: 7.3827 - val_mae: 2.1288\n",
            "Epoch 140/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.9380 - mae: 0.7306 - val_loss: 7.7568 - val_mae: 2.1937\n",
            "Epoch 141/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.5719 - mae: 0.9627 - val_loss: 10.4416 - val_mae: 2.5338\n",
            "Epoch 142/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.5163 - mae: 0.9249 - val_loss: 7.3020 - val_mae: 2.0017\n",
            "Epoch 143/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.8989 - mae: 1.0129 - val_loss: 8.4714 - val_mae: 2.3748\n",
            "Epoch 144/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.7949 - mae: 0.9580 - val_loss: 7.4731 - val_mae: 2.0436\n",
            "Epoch 145/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.3618 - mae: 0.8455 - val_loss: 8.5527 - val_mae: 2.1618\n",
            "Epoch 146/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.7856 - mae: 0.9713 - val_loss: 7.0088 - val_mae: 2.0901\n",
            "Epoch 147/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.5773 - mae: 0.9135 - val_loss: 9.9571 - val_mae: 2.3625\n",
            "Epoch 148/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.9433 - mae: 0.7463 - val_loss: 7.9456 - val_mae: 2.1281\n",
            "Epoch 149/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.2082 - mae: 0.8178 - val_loss: 6.8303 - val_mae: 2.0461\n",
            "Epoch 150/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.0980 - mae: 0.7758 - val_loss: 6.7343 - val_mae: 2.0021\n",
            "Epoch 151/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.0093 - mae: 0.7288 - val_loss: 6.9945 - val_mae: 2.0438\n",
            "Epoch 152/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.0869 - mae: 0.8084 - val_loss: 8.2027 - val_mae: 2.1560\n",
            "Epoch 153/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.1354 - mae: 0.8115 - val_loss: 7.5894 - val_mae: 2.1120\n",
            "Epoch 154/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.0935 - mae: 0.7870 - val_loss: 9.3957 - val_mae: 2.4604\n",
            "Epoch 155/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 2.4392 - mae: 1.1090 - val_loss: 10.1177 - val_mae: 2.3483\n",
            "Epoch 156/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.2241 - mae: 0.8400 - val_loss: 7.3504 - val_mae: 2.0697\n",
            "Epoch 157/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.0618 - mae: 0.7422 - val_loss: 9.1673 - val_mae: 2.2958\n",
            "Epoch 158/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.4081 - mae: 0.9070 - val_loss: 7.4913 - val_mae: 2.1084\n",
            "Epoch 159/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.8501 - mae: 0.6904 - val_loss: 7.8118 - val_mae: 2.1038\n",
            "Epoch 160/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.8369 - mae: 0.6878 - val_loss: 7.5443 - val_mae: 2.0968\n",
            "Epoch 161/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.9455 - mae: 0.7157 - val_loss: 8.2494 - val_mae: 2.2073\n",
            "Epoch 162/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.0236 - mae: 0.7461 - val_loss: 7.7696 - val_mae: 2.1257\n",
            "Epoch 163/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.9854 - mae: 0.7170 - val_loss: 7.9573 - val_mae: 2.1192\n",
            "Epoch 164/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.2684 - mae: 0.8003 - val_loss: 8.4064 - val_mae: 2.1640\n",
            "Epoch 165/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.7666 - mae: 0.9904 - val_loss: 7.1839 - val_mae: 2.0485\n",
            "Epoch 166/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.0464 - mae: 0.7745 - val_loss: 9.2031 - val_mae: 2.3239\n",
            "Epoch 167/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.9256 - mae: 0.7102 - val_loss: 7.9850 - val_mae: 2.1330\n",
            "Epoch 168/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.8221 - mae: 0.6843 - val_loss: 7.6783 - val_mae: 2.1475\n",
            "Epoch 169/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.6113 - mae: 0.6107 - val_loss: 8.1720 - val_mae: 2.1347\n",
            "Epoch 170/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.8628 - mae: 0.7107 - val_loss: 7.7514 - val_mae: 2.2089\n",
            "Epoch 171/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.3769 - mae: 0.8785 - val_loss: 7.4924 - val_mae: 2.1125\n",
            "Epoch 172/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.6374 - mae: 0.8783 - val_loss: 7.6235 - val_mae: 2.1492\n",
            "Epoch 173/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.5153 - mae: 0.9318 - val_loss: 7.7198 - val_mae: 2.1309\n",
            "Epoch 174/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.1803 - mae: 0.8458 - val_loss: 8.2203 - val_mae: 2.1064\n",
            "Epoch 175/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.3793 - mae: 0.8372 - val_loss: 9.2660 - val_mae: 2.2679\n",
            "Epoch 176/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.5384 - mae: 0.9365 - val_loss: 8.5066 - val_mae: 2.1600\n",
            "Epoch 177/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.5461 - mae: 0.9166 - val_loss: 7.6400 - val_mae: 2.0838\n",
            "Epoch 178/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.2779 - mae: 0.8096 - val_loss: 8.4056 - val_mae: 2.2690\n",
            "Epoch 179/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.0772 - mae: 0.7680 - val_loss: 7.9977 - val_mae: 2.1525\n",
            "Epoch 180/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.9382 - mae: 0.6966 - val_loss: 7.4897 - val_mae: 2.1061\n",
            "Epoch 181/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.0570 - mae: 0.7672 - val_loss: 7.6415 - val_mae: 2.1181\n",
            "Epoch 182/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.8409 - mae: 0.6965 - val_loss: 7.8687 - val_mae: 2.1585\n",
            "Epoch 183/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.6609 - mae: 0.6094 - val_loss: 7.7083 - val_mae: 2.1087\n",
            "Epoch 184/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.9186 - mae: 0.7404 - val_loss: 8.7479 - val_mae: 2.2408\n",
            "Epoch 185/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.9037 - mae: 0.7129 - val_loss: 7.4433 - val_mae: 2.0467\n",
            "Epoch 186/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.6628 - mae: 0.6273 - val_loss: 7.5033 - val_mae: 2.0750\n",
            "Epoch 187/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.0629 - mae: 0.7668 - val_loss: 7.9648 - val_mae: 2.0662\n",
            "Epoch 188/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.9836 - mae: 0.7449 - val_loss: 8.3976 - val_mae: 2.2998\n",
            "Epoch 189/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.1830 - mae: 0.7589 - val_loss: 10.9917 - val_mae: 2.5685\n",
            "Epoch 190/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.5382 - mae: 0.8556 - val_loss: 7.9171 - val_mae: 2.0512\n",
            "Epoch 191/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.8024 - mae: 0.9262 - val_loss: 9.7675 - val_mae: 2.3784\n",
            "Epoch 192/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.8103 - mae: 0.9521 - val_loss: 7.7083 - val_mae: 2.0952\n",
            "Epoch 193/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.7768 - mae: 0.6477 - val_loss: 8.1803 - val_mae: 2.1487\n",
            "Epoch 194/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.5412 - mae: 0.5839 - val_loss: 8.2137 - val_mae: 2.1637\n",
            "Epoch 195/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.6788 - mae: 0.5956 - val_loss: 7.5899 - val_mae: 2.0690\n",
            "Epoch 196/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.5874 - mae: 0.5799 - val_loss: 7.6926 - val_mae: 2.0675\n",
            "Epoch 197/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 0.7889 - mae: 0.6540 - val_loss: 10.4704 - val_mae: 2.5416\n",
            "Epoch 198/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.6529 - mae: 0.9781 - val_loss: 7.8168 - val_mae: 2.0491\n",
            "Epoch 199/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.6581 - mae: 0.8756 - val_loss: 9.0629 - val_mae: 2.2055\n",
            "Epoch 200/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.0105 - mae: 0.7486 - val_loss: 8.6222 - val_mae: 2.1861\n",
            "Epoch 201/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.8618 - mae: 0.6852 - val_loss: 8.9993 - val_mae: 2.2404\n",
            "Epoch 202/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.7929 - mae: 0.6333 - val_loss: 9.8888 - val_mae: 2.2893\n",
            "Epoch 203/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.5821 - mae: 0.5736 - val_loss: 7.8348 - val_mae: 2.0710\n",
            "Epoch 204/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.7483 - mae: 0.6183 - val_loss: 9.0116 - val_mae: 2.1919\n",
            "Epoch 205/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.5010 - mae: 0.8811 - val_loss: 8.3755 - val_mae: 2.2093\n",
            "Epoch 206/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.8765 - mae: 0.6953 - val_loss: 7.9209 - val_mae: 2.1337\n",
            "Epoch 207/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.8912 - mae: 0.6690 - val_loss: 8.4499 - val_mae: 2.1394\n",
            "Epoch 208/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.9174 - mae: 0.7094 - val_loss: 7.8431 - val_mae: 2.0561\n",
            "Epoch 209/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.6736 - mae: 0.6077 - val_loss: 8.5144 - val_mae: 2.1820\n",
            "Epoch 210/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.0159 - mae: 0.6934 - val_loss: 8.2962 - val_mae: 2.1739\n",
            "Epoch 211/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.8391 - mae: 0.6989 - val_loss: 9.0039 - val_mae: 2.1940\n",
            "Epoch 212/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.8590 - mae: 0.6907 - val_loss: 8.7896 - val_mae: 2.2126\n",
            "Epoch 213/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.4631 - mae: 0.8324 - val_loss: 9.1653 - val_mae: 2.3006\n",
            "Epoch 214/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.6526 - mae: 0.9707 - val_loss: 8.0786 - val_mae: 2.1117\n",
            "Epoch 215/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.8587 - mae: 0.6946 - val_loss: 9.6988 - val_mae: 2.2418\n",
            "Epoch 216/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.8310 - mae: 0.6851 - val_loss: 8.8689 - val_mae: 2.1952\n",
            "Epoch 217/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.8429 - mae: 0.6774 - val_loss: 8.9278 - val_mae: 2.2639\n",
            "Epoch 218/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.9557 - mae: 0.7151 - val_loss: 8.3265 - val_mae: 2.1167\n",
            "Epoch 219/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.8641 - mae: 0.6122 - val_loss: 8.9367 - val_mae: 2.1281\n",
            "Epoch 220/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.9796 - mae: 0.6919 - val_loss: 9.2121 - val_mae: 2.2478\n",
            "Epoch 221/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.7861 - mae: 0.6810 - val_loss: 8.1694 - val_mae: 2.1291\n",
            "Epoch 222/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.3800 - mae: 0.4759 - val_loss: 8.9021 - val_mae: 2.1722\n",
            "Epoch 223/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.4908 - mae: 0.5261 - val_loss: 8.7341 - val_mae: 2.2207\n",
            "Epoch 224/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.6044 - mae: 0.5540 - val_loss: 8.4004 - val_mae: 2.2274\n",
            "Epoch 225/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.8826 - mae: 0.7000 - val_loss: 8.3563 - val_mae: 2.2263\n",
            "Epoch 226/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.1666 - mae: 0.7425 - val_loss: 8.9832 - val_mae: 2.2530\n",
            "Epoch 227/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.9059 - mae: 1.0032 - val_loss: 8.7664 - val_mae: 2.1729\n",
            "Epoch 228/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 2.3624 - mae: 1.0886 - val_loss: 10.0878 - val_mae: 2.4231\n",
            "Epoch 229/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.1873 - mae: 0.8005 - val_loss: 7.3681 - val_mae: 2.0770\n",
            "Epoch 230/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.7707 - mae: 0.6688 - val_loss: 8.5016 - val_mae: 2.1480\n",
            "Epoch 231/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.5839 - mae: 0.5373 - val_loss: 9.4729 - val_mae: 2.2680\n",
            "Epoch 232/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.9787 - mae: 0.7251 - val_loss: 8.0764 - val_mae: 2.1056\n",
            "Epoch 233/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.8576 - mae: 0.6827 - val_loss: 8.6443 - val_mae: 2.1817\n",
            "Epoch 234/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.5283 - mae: 0.5514 - val_loss: 8.1565 - val_mae: 2.0815\n",
            "Epoch 235/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.8204 - mae: 0.6765 - val_loss: 8.2754 - val_mae: 2.1392\n",
            "Epoch 236/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.6712 - mae: 0.6269 - val_loss: 8.9132 - val_mae: 2.2257\n",
            "Epoch 237/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.6250 - mae: 0.6002 - val_loss: 8.4020 - val_mae: 2.1636\n",
            "Epoch 238/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.8356 - mae: 0.6802 - val_loss: 8.6514 - val_mae: 2.1271\n",
            "Epoch 239/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.7649 - mae: 0.6335 - val_loss: 8.6372 - val_mae: 2.2442\n",
            "Epoch 240/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.9118 - mae: 0.6868 - val_loss: 7.9531 - val_mae: 2.1174\n",
            "Epoch 241/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.6234 - mae: 0.5832 - val_loss: 9.0659 - val_mae: 2.1868\n",
            "Epoch 242/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.5082 - mae: 0.5295 - val_loss: 8.0890 - val_mae: 2.0859\n",
            "Epoch 243/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.7283 - mae: 0.6105 - val_loss: 8.8636 - val_mae: 2.2147\n",
            "Epoch 244/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.9487 - mae: 0.7036 - val_loss: 7.9314 - val_mae: 2.1433\n",
            "Epoch 245/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.7905 - mae: 0.6347 - val_loss: 8.6726 - val_mae: 2.1443\n",
            "Epoch 246/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4457 - mae: 0.4848 - val_loss: 8.7916 - val_mae: 2.1803\n",
            "Epoch 247/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.5592 - mae: 0.5725 - val_loss: 8.6780 - val_mae: 2.2503\n",
            "Epoch 248/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.9667 - mae: 0.7233 - val_loss: 10.0691 - val_mae: 2.3289\n",
            "Epoch 249/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.9890 - mae: 0.7300 - val_loss: 7.5738 - val_mae: 2.0887\n",
            "Epoch 250/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.9953 - mae: 0.7645 - val_loss: 8.0969 - val_mae: 2.0503\n",
            "Epoch 251/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.6514 - mae: 0.5826 - val_loss: 7.4343 - val_mae: 1.9779\n",
            "Epoch 252/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.0322 - mae: 0.7702 - val_loss: 8.4006 - val_mae: 2.1668\n",
            "Epoch 253/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.8536 - mae: 0.7202 - val_loss: 9.1859 - val_mae: 2.1689\n",
            "Epoch 254/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.6264 - mae: 0.5935 - val_loss: 9.0701 - val_mae: 2.2074\n",
            "Epoch 255/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.5410 - mae: 0.5384 - val_loss: 8.1019 - val_mae: 2.1018\n",
            "Epoch 256/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4441 - mae: 0.4956 - val_loss: 8.5964 - val_mae: 2.1240\n",
            "Epoch 257/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.6692 - mae: 0.5808 - val_loss: 8.2748 - val_mae: 2.1424\n",
            "Epoch 258/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.1166 - mae: 0.7275 - val_loss: 10.3273 - val_mae: 2.3191\n",
            "Epoch 259/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.1145 - mae: 0.7692 - val_loss: 8.8550 - val_mae: 2.1453\n",
            "Epoch 260/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.6064 - mae: 0.5808 - val_loss: 8.9014 - val_mae: 2.1724\n",
            "Epoch 261/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.6991 - mae: 0.6113 - val_loss: 8.7039 - val_mae: 2.1703\n",
            "Epoch 262/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.9205 - mae: 0.6900 - val_loss: 10.2165 - val_mae: 2.3513\n",
            "Epoch 263/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.1821 - mae: 0.8143 - val_loss: 8.8828 - val_mae: 2.0973\n",
            "Epoch 264/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.8999 - mae: 0.6231 - val_loss: 8.2161 - val_mae: 2.0346\n",
            "Epoch 265/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.0531 - mae: 0.7336 - val_loss: 8.7133 - val_mae: 2.1381\n",
            "Epoch 266/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.8116 - mae: 0.6426 - val_loss: 9.1055 - val_mae: 2.1716\n",
            "Epoch 267/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.7558 - mae: 0.6199 - val_loss: 8.8014 - val_mae: 2.1927\n",
            "Epoch 268/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.5450 - mae: 0.5646 - val_loss: 9.7877 - val_mae: 2.1697\n",
            "Epoch 269/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.5835 - mae: 0.5579 - val_loss: 8.1951 - val_mae: 2.0636\n",
            "Epoch 270/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.5796 - mae: 0.5218 - val_loss: 9.0129 - val_mae: 2.1616\n",
            "Epoch 271/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4528 - mae: 0.5156 - val_loss: 8.9454 - val_mae: 2.1789\n",
            "Epoch 272/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.9241 - mae: 0.7090 - val_loss: 10.2582 - val_mae: 2.2979\n",
            "Epoch 273/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.1239 - mae: 0.7455 - val_loss: 8.3028 - val_mae: 2.1165\n",
            "Epoch 274/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.6245 - mae: 0.5924 - val_loss: 10.0017 - val_mae: 2.2866\n",
            "Epoch 275/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.1594 - mae: 0.7614 - val_loss: 8.5610 - val_mae: 2.1500\n",
            "Epoch 276/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.4660 - mae: 0.8427 - val_loss: 7.8819 - val_mae: 2.0269\n",
            "Epoch 277/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.6091 - mae: 0.5734 - val_loss: 8.0250 - val_mae: 2.0120\n",
            "Epoch 279/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.6007 - mae: 0.5433 - val_loss: 8.5810 - val_mae: 2.0940\n",
            "Epoch 280/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.0685 - mae: 0.7545 - val_loss: 8.4253 - val_mae: 2.2312\n",
            "Epoch 281/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4838 - mae: 0.5288 - val_loss: 8.6938 - val_mae: 2.2043\n",
            "Epoch 282/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.6826 - mae: 0.5588 - val_loss: 8.4234 - val_mae: 2.2227\n",
            "Epoch 283/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.5742 - mae: 0.5340 - val_loss: 9.0630 - val_mae: 2.2534\n",
            "Epoch 284/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.6558 - mae: 0.6144 - val_loss: 8.3994 - val_mae: 2.0967\n",
            "Epoch 285/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.7219 - mae: 0.6405 - val_loss: 8.2645 - val_mae: 2.1389\n",
            "Epoch 286/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4386 - mae: 0.4917 - val_loss: 9.1103 - val_mae: 2.2033\n",
            "Epoch 287/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.6630 - mae: 0.5970 - val_loss: 8.5263 - val_mae: 2.1860\n",
            "Epoch 288/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.7184 - mae: 0.6181 - val_loss: 8.5010 - val_mae: 2.1637\n",
            "Epoch 289/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.7992 - mae: 0.6388 - val_loss: 8.5825 - val_mae: 2.1634\n",
            "Epoch 290/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.6930 - mae: 0.6148 - val_loss: 8.2796 - val_mae: 2.0795\n",
            "Epoch 291/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.5294 - mae: 0.5569 - val_loss: 8.6808 - val_mae: 2.1568\n",
            "Epoch 292/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4553 - mae: 0.4896 - val_loss: 9.3062 - val_mae: 2.1458\n",
            "Epoch 293/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.8202 - mae: 0.6237 - val_loss: 9.6471 - val_mae: 2.4072\n",
            "Epoch 294/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.9374 - mae: 0.7433 - val_loss: 8.5444 - val_mae: 2.0517\n",
            "Epoch 295/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.6081 - mae: 0.5906 - val_loss: 9.2384 - val_mae: 2.1124\n",
            "Epoch 296/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.5012 - mae: 0.4913 - val_loss: 9.3930 - val_mae: 2.2057\n",
            "Epoch 297/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.5628 - mae: 0.5487 - val_loss: 8.1022 - val_mae: 2.0663\n",
            "Epoch 298/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.8210 - mae: 0.6790 - val_loss: 9.4043 - val_mae: 2.1693\n",
            "Epoch 299/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.6029 - mae: 0.5537 - val_loss: 9.0170 - val_mae: 2.1743\n",
            "Epoch 300/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.4361 - mae: 0.4942 - val_loss: 9.3561 - val_mae: 2.1459\n",
            "processing fold # 1\n",
            "Epoch 1/300\n",
            "152/152 [==============================] - 2s 6ms/step - loss: 300.1981 - mae: 13.5179 - val_loss: 44.6076 - val_mae: 4.8097\n",
            "Epoch 2/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 25.7207 - mae: 3.6150 - val_loss: 25.5812 - val_mae: 3.6748\n",
            "Epoch 3/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 18.7636 - mae: 2.9962 - val_loss: 21.8841 - val_mae: 3.4741\n",
            "Epoch 4/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 15.7828 - mae: 2.7860 - val_loss: 19.8908 - val_mae: 3.3888\n",
            "Epoch 5/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 14.2401 - mae: 2.5664 - val_loss: 16.6809 - val_mae: 3.0822\n",
            "Epoch 6/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 12.7152 - mae: 2.5126 - val_loss: 13.2063 - val_mae: 2.7599\n",
            "Epoch 7/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 12.1420 - mae: 2.5113 - val_loss: 12.6089 - val_mae: 2.7120\n",
            "Epoch 8/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 13.4455 - mae: 2.6062 - val_loss: 13.2535 - val_mae: 2.7521\n",
            "Epoch 9/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 11.9264 - mae: 2.4333 - val_loss: 11.9289 - val_mae: 2.6254\n",
            "Epoch 10/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 11.0192 - mae: 2.4302 - val_loss: 11.9385 - val_mae: 2.6230\n",
            "Epoch 11/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 10.1350 - mae: 2.2357 - val_loss: 12.0886 - val_mae: 2.6794\n",
            "Epoch 12/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 10.5930 - mae: 2.3236 - val_loss: 12.5124 - val_mae: 2.7033\n",
            "Epoch 13/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 9.7493 - mae: 2.1948 - val_loss: 11.7624 - val_mae: 2.6124\n",
            "Epoch 14/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 8.7541 - mae: 2.1308 - val_loss: 12.2105 - val_mae: 2.7272\n",
            "Epoch 15/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 8.8711 - mae: 2.0844 - val_loss: 11.5200 - val_mae: 2.6258\n",
            "Epoch 16/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 8.4317 - mae: 1.9820 - val_loss: 10.9605 - val_mae: 2.5412\n",
            "Epoch 17/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 8.1574 - mae: 1.9501 - val_loss: 10.1551 - val_mae: 2.4152\n",
            "Epoch 18/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 7.7392 - mae: 1.9577 - val_loss: 13.4457 - val_mae: 2.7706\n",
            "Epoch 19/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 8.0411 - mae: 2.0082 - val_loss: 10.5158 - val_mae: 2.5709\n",
            "Epoch 20/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 8.5282 - mae: 2.0474 - val_loss: 9.4317 - val_mae: 2.2955\n",
            "Epoch 21/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 7.3895 - mae: 1.9187 - val_loss: 14.3908 - val_mae: 2.8834\n",
            "Epoch 22/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 8.1919 - mae: 2.0789 - val_loss: 11.7675 - val_mae: 2.6322\n",
            "Epoch 23/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 7.7930 - mae: 2.0085 - val_loss: 11.0827 - val_mae: 2.5841\n",
            "Epoch 24/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 7.4859 - mae: 1.8700 - val_loss: 10.8963 - val_mae: 2.5412\n",
            "Epoch 25/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 6.6404 - mae: 1.8234 - val_loss: 12.9473 - val_mae: 2.7764\n",
            "Epoch 26/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 7.0785 - mae: 1.8743 - val_loss: 11.0519 - val_mae: 2.6012\n",
            "Epoch 27/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 6.7821 - mae: 1.7509 - val_loss: 14.1965 - val_mae: 2.9336\n",
            "Epoch 28/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 7.2606 - mae: 1.9442 - val_loss: 9.1075 - val_mae: 2.3332\n",
            "Epoch 29/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 6.3379 - mae: 1.7758 - val_loss: 8.6937 - val_mae: 2.2665\n",
            "Epoch 30/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 6.7952 - mae: 1.8878 - val_loss: 9.3236 - val_mae: 2.3157\n",
            "Epoch 31/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 7.1345 - mae: 1.9081 - val_loss: 10.6677 - val_mae: 2.5160\n",
            "Epoch 32/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 5.4660 - mae: 1.7167 - val_loss: 10.4637 - val_mae: 2.4954\n",
            "Epoch 33/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 5.6176 - mae: 1.6023 - val_loss: 9.0902 - val_mae: 2.3356\n",
            "Epoch 34/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 5.7814 - mae: 1.7006 - val_loss: 9.0571 - val_mae: 2.2658\n",
            "Epoch 35/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 5.2985 - mae: 1.6800 - val_loss: 10.7208 - val_mae: 2.5734\n",
            "Epoch 36/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 4.9992 - mae: 1.6081 - val_loss: 11.3065 - val_mae: 2.6128\n",
            "Epoch 37/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 5.0794 - mae: 1.7010 - val_loss: 12.0632 - val_mae: 2.7321\n",
            "Epoch 38/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 4.7650 - mae: 1.5727 - val_loss: 13.1331 - val_mae: 2.7552\n",
            "Epoch 39/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 4.8827 - mae: 1.6273 - val_loss: 9.2489 - val_mae: 2.2736\n",
            "Epoch 40/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 4.4198 - mae: 1.5880 - val_loss: 8.1950 - val_mae: 2.1438\n",
            "Epoch 41/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 4.6165 - mae: 1.5747 - val_loss: 9.4764 - val_mae: 2.4003\n",
            "Epoch 42/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 4.3403 - mae: 1.5464 - val_loss: 16.8920 - val_mae: 3.2758\n",
            "Epoch 43/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 5.8496 - mae: 1.8765 - val_loss: 9.1880 - val_mae: 2.3068\n",
            "Epoch 44/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 3.6258 - mae: 1.4422 - val_loss: 12.4806 - val_mae: 2.7269\n",
            "Epoch 45/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 7.6132 - mae: 2.0201 - val_loss: 11.8076 - val_mae: 2.6705\n",
            "Epoch 46/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 3.5807 - mae: 1.4165 - val_loss: 8.6169 - val_mae: 2.3216\n",
            "Epoch 47/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 3.4995 - mae: 1.4163 - val_loss: 13.4146 - val_mae: 2.9120\n",
            "Epoch 48/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 3.9347 - mae: 1.4618 - val_loss: 14.3280 - val_mae: 2.7844\n",
            "Epoch 49/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 3.6188 - mae: 1.4365 - val_loss: 7.9820 - val_mae: 2.1231\n",
            "Epoch 50/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 3.4508 - mae: 1.3556 - val_loss: 8.8149 - val_mae: 2.2786\n",
            "Epoch 51/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 3.4529 - mae: 1.3722 - val_loss: 7.9453 - val_mae: 2.1727\n",
            "Epoch 52/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 2.9524 - mae: 1.2744 - val_loss: 8.6839 - val_mae: 2.2271\n",
            "Epoch 53/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 3.5466 - mae: 1.4514 - val_loss: 8.7505 - val_mae: 2.2477\n",
            "Epoch 54/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 3.4845 - mae: 1.3981 - val_loss: 17.8965 - val_mae: 3.3253\n",
            "Epoch 55/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 3.2459 - mae: 1.3656 - val_loss: 9.3719 - val_mae: 2.3436\n",
            "Epoch 56/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 3.1256 - mae: 1.2672 - val_loss: 11.3403 - val_mae: 2.5538\n",
            "Epoch 57/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.8973 - mae: 1.3421 - val_loss: 8.5670 - val_mae: 2.2539\n",
            "Epoch 58/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 3.2705 - mae: 1.3692 - val_loss: 7.6625 - val_mae: 2.1202\n",
            "Epoch 59/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 3.9386 - mae: 1.5061 - val_loss: 10.8004 - val_mae: 2.4947\n",
            "Epoch 60/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 3.1164 - mae: 1.3208 - val_loss: 8.5977 - val_mae: 2.2135\n",
            "Epoch 61/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 2.9089 - mae: 1.3031 - val_loss: 10.2409 - val_mae: 2.5301\n",
            "Epoch 62/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.5171 - mae: 1.1669 - val_loss: 11.2489 - val_mae: 2.5725\n",
            "Epoch 63/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.7936 - mae: 1.2998 - val_loss: 9.0799 - val_mae: 2.2559\n",
            "Epoch 64/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 3.1134 - mae: 1.3483 - val_loss: 8.9783 - val_mae: 2.2873\n",
            "Epoch 65/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.6079 - mae: 1.2413 - val_loss: 10.1664 - val_mae: 2.4894\n",
            "Epoch 66/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 3.0317 - mae: 1.2994 - val_loss: 9.8062 - val_mae: 2.3447\n",
            "Epoch 67/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.4018 - mae: 1.1606 - val_loss: 8.9648 - val_mae: 2.2680\n",
            "Epoch 68/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.3252 - mae: 1.1632 - val_loss: 10.2856 - val_mae: 2.4126\n",
            "Epoch 69/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.1283 - mae: 1.0888 - val_loss: 9.7474 - val_mae: 2.3865\n",
            "Epoch 70/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 3.2504 - mae: 1.3802 - val_loss: 9.5291 - val_mae: 2.4051\n",
            "Epoch 71/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 3.6131 - mae: 1.3911 - val_loss: 11.7660 - val_mae: 2.6594\n",
            "Epoch 72/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.5225 - mae: 1.1755 - val_loss: 9.9090 - val_mae: 2.3720\n",
            "Epoch 73/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.5085 - mae: 1.1904 - val_loss: 18.6469 - val_mae: 3.3825\n",
            "Epoch 74/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.7107 - mae: 1.2240 - val_loss: 8.5185 - val_mae: 2.1672\n",
            "Epoch 75/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.3409 - mae: 1.1579 - val_loss: 12.4492 - val_mae: 2.7127\n",
            "Epoch 76/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.2549 - mae: 1.1226 - val_loss: 7.7101 - val_mae: 2.0899\n",
            "Epoch 77/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.1363 - mae: 1.0976 - val_loss: 10.1697 - val_mae: 2.4093\n",
            "Epoch 78/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.8485 - mae: 1.0272 - val_loss: 7.8475 - val_mae: 2.0764\n",
            "Epoch 79/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 2.0533 - mae: 1.0889 - val_loss: 8.8872 - val_mae: 2.2256\n",
            "Epoch 80/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 2.1416 - mae: 1.1238 - val_loss: 9.5739 - val_mae: 2.3726\n",
            "Epoch 81/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.8559 - mae: 1.0168 - val_loss: 11.8334 - val_mae: 2.5701\n",
            "Epoch 82/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 2.3705 - mae: 1.1432 - val_loss: 10.5400 - val_mae: 2.4257\n",
            "Epoch 83/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 2.0346 - mae: 1.0659 - val_loss: 12.0756 - val_mae: 2.6490\n",
            "Epoch 84/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.8868 - mae: 1.2537 - val_loss: 10.5288 - val_mae: 2.3609\n",
            "Epoch 85/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.6790 - mae: 1.2656 - val_loss: 9.3670 - val_mae: 2.2532\n",
            "Epoch 86/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.1222 - mae: 1.1061 - val_loss: 9.2883 - val_mae: 2.2701\n",
            "Epoch 87/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.9635 - mae: 1.0456 - val_loss: 10.5154 - val_mae: 2.5173\n",
            "Epoch 88/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.8676 - mae: 1.0152 - val_loss: 9.9746 - val_mae: 2.3888\n",
            "Epoch 89/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.9121 - mae: 1.0739 - val_loss: 11.3899 - val_mae: 2.3992\n",
            "Epoch 90/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 2.0767 - mae: 1.0543 - val_loss: 9.5172 - val_mae: 2.3479\n",
            "Epoch 91/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 2.0818 - mae: 1.0296 - val_loss: 10.3291 - val_mae: 2.3237\n",
            "Epoch 92/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.7043 - mae: 0.9726 - val_loss: 9.6126 - val_mae: 2.3908\n",
            "Epoch 93/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.5850 - mae: 0.9586 - val_loss: 9.3293 - val_mae: 2.3067\n",
            "Epoch 94/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.7497 - mae: 1.0212 - val_loss: 9.4255 - val_mae: 2.2677\n",
            "Epoch 95/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.8846 - mae: 1.0129 - val_loss: 8.1047 - val_mae: 2.0825\n",
            "Epoch 96/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.9259 - mae: 1.0424 - val_loss: 10.8655 - val_mae: 2.4372\n",
            "Epoch 97/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.8157 - mae: 0.9999 - val_loss: 9.7937 - val_mae: 2.3719\n",
            "Epoch 98/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.1632 - mae: 1.1218 - val_loss: 12.3644 - val_mae: 2.6902\n",
            "Epoch 99/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.6552 - mae: 0.9706 - val_loss: 11.5270 - val_mae: 2.5816\n",
            "Epoch 100/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.6015 - mae: 1.1434 - val_loss: 10.6313 - val_mae: 2.4538\n",
            "Epoch 101/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.2444 - mae: 1.1434 - val_loss: 12.0039 - val_mae: 2.4924\n",
            "Epoch 102/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.6072 - mae: 1.1758 - val_loss: 9.8992 - val_mae: 2.2984\n",
            "Epoch 103/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.1149 - mae: 1.0711 - val_loss: 16.1743 - val_mae: 3.1663\n",
            "Epoch 104/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 2.2391 - mae: 1.0911 - val_loss: 10.2737 - val_mae: 2.4126\n",
            "Epoch 105/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.6745 - mae: 0.9747 - val_loss: 11.4033 - val_mae: 2.5479\n",
            "Epoch 106/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.8715 - mae: 1.0019 - val_loss: 11.3307 - val_mae: 2.4360\n",
            "Epoch 107/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.4763 - mae: 0.8895 - val_loss: 11.8552 - val_mae: 2.4995\n",
            "Epoch 108/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.5459 - mae: 0.9151 - val_loss: 14.1663 - val_mae: 2.8661\n",
            "Epoch 109/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.5359 - mae: 0.9724 - val_loss: 11.2308 - val_mae: 2.5933\n",
            "Epoch 110/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.3097 - mae: 1.0513 - val_loss: 9.2212 - val_mae: 2.1833\n",
            "Epoch 111/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.0761 - mae: 1.1169 - val_loss: 10.3000 - val_mae: 2.4259\n",
            "Epoch 112/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.9190 - mae: 1.0433 - val_loss: 9.9759 - val_mae: 2.2935\n",
            "Epoch 113/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.9187 - mae: 1.0535 - val_loss: 12.6570 - val_mae: 2.7222\n",
            "Epoch 114/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.7457 - mae: 0.9513 - val_loss: 9.8481 - val_mae: 2.3599\n",
            "Epoch 115/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.7330 - mae: 0.9732 - val_loss: 11.7664 - val_mae: 2.5992\n",
            "Epoch 116/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.6939 - mae: 0.9288 - val_loss: 10.9136 - val_mae: 2.4866\n",
            "Epoch 117/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.6405 - mae: 0.9194 - val_loss: 11.4466 - val_mae: 2.5795\n",
            "Epoch 118/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.6364 - mae: 0.9370 - val_loss: 14.6108 - val_mae: 2.9006\n",
            "Epoch 119/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.5940 - mae: 0.9309 - val_loss: 11.6145 - val_mae: 2.5674\n",
            "Epoch 120/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.5225 - mae: 0.8944 - val_loss: 10.9541 - val_mae: 2.4979\n",
            "Epoch 121/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.3730 - mae: 0.8468 - val_loss: 10.0232 - val_mae: 2.3236\n",
            "Epoch 122/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.5107 - mae: 0.9043 - val_loss: 9.5240 - val_mae: 2.2850\n",
            "Epoch 123/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.3216 - mae: 0.8783 - val_loss: 12.7677 - val_mae: 2.7234\n",
            "Epoch 124/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.3249 - mae: 0.8459 - val_loss: 10.0261 - val_mae: 2.3843\n",
            "Epoch 125/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.8086 - mae: 0.9936 - val_loss: 13.0397 - val_mae: 2.7660\n",
            "Epoch 126/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.9976 - mae: 0.9705 - val_loss: 9.2532 - val_mae: 2.2691\n",
            "Epoch 127/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.5515 - mae: 0.9130 - val_loss: 10.0085 - val_mae: 2.2939\n",
            "Epoch 128/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.5391 - mae: 0.8796 - val_loss: 16.0192 - val_mae: 2.9889\n",
            "Epoch 129/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.0393 - mae: 1.0440 - val_loss: 9.8966 - val_mae: 2.3941\n",
            "Epoch 130/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.6798 - mae: 0.9571 - val_loss: 13.8713 - val_mae: 2.8583\n",
            "Epoch 131/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.3008 - mae: 0.8401 - val_loss: 11.6140 - val_mae: 2.5766\n",
            "Epoch 132/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.2441 - mae: 0.8107 - val_loss: 10.3446 - val_mae: 2.3593\n",
            "Epoch 133/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.4255 - mae: 0.8874 - val_loss: 10.6344 - val_mae: 2.4262\n",
            "Epoch 134/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.4425 - mae: 0.8854 - val_loss: 11.1153 - val_mae: 2.5489\n",
            "Epoch 135/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.6226 - mae: 0.9399 - val_loss: 9.5383 - val_mae: 2.3609\n",
            "Epoch 136/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.2407 - mae: 0.8095 - val_loss: 10.5243 - val_mae: 2.4097\n",
            "Epoch 137/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.2548 - mae: 0.8470 - val_loss: 11.6944 - val_mae: 2.6230\n",
            "Epoch 138/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.1753 - mae: 0.7938 - val_loss: 8.3380 - val_mae: 2.1036\n",
            "Epoch 139/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.1901 - mae: 0.8283 - val_loss: 12.1810 - val_mae: 2.7254\n",
            "Epoch 140/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.8913 - mae: 0.9792 - val_loss: 11.8199 - val_mae: 2.7050\n",
            "Epoch 141/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.7894 - mae: 1.0221 - val_loss: 10.3477 - val_mae: 2.3913\n",
            "Epoch 142/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.5781 - mae: 0.9487 - val_loss: 12.1340 - val_mae: 2.5699\n",
            "Epoch 143/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.0493 - mae: 1.0111 - val_loss: 12.0322 - val_mae: 2.7462\n",
            "Epoch 144/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.6743 - mae: 0.9379 - val_loss: 11.0167 - val_mae: 2.5274\n",
            "Epoch 145/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.9477 - mae: 1.0220 - val_loss: 9.5855 - val_mae: 2.3424\n",
            "Epoch 146/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.3704 - mae: 0.8737 - val_loss: 9.6433 - val_mae: 2.2835\n",
            "Epoch 147/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.3383 - mae: 0.8563 - val_loss: 9.1017 - val_mae: 2.2532\n",
            "Epoch 148/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.5936 - mae: 0.9128 - val_loss: 10.5089 - val_mae: 2.4186\n",
            "Epoch 149/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.6182 - mae: 0.9474 - val_loss: 10.8266 - val_mae: 2.4944\n",
            "Epoch 150/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.2946 - mae: 0.8289 - val_loss: 13.3431 - val_mae: 2.7854\n",
            "Epoch 151/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.5299 - mae: 0.9305 - val_loss: 12.9147 - val_mae: 2.6680\n",
            "Epoch 152/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.8448 - mae: 0.9890 - val_loss: 8.4190 - val_mae: 2.1516\n",
            "Epoch 153/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.6828 - mae: 0.9437 - val_loss: 11.6520 - val_mae: 2.6039\n",
            "Epoch 154/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.9135 - mae: 0.9556 - val_loss: 11.1898 - val_mae: 2.4534\n",
            "Epoch 155/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.3391 - mae: 0.8521 - val_loss: 11.9495 - val_mae: 2.6570\n",
            "Epoch 156/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.3948 - mae: 0.8440 - val_loss: 11.0078 - val_mae: 2.5278\n",
            "Epoch 157/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.1060 - mae: 0.7695 - val_loss: 10.4887 - val_mae: 2.4359\n",
            "Epoch 158/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.2226 - mae: 0.8304 - val_loss: 11.9631 - val_mae: 2.6649\n",
            "Epoch 159/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.2375 - mae: 0.8422 - val_loss: 11.8453 - val_mae: 2.6539\n",
            "Epoch 160/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.1380 - mae: 0.7961 - val_loss: 9.5390 - val_mae: 2.3178\n",
            "Epoch 161/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.4591 - mae: 0.8702 - val_loss: 10.0628 - val_mae: 2.4119\n",
            "Epoch 162/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.1236 - mae: 0.7703 - val_loss: 12.6712 - val_mae: 2.6693\n",
            "Epoch 163/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.4135 - mae: 0.8763 - val_loss: 10.8643 - val_mae: 2.5001\n",
            "Epoch 164/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.3375 - mae: 0.8537 - val_loss: 11.1099 - val_mae: 2.4348\n",
            "Epoch 165/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.1615 - mae: 0.8016 - val_loss: 11.0513 - val_mae: 2.5739\n",
            "Epoch 166/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.9278 - mae: 0.6938 - val_loss: 9.9392 - val_mae: 2.4262\n",
            "Epoch 167/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.0498 - mae: 0.7859 - val_loss: 13.3926 - val_mae: 2.8065\n",
            "Epoch 168/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.1044 - mae: 0.7788 - val_loss: 11.2534 - val_mae: 2.4784\n",
            "Epoch 169/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.5943 - mae: 0.8856 - val_loss: 8.9201 - val_mae: 2.1700\n",
            "Epoch 170/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.5451 - mae: 0.8995 - val_loss: 14.0779 - val_mae: 2.8784\n",
            "Epoch 171/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.1873 - mae: 0.8196 - val_loss: 11.7999 - val_mae: 2.6055\n",
            "Epoch 172/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.4495 - mae: 0.8541 - val_loss: 11.8876 - val_mae: 2.5629\n",
            "Epoch 173/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.0944 - mae: 0.7329 - val_loss: 9.4482 - val_mae: 2.2711\n",
            "Epoch 174/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.1750 - mae: 0.8097 - val_loss: 10.0030 - val_mae: 2.2900\n",
            "Epoch 175/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.6917 - mae: 0.9480 - val_loss: 11.6932 - val_mae: 2.6009\n",
            "Epoch 176/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.7141 - mae: 0.9992 - val_loss: 9.3251 - val_mae: 2.3090\n",
            "Epoch 177/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.3121 - mae: 0.8250 - val_loss: 12.4175 - val_mae: 2.6806\n",
            "Epoch 178/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.6641 - mae: 0.8697 - val_loss: 11.0964 - val_mae: 2.5682\n",
            "Epoch 179/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.3807 - mae: 1.0528 - val_loss: 8.6485 - val_mae: 2.2053\n",
            "Epoch 180/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.1943 - mae: 0.7680 - val_loss: 10.4978 - val_mae: 2.4831\n",
            "Epoch 181/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.8588 - mae: 0.6771 - val_loss: 11.1801 - val_mae: 2.5072\n",
            "Epoch 182/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.9518 - mae: 0.6960 - val_loss: 11.7959 - val_mae: 2.6792\n",
            "Epoch 183/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.0013 - mae: 0.7208 - val_loss: 9.9860 - val_mae: 2.3907\n",
            "Epoch 184/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.8051 - mae: 0.6675 - val_loss: 9.7564 - val_mae: 2.3048\n",
            "Epoch 185/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.0012 - mae: 0.7118 - val_loss: 10.9588 - val_mae: 2.5102\n",
            "Epoch 186/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.1839 - mae: 0.8213 - val_loss: 11.9959 - val_mae: 2.6807\n",
            "Epoch 187/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.1936 - mae: 0.8032 - val_loss: 10.1262 - val_mae: 2.3777\n",
            "Epoch 188/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.8875 - mae: 0.6906 - val_loss: 12.8284 - val_mae: 2.5774\n",
            "Epoch 189/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.2594 - mae: 0.8303 - val_loss: 9.6659 - val_mae: 2.2742\n",
            "Epoch 190/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.2794 - mae: 0.7850 - val_loss: 8.9494 - val_mae: 2.1942\n",
            "Epoch 191/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.0462 - mae: 0.7421 - val_loss: 10.5652 - val_mae: 2.4875\n",
            "Epoch 192/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.7569 - mae: 0.9524 - val_loss: 11.9447 - val_mae: 2.4900\n",
            "Epoch 193/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.7721 - mae: 0.9841 - val_loss: 9.4879 - val_mae: 2.3096\n",
            "Epoch 194/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.4195 - mae: 0.9108 - val_loss: 10.0368 - val_mae: 2.4255\n",
            "Epoch 195/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.1642 - mae: 0.7502 - val_loss: 10.6911 - val_mae: 2.4999\n",
            "Epoch 196/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 0.7785 - mae: 0.6511 - val_loss: 10.6012 - val_mae: 2.5092\n",
            "Epoch 197/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.8740 - mae: 0.6785 - val_loss: 10.2707 - val_mae: 2.3511\n",
            "Epoch 198/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 0.9984 - mae: 0.7217 - val_loss: 13.2718 - val_mae: 2.7720\n",
            "Epoch 199/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.1044 - mae: 0.7813 - val_loss: 10.4096 - val_mae: 2.3160\n",
            "Epoch 200/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.2340 - mae: 0.7902 - val_loss: 12.9819 - val_mae: 2.7872\n",
            "Epoch 201/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.1275 - mae: 0.8130 - val_loss: 10.0496 - val_mae: 2.3768\n",
            "Epoch 202/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.3792 - mae: 0.8542 - val_loss: 10.9314 - val_mae: 2.5352\n",
            "Epoch 203/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.0016 - mae: 0.7368 - val_loss: 9.7616 - val_mae: 2.3339\n",
            "Epoch 204/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.3724 - mae: 0.8439 - val_loss: 9.5595 - val_mae: 2.3338\n",
            "Epoch 205/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.5779 - mae: 0.9180 - val_loss: 9.3389 - val_mae: 2.2178\n",
            "Epoch 206/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.9495 - mae: 0.7401 - val_loss: 13.3324 - val_mae: 2.8591\n",
            "Epoch 207/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.8567 - mae: 0.6791 - val_loss: 9.2934 - val_mae: 2.2801\n",
            "Epoch 208/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.9253 - mae: 0.7225 - val_loss: 9.8022 - val_mae: 2.3513\n",
            "Epoch 209/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.8513 - mae: 0.6901 - val_loss: 9.6712 - val_mae: 2.3607\n",
            "Epoch 210/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.0197 - mae: 0.7574 - val_loss: 12.2350 - val_mae: 2.7479\n",
            "Epoch 211/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.0619 - mae: 0.7361 - val_loss: 8.9333 - val_mae: 2.2443\n",
            "Epoch 212/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.4287 - mae: 0.8513 - val_loss: 9.6923 - val_mae: 2.2750\n",
            "Epoch 213/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.0329 - mae: 0.7443 - val_loss: 10.8480 - val_mae: 2.5054\n",
            "Epoch 214/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.6394 - mae: 0.5890 - val_loss: 10.9926 - val_mae: 2.5606\n",
            "Epoch 215/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.9279 - mae: 0.7026 - val_loss: 11.5915 - val_mae: 2.6320\n",
            "Epoch 216/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.8037 - mae: 0.6565 - val_loss: 11.5586 - val_mae: 2.5463\n",
            "Epoch 217/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.4812 - mae: 0.8649 - val_loss: 8.8784 - val_mae: 2.2209\n",
            "Epoch 218/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.1279 - mae: 0.7933 - val_loss: 10.2501 - val_mae: 2.4669\n",
            "Epoch 219/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.1230 - mae: 0.7943 - val_loss: 9.8578 - val_mae: 2.3469\n",
            "Epoch 220/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.2750 - mae: 0.7805 - val_loss: 10.7683 - val_mae: 2.4450\n",
            "Epoch 221/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.3400 - mae: 0.9918 - val_loss: 9.4085 - val_mae: 2.3209\n",
            "Epoch 222/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.3988 - mae: 0.8419 - val_loss: 8.6950 - val_mae: 2.1649\n",
            "Epoch 223/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.4900 - mae: 0.7760 - val_loss: 12.0416 - val_mae: 2.4940\n",
            "Epoch 224/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.8911 - mae: 0.9040 - val_loss: 11.2581 - val_mae: 2.6042\n",
            "Epoch 225/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.7789 - mae: 0.6408 - val_loss: 9.5734 - val_mae: 2.2997\n",
            "Epoch 226/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.7678 - mae: 0.6299 - val_loss: 10.7987 - val_mae: 2.5277\n",
            "Epoch 227/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.7023 - mae: 0.6150 - val_loss: 10.2631 - val_mae: 2.3733\n",
            "Epoch 228/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.6698 - mae: 0.6002 - val_loss: 9.5017 - val_mae: 2.3776\n",
            "Epoch 229/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.8847 - mae: 0.6971 - val_loss: 10.5452 - val_mae: 2.4320\n",
            "Epoch 230/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.1899 - mae: 0.7566 - val_loss: 9.1153 - val_mae: 2.2484\n",
            "Epoch 231/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.2643 - mae: 0.7964 - val_loss: 9.8756 - val_mae: 2.3603\n",
            "Epoch 232/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.7757 - mae: 0.6604 - val_loss: 10.1467 - val_mae: 2.4148\n",
            "Epoch 233/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.9669 - mae: 0.7164 - val_loss: 14.7668 - val_mae: 2.9882\n",
            "Epoch 234/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.0221 - mae: 0.7459 - val_loss: 9.8871 - val_mae: 2.3593\n",
            "Epoch 235/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.7871 - mae: 0.6666 - val_loss: 10.1071 - val_mae: 2.3897\n",
            "Epoch 236/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.7365 - mae: 0.6409 - val_loss: 13.4530 - val_mae: 2.8035\n",
            "Epoch 237/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.2428 - mae: 0.7972 - val_loss: 8.6335 - val_mae: 2.1642\n",
            "Epoch 238/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.4956 - mae: 0.8688 - val_loss: 11.7959 - val_mae: 2.6112\n",
            "Epoch 239/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.7957 - mae: 0.6510 - val_loss: 9.8935 - val_mae: 2.3830\n",
            "Epoch 240/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.6327 - mae: 0.5886 - val_loss: 12.1467 - val_mae: 2.6643\n",
            "Epoch 241/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.7777 - mae: 0.6400 - val_loss: 10.2574 - val_mae: 2.4578\n",
            "Epoch 242/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.1956 - mae: 0.8333 - val_loss: 11.8197 - val_mae: 2.6065\n",
            "Epoch 243/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.7944 - mae: 0.6832 - val_loss: 9.6552 - val_mae: 2.3343\n",
            "Epoch 244/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 0.6418 - mae: 0.5964 - val_loss: 10.7617 - val_mae: 2.5307\n",
            "Epoch 245/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.6489 - mae: 0.5780 - val_loss: 12.2476 - val_mae: 2.6483\n",
            "Epoch 246/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 0.8331 - mae: 0.6442 - val_loss: 9.9929 - val_mae: 2.4160\n",
            "Epoch 247/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.7017 - mae: 0.6155 - val_loss: 11.5714 - val_mae: 2.5482\n",
            "Epoch 248/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.2362 - mae: 0.7880 - val_loss: 11.8100 - val_mae: 2.6768\n",
            "Epoch 249/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.0759 - mae: 0.7564 - val_loss: 12.6183 - val_mae: 2.7188\n",
            "Epoch 250/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.9343 - mae: 0.7142 - val_loss: 11.1188 - val_mae: 2.5120\n",
            "Epoch 251/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.4256 - mae: 1.0912 - val_loss: 11.6161 - val_mae: 2.6192\n",
            "Epoch 252/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.8672 - mae: 0.6716 - val_loss: 11.2547 - val_mae: 2.5016\n",
            "Epoch 253/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.8230 - mae: 0.6646 - val_loss: 11.7537 - val_mae: 2.6148\n",
            "Epoch 254/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.7590 - mae: 0.6460 - val_loss: 11.4715 - val_mae: 2.5552\n",
            "Epoch 255/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.8003 - mae: 0.6492 - val_loss: 13.2089 - val_mae: 2.8201\n",
            "Epoch 256/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.6344 - mae: 0.5875 - val_loss: 11.5642 - val_mae: 2.5571\n",
            "Epoch 257/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.8049 - mae: 0.6407 - val_loss: 10.2192 - val_mae: 2.4420\n",
            "Epoch 258/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.8182 - mae: 0.6205 - val_loss: 10.9123 - val_mae: 2.4124\n",
            "Epoch 259/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.0963 - mae: 0.7368 - val_loss: 9.6561 - val_mae: 2.3623\n",
            "Epoch 260/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.2291 - mae: 0.8198 - val_loss: 10.6853 - val_mae: 2.3943\n",
            "Epoch 261/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.9649 - mae: 0.7441 - val_loss: 10.0601 - val_mae: 2.3859\n",
            "Epoch 262/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.3704 - mae: 0.8772 - val_loss: 11.3234 - val_mae: 2.5221\n",
            "Epoch 263/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.1413 - mae: 0.7195 - val_loss: 10.2361 - val_mae: 2.3640\n",
            "Epoch 264/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.1418 - mae: 0.7342 - val_loss: 10.7205 - val_mae: 2.4270\n",
            "Epoch 265/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.7488 - mae: 0.6280 - val_loss: 11.8595 - val_mae: 2.6458\n",
            "Epoch 266/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.7369 - mae: 0.6210 - val_loss: 11.7375 - val_mae: 2.6347\n",
            "Epoch 267/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.6307 - mae: 0.5876 - val_loss: 10.9668 - val_mae: 2.4987\n",
            "Epoch 268/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.9161 - mae: 0.7064 - val_loss: 9.3358 - val_mae: 2.2388\n",
            "Epoch 269/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.2232 - mae: 0.8027 - val_loss: 10.5382 - val_mae: 2.4969\n",
            "Epoch 270/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.7929 - mae: 0.6410 - val_loss: 10.1819 - val_mae: 2.4535\n",
            "Epoch 271/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.6766 - mae: 0.5877 - val_loss: 10.7438 - val_mae: 2.4871\n",
            "Epoch 272/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.7835 - mae: 0.6569 - val_loss: 10.4897 - val_mae: 2.4241\n",
            "Epoch 273/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.8254 - mae: 0.6216 - val_loss: 13.8818 - val_mae: 2.9402\n",
            "Epoch 274/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.0560 - mae: 0.7190 - val_loss: 11.4088 - val_mae: 2.6097\n",
            "Epoch 275/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.6270 - mae: 0.5530 - val_loss: 11.4365 - val_mae: 2.6143\n",
            "Epoch 276/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.6354 - mae: 0.5833 - val_loss: 10.7188 - val_mae: 2.4866\n",
            "Epoch 277/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.9947 - mae: 0.7097 - val_loss: 13.5196 - val_mae: 2.8399\n",
            "Epoch 278/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.6927 - mae: 0.6196 - val_loss: 10.0328 - val_mae: 2.3483\n",
            "Epoch 279/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.5594 - mae: 0.5324 - val_loss: 11.9276 - val_mae: 2.6740\n",
            "Epoch 280/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.9343 - mae: 0.6974 - val_loss: 9.8273 - val_mae: 2.3619\n",
            "Epoch 281/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.3612 - mae: 0.7999 - val_loss: 11.8772 - val_mae: 2.5834\n",
            "Epoch 282/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.3369 - mae: 0.7863 - val_loss: 10.1018 - val_mae: 2.3917\n",
            "Epoch 283/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.7340 - mae: 0.6381 - val_loss: 9.1995 - val_mae: 2.2806\n",
            "Epoch 284/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.6979 - mae: 0.6033 - val_loss: 12.4947 - val_mae: 2.7124\n",
            "Epoch 285/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.5117 - mae: 0.5266 - val_loss: 9.7893 - val_mae: 2.3655\n",
            "Epoch 286/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.9121 - mae: 0.6987 - val_loss: 11.2320 - val_mae: 2.4601\n",
            "Epoch 287/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.4101 - mae: 0.8965 - val_loss: 9.8850 - val_mae: 2.4091\n",
            "Epoch 288/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.9278 - mae: 0.6782 - val_loss: 11.9148 - val_mae: 2.6361\n",
            "Epoch 289/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.6604 - mae: 0.5823 - val_loss: 9.6980 - val_mae: 2.3500\n",
            "Epoch 290/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.8934 - mae: 0.6676 - val_loss: 11.0768 - val_mae: 2.4941\n",
            "Epoch 291/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.6895 - mae: 0.5954 - val_loss: 10.6900 - val_mae: 2.4543\n",
            "Epoch 292/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.4227 - mae: 0.4586 - val_loss: 12.1251 - val_mae: 2.6729\n",
            "Epoch 293/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.5348 - mae: 0.5108 - val_loss: 11.0411 - val_mae: 2.4579\n",
            "Epoch 294/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.5608 - mae: 0.5356 - val_loss: 11.2814 - val_mae: 2.5860\n",
            "Epoch 295/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.4981 - mae: 0.4997 - val_loss: 10.2073 - val_mae: 2.4311\n",
            "Epoch 296/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.6211 - mae: 0.5425 - val_loss: 9.0479 - val_mae: 2.2554\n",
            "Epoch 297/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.0488 - mae: 0.7567 - val_loss: 11.3637 - val_mae: 2.6044\n",
            "Epoch 298/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.2872 - mae: 0.8373 - val_loss: 11.5308 - val_mae: 2.5345\n",
            "Epoch 299/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.2024 - mae: 0.7765 - val_loss: 10.8213 - val_mae: 2.4559\n",
            "Epoch 300/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.5107 - mae: 0.5152 - val_loss: 10.4794 - val_mae: 2.4551\n",
            "processing fold # 2\n",
            "Epoch 1/300\n",
            "152/152 [==============================] - 2s 4ms/step - loss: 281.6861 - mae: 12.8953 - val_loss: 28.4216 - val_mae: 3.7316\n",
            "Epoch 2/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 26.4187 - mae: 3.5539 - val_loss: 20.2135 - val_mae: 2.8839\n",
            "Epoch 3/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 16.6149 - mae: 2.8696 - val_loss: 16.5538 - val_mae: 2.6587\n",
            "Epoch 4/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 13.1629 - mae: 2.6893 - val_loss: 17.5428 - val_mae: 2.6610\n",
            "Epoch 5/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 11.5532 - mae: 2.4950 - val_loss: 16.2893 - val_mae: 2.6277\n",
            "Epoch 6/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 10.4477 - mae: 2.3800 - val_loss: 15.7369 - val_mae: 2.5899\n",
            "Epoch 7/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 10.0801 - mae: 2.3397 - val_loss: 16.2031 - val_mae: 2.6946\n",
            "Epoch 8/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 10.1093 - mae: 2.3641 - val_loss: 18.4786 - val_mae: 3.0945\n",
            "Epoch 9/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 8.9204 - mae: 2.2549 - val_loss: 15.1238 - val_mae: 2.6599\n",
            "Epoch 10/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 8.4243 - mae: 2.1750 - val_loss: 15.8484 - val_mae: 2.6666\n",
            "Epoch 11/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 7.9256 - mae: 2.0686 - val_loss: 17.7230 - val_mae: 3.0574\n",
            "Epoch 12/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 8.1701 - mae: 2.2313 - val_loss: 16.4333 - val_mae: 2.6975\n",
            "Epoch 13/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 7.9720 - mae: 2.0315 - val_loss: 17.5562 - val_mae: 3.0000\n",
            "Epoch 14/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 7.3612 - mae: 2.0503 - val_loss: 17.2543 - val_mae: 2.9520\n",
            "Epoch 15/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 7.2491 - mae: 1.9883 - val_loss: 14.2323 - val_mae: 2.5592\n",
            "Epoch 16/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 7.5786 - mae: 2.0196 - val_loss: 13.9143 - val_mae: 2.5417\n",
            "Epoch 17/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 6.6535 - mae: 1.9499 - val_loss: 14.3560 - val_mae: 2.6368\n",
            "Epoch 18/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 6.2719 - mae: 1.8082 - val_loss: 15.4187 - val_mae: 2.7675\n",
            "Epoch 19/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 6.0740 - mae: 1.8391 - val_loss: 16.4116 - val_mae: 2.6783\n",
            "Epoch 20/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 5.9698 - mae: 1.8737 - val_loss: 13.9711 - val_mae: 2.4670\n",
            "Epoch 21/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 5.8770 - mae: 1.7805 - val_loss: 14.5943 - val_mae: 2.5738\n",
            "Epoch 22/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 5.6622 - mae: 1.7839 - val_loss: 13.9866 - val_mae: 2.5296\n",
            "Epoch 23/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 4.9972 - mae: 1.7182 - val_loss: 16.7479 - val_mae: 2.8381\n",
            "Epoch 24/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 5.8578 - mae: 1.8117 - val_loss: 14.0566 - val_mae: 2.5333\n",
            "Epoch 25/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 4.6704 - mae: 1.6331 - val_loss: 14.1553 - val_mae: 2.6021\n",
            "Epoch 26/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 4.6082 - mae: 1.6590 - val_loss: 14.9229 - val_mae: 2.6873\n",
            "Epoch 27/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 4.9353 - mae: 1.7067 - val_loss: 18.1620 - val_mae: 2.9502\n",
            "Epoch 28/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 5.2185 - mae: 1.6876 - val_loss: 13.7172 - val_mae: 2.4197\n",
            "Epoch 29/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 4.4490 - mae: 1.5904 - val_loss: 14.9773 - val_mae: 2.5876\n",
            "Epoch 30/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 5.0070 - mae: 1.6962 - val_loss: 13.7744 - val_mae: 2.4763\n",
            "Epoch 31/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 4.5067 - mae: 1.5831 - val_loss: 13.7726 - val_mae: 2.4703\n",
            "Epoch 32/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 4.3976 - mae: 1.6081 - val_loss: 14.7257 - val_mae: 2.6083\n",
            "Epoch 33/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 4.0638 - mae: 1.5190 - val_loss: 18.2815 - val_mae: 3.2139\n",
            "Epoch 34/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 4.1672 - mae: 1.5280 - val_loss: 13.9893 - val_mae: 2.5407\n",
            "Epoch 35/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 4.3736 - mae: 1.5939 - val_loss: 13.1328 - val_mae: 2.4018\n",
            "Epoch 36/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 3.4296 - mae: 1.3993 - val_loss: 13.2800 - val_mae: 2.4467\n",
            "Epoch 37/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 3.8273 - mae: 1.4625 - val_loss: 13.4665 - val_mae: 2.5619\n",
            "Epoch 38/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 4.1661 - mae: 1.5300 - val_loss: 12.3155 - val_mae: 2.3429\n",
            "Epoch 39/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 3.6461 - mae: 1.4501 - val_loss: 13.6712 - val_mae: 2.4488\n",
            "Epoch 40/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 4.1917 - mae: 1.5463 - val_loss: 13.1322 - val_mae: 2.4319\n",
            "Epoch 41/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 3.0403 - mae: 1.3489 - val_loss: 14.1640 - val_mae: 2.5759\n",
            "Epoch 42/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 4.2435 - mae: 1.5203 - val_loss: 14.0969 - val_mae: 2.5278\n",
            "Epoch 43/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 3.5549 - mae: 1.4062 - val_loss: 14.5119 - val_mae: 2.5824\n",
            "Epoch 44/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 3.1322 - mae: 1.3468 - val_loss: 12.6755 - val_mae: 2.3863\n",
            "Epoch 45/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.9362 - mae: 1.3040 - val_loss: 13.8938 - val_mae: 2.5241\n",
            "Epoch 46/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 3.2034 - mae: 1.3414 - val_loss: 15.4608 - val_mae: 2.8497\n",
            "Epoch 47/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.7800 - mae: 1.2849 - val_loss: 12.7061 - val_mae: 2.4610\n",
            "Epoch 48/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 3.0627 - mae: 1.3379 - val_loss: 13.7321 - val_mae: 2.5446\n",
            "Epoch 49/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 3.0649 - mae: 1.2626 - val_loss: 12.6328 - val_mae: 2.3615\n",
            "Epoch 50/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 3.0069 - mae: 1.2992 - val_loss: 12.9972 - val_mae: 2.4139\n",
            "Epoch 51/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.5793 - mae: 1.2385 - val_loss: 12.9171 - val_mae: 2.3659\n",
            "Epoch 52/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.7081 - mae: 1.2410 - val_loss: 13.1903 - val_mae: 2.4221\n",
            "Epoch 53/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 2.4279 - mae: 1.1821 - val_loss: 15.4172 - val_mae: 2.6340\n",
            "Epoch 54/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.5204 - mae: 1.2489 - val_loss: 12.6674 - val_mae: 2.3880\n",
            "Epoch 55/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.8162 - mae: 1.2847 - val_loss: 13.3032 - val_mae: 2.5047\n",
            "Epoch 56/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 4.2326 - mae: 1.6069 - val_loss: 12.5885 - val_mae: 2.4067\n",
            "Epoch 57/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 2.8630 - mae: 1.2818 - val_loss: 11.0955 - val_mae: 2.2257\n",
            "Epoch 58/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.5970 - mae: 1.2292 - val_loss: 12.5776 - val_mae: 2.4347\n",
            "Epoch 59/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 2.2368 - mae: 1.1700 - val_loss: 12.6191 - val_mae: 2.4536\n",
            "Epoch 60/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 2.7897 - mae: 1.3050 - val_loss: 13.1332 - val_mae: 2.5173\n",
            "Epoch 61/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.4016 - mae: 1.2121 - val_loss: 13.2738 - val_mae: 2.4711\n",
            "Epoch 62/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.2468 - mae: 1.1828 - val_loss: 12.9275 - val_mae: 2.4238\n",
            "Epoch 63/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.1498 - mae: 1.1022 - val_loss: 12.3794 - val_mae: 2.4046\n",
            "Epoch 64/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.8551 - mae: 1.3189 - val_loss: 13.5259 - val_mae: 2.6290\n",
            "Epoch 65/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 4.0381 - mae: 1.4852 - val_loss: 12.9242 - val_mae: 2.5388\n",
            "Epoch 66/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.2330 - mae: 1.1350 - val_loss: 13.2933 - val_mae: 2.5167\n",
            "Epoch 67/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.1773 - mae: 1.1219 - val_loss: 13.0367 - val_mae: 2.5295\n",
            "Epoch 68/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.1908 - mae: 1.1441 - val_loss: 12.4312 - val_mae: 2.4417\n",
            "Epoch 69/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.9816 - mae: 1.0469 - val_loss: 12.4804 - val_mae: 2.4242\n",
            "Epoch 70/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.2806 - mae: 1.1348 - val_loss: 13.9282 - val_mae: 2.5427\n",
            "Epoch 71/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.0323 - mae: 1.0773 - val_loss: 12.2809 - val_mae: 2.4201\n",
            "Epoch 72/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.8522 - mae: 1.0393 - val_loss: 12.9868 - val_mae: 2.4838\n",
            "Epoch 73/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.2595 - mae: 1.1322 - val_loss: 13.2451 - val_mae: 2.5260\n",
            "Epoch 74/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 2.7233 - mae: 1.2654 - val_loss: 12.2957 - val_mae: 2.4260\n",
            "Epoch 75/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.9336 - mae: 1.0523 - val_loss: 11.6504 - val_mae: 2.3063\n",
            "Epoch 76/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.5182 - mae: 1.2287 - val_loss: 13.5301 - val_mae: 2.5464\n",
            "Epoch 77/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.0524 - mae: 1.0919 - val_loss: 11.9327 - val_mae: 2.3465\n",
            "Epoch 78/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.6727 - mae: 1.2306 - val_loss: 15.3544 - val_mae: 2.8123\n",
            "Epoch 79/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.4498 - mae: 1.1889 - val_loss: 13.0510 - val_mae: 2.4492\n",
            "Epoch 80/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.5811 - mae: 0.9571 - val_loss: 12.9977 - val_mae: 2.5167\n",
            "Epoch 81/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.0421 - mae: 1.0901 - val_loss: 12.5451 - val_mae: 2.4254\n",
            "Epoch 82/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.2724 - mae: 1.1466 - val_loss: 14.5012 - val_mae: 2.7047\n",
            "Epoch 83/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.0105 - mae: 1.1189 - val_loss: 13.6432 - val_mae: 2.5366\n",
            "Epoch 84/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.1691 - mae: 1.1413 - val_loss: 13.4417 - val_mae: 2.5794\n",
            "Epoch 85/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.4760 - mae: 1.2215 - val_loss: 14.0410 - val_mae: 2.7046\n",
            "Epoch 86/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.2857 - mae: 1.1138 - val_loss: 12.6785 - val_mae: 2.4994\n",
            "Epoch 87/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.9567 - mae: 1.0519 - val_loss: 12.8478 - val_mae: 2.4131\n",
            "Epoch 88/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.6777 - mae: 0.9974 - val_loss: 12.5214 - val_mae: 2.3919\n",
            "Epoch 89/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.6385 - mae: 0.9647 - val_loss: 13.3471 - val_mae: 2.4953\n",
            "Epoch 90/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.0677 - mae: 1.0804 - val_loss: 12.3513 - val_mae: 2.4975\n",
            "Epoch 91/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.3169 - mae: 1.2020 - val_loss: 11.6999 - val_mae: 2.4334\n",
            "Epoch 92/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.9658 - mae: 1.0749 - val_loss: 13.8375 - val_mae: 2.6909\n",
            "Epoch 93/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.8063 - mae: 1.0320 - val_loss: 13.6773 - val_mae: 2.6489\n",
            "Epoch 94/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.3845 - mae: 0.8694 - val_loss: 13.5496 - val_mae: 2.5230\n",
            "Epoch 95/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.2437 - mae: 0.8435 - val_loss: 12.1897 - val_mae: 2.4362\n",
            "Epoch 96/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.8962 - mae: 1.0649 - val_loss: 12.2268 - val_mae: 2.3958\n",
            "Epoch 97/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.5853 - mae: 0.9603 - val_loss: 12.9422 - val_mae: 2.4884\n",
            "Epoch 98/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.7878 - mae: 0.9826 - val_loss: 11.9460 - val_mae: 2.4062\n",
            "Epoch 99/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.1852 - mae: 1.1229 - val_loss: 12.6528 - val_mae: 2.5257\n",
            "Epoch 100/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.5718 - mae: 0.9740 - val_loss: 13.3977 - val_mae: 2.5037\n",
            "Epoch 101/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.8466 - mae: 0.9910 - val_loss: 12.8409 - val_mae: 2.5032\n",
            "Epoch 102/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.0693 - mae: 1.0436 - val_loss: 13.1235 - val_mae: 2.4311\n",
            "Epoch 103/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.0397 - mae: 1.0595 - val_loss: 13.4430 - val_mae: 2.5392\n",
            "Epoch 104/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.4624 - mae: 0.9129 - val_loss: 12.2439 - val_mae: 2.4899\n",
            "Epoch 105/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.3272 - mae: 0.8824 - val_loss: 12.1470 - val_mae: 2.3819\n",
            "Epoch 106/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.3918 - mae: 0.9372 - val_loss: 12.8524 - val_mae: 2.5434\n",
            "Epoch 107/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.6486 - mae: 0.9608 - val_loss: 12.8347 - val_mae: 2.4449\n",
            "Epoch 108/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.9725 - mae: 1.0247 - val_loss: 12.7190 - val_mae: 2.4602\n",
            "Epoch 109/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.3875 - mae: 0.9121 - val_loss: 12.5225 - val_mae: 2.4636\n",
            "Epoch 110/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.2207 - mae: 0.8308 - val_loss: 13.1151 - val_mae: 2.5009\n",
            "Epoch 111/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.2923 - mae: 0.8906 - val_loss: 13.2688 - val_mae: 2.5600\n",
            "Epoch 112/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.5873 - mae: 0.9361 - val_loss: 14.6840 - val_mae: 2.7581\n",
            "Epoch 113/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.2585 - mae: 1.1047 - val_loss: 14.4858 - val_mae: 2.5660\n",
            "Epoch 114/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.2293 - mae: 1.1121 - val_loss: 12.7568 - val_mae: 2.4525\n",
            "Epoch 115/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.3167 - mae: 0.8854 - val_loss: 12.8614 - val_mae: 2.4248\n",
            "Epoch 116/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.7718 - mae: 1.0606 - val_loss: 13.1992 - val_mae: 2.5256\n",
            "Epoch 117/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.4359 - mae: 0.8575 - val_loss: 13.1026 - val_mae: 2.5044\n",
            "Epoch 118/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.3376 - mae: 0.8835 - val_loss: 12.3317 - val_mae: 2.4059\n",
            "Epoch 119/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.0349 - mae: 0.7856 - val_loss: 12.9869 - val_mae: 2.4354\n",
            "Epoch 120/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.1486 - mae: 0.8064 - val_loss: 14.1063 - val_mae: 2.5779\n",
            "Epoch 121/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.2135 - mae: 0.8545 - val_loss: 11.8752 - val_mae: 2.3613\n",
            "Epoch 122/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.7867 - mae: 1.0256 - val_loss: 14.2588 - val_mae: 2.6437\n",
            "Epoch 123/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.6870 - mae: 0.9533 - val_loss: 14.2474 - val_mae: 2.7660\n",
            "Epoch 124/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.5955 - mae: 0.9605 - val_loss: 14.0315 - val_mae: 2.6860\n",
            "Epoch 125/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.3499 - mae: 1.1757 - val_loss: 12.0570 - val_mae: 2.4369\n",
            "Epoch 126/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.8924 - mae: 1.0444 - val_loss: 11.8933 - val_mae: 2.4002\n",
            "Epoch 127/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.3532 - mae: 0.8887 - val_loss: 12.3772 - val_mae: 2.4459\n",
            "Epoch 128/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.0106 - mae: 0.7522 - val_loss: 12.7138 - val_mae: 2.4677\n",
            "Epoch 129/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.8448 - mae: 0.6961 - val_loss: 14.1771 - val_mae: 2.6674\n",
            "Epoch 130/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.9965 - mae: 0.7359 - val_loss: 12.8595 - val_mae: 2.5031\n",
            "Epoch 131/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.0723 - mae: 0.7788 - val_loss: 12.8102 - val_mae: 2.4891\n",
            "Epoch 132/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.2047 - mae: 0.8269 - val_loss: 14.2066 - val_mae: 2.6187\n",
            "Epoch 133/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.6356 - mae: 0.9506 - val_loss: 12.3520 - val_mae: 2.4587\n",
            "Epoch 134/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.4422 - mae: 0.9321 - val_loss: 12.5804 - val_mae: 2.5106\n",
            "Epoch 135/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.8953 - mae: 1.0638 - val_loss: 11.4920 - val_mae: 2.4270\n",
            "Epoch 136/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.6943 - mae: 0.9848 - val_loss: 12.4853 - val_mae: 2.4023\n",
            "Epoch 137/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.5529 - mae: 0.9564 - val_loss: 12.0881 - val_mae: 2.4094\n",
            "Epoch 138/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.0399 - mae: 0.7770 - val_loss: 12.8047 - val_mae: 2.5187\n",
            "Epoch 139/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.9181 - mae: 0.7312 - val_loss: 12.7055 - val_mae: 2.4745\n",
            "Epoch 140/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.0647 - mae: 0.7561 - val_loss: 12.3817 - val_mae: 2.3970\n",
            "Epoch 141/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.2018 - mae: 0.8214 - val_loss: 12.2459 - val_mae: 2.4203\n",
            "Epoch 142/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.3146 - mae: 0.8748 - val_loss: 12.7772 - val_mae: 2.4596\n",
            "Epoch 143/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.9741 - mae: 0.7349 - val_loss: 14.5562 - val_mae: 2.6605\n",
            "Epoch 144/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.2886 - mae: 0.8641 - val_loss: 13.4847 - val_mae: 2.5903\n",
            "Epoch 145/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.2277 - mae: 0.8271 - val_loss: 13.4460 - val_mae: 2.5487\n",
            "Epoch 146/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.7486 - mae: 0.6538 - val_loss: 12.8643 - val_mae: 2.4728\n",
            "Epoch 147/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.8785 - mae: 0.7219 - val_loss: 12.7414 - val_mae: 2.4824\n",
            "Epoch 148/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.1965 - mae: 0.8389 - val_loss: 13.3748 - val_mae: 2.5128\n",
            "Epoch 149/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.0378 - mae: 0.7345 - val_loss: 11.8132 - val_mae: 2.3915\n",
            "Epoch 150/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.4181 - mae: 0.9137 - val_loss: 12.9941 - val_mae: 2.5423\n",
            "Epoch 151/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.7043 - mae: 0.9632 - val_loss: 13.0453 - val_mae: 2.3556\n",
            "Epoch 152/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.3358 - mae: 0.8725 - val_loss: 12.1423 - val_mae: 2.4851\n",
            "Epoch 153/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.5615 - mae: 0.9349 - val_loss: 12.6951 - val_mae: 2.4891\n",
            "Epoch 154/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 0.9278 - mae: 0.7368 - val_loss: 11.8702 - val_mae: 2.4043\n",
            "Epoch 155/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.9458 - mae: 0.7308 - val_loss: 12.5757 - val_mae: 2.4613\n",
            "Epoch 156/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.9828 - mae: 0.7607 - val_loss: 12.6397 - val_mae: 2.4610\n",
            "Epoch 157/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.9964 - mae: 0.7515 - val_loss: 12.4210 - val_mae: 2.4075\n",
            "Epoch 158/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.7309 - mae: 0.6524 - val_loss: 11.8487 - val_mae: 2.3396\n",
            "Epoch 159/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.9184 - mae: 0.7392 - val_loss: 12.8874 - val_mae: 2.4114\n",
            "Epoch 160/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.1298 - mae: 0.7554 - val_loss: 14.8511 - val_mae: 2.7696\n",
            "Epoch 161/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.0163 - mae: 0.7689 - val_loss: 13.2523 - val_mae: 2.5013\n",
            "Epoch 162/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.0542 - mae: 0.7700 - val_loss: 12.6162 - val_mae: 2.4718\n",
            "Epoch 163/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.2650 - mae: 0.8528 - val_loss: 12.7284 - val_mae: 2.4514\n",
            "Epoch 164/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.9616 - mae: 1.0858 - val_loss: 12.6754 - val_mae: 2.5236\n",
            "Epoch 165/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.1016 - mae: 0.7989 - val_loss: 12.2251 - val_mae: 2.4119\n",
            "Epoch 166/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.8283 - mae: 0.6843 - val_loss: 13.0135 - val_mae: 2.4768\n",
            "Epoch 167/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.1727 - mae: 0.8138 - val_loss: 13.5292 - val_mae: 2.5261\n",
            "Epoch 168/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.9485 - mae: 0.7304 - val_loss: 12.9141 - val_mae: 2.4296\n",
            "Epoch 169/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.2128 - mae: 0.8292 - val_loss: 13.1800 - val_mae: 2.5616\n",
            "Epoch 170/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.0244 - mae: 0.7522 - val_loss: 12.2405 - val_mae: 2.4213\n",
            "Epoch 171/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.7909 - mae: 0.6518 - val_loss: 12.7045 - val_mae: 2.4458\n",
            "Epoch 172/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.3953 - mae: 0.8933 - val_loss: 13.1844 - val_mae: 2.5339\n",
            "Epoch 173/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.9240 - mae: 0.7318 - val_loss: 12.8895 - val_mae: 2.4598\n",
            "Epoch 174/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.7607 - mae: 0.6794 - val_loss: 13.3431 - val_mae: 2.5803\n",
            "Epoch 175/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 0.6864 - mae: 0.6256 - val_loss: 13.0358 - val_mae: 2.5036\n",
            "Epoch 176/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 0.6493 - mae: 0.6067 - val_loss: 12.6802 - val_mae: 2.4482\n",
            "Epoch 177/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 0.7425 - mae: 0.6179 - val_loss: 12.0892 - val_mae: 2.3824\n",
            "Epoch 178/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 0.8377 - mae: 0.6927 - val_loss: 12.4278 - val_mae: 2.4408\n",
            "Epoch 179/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 0.9676 - mae: 0.7064 - val_loss: 12.8592 - val_mae: 2.5391\n",
            "Epoch 180/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.6463 - mae: 0.6126 - val_loss: 12.8055 - val_mae: 2.4622\n",
            "Epoch 181/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.0591 - mae: 0.7601 - val_loss: 13.2925 - val_mae: 2.4905\n",
            "Epoch 182/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.3027 - mae: 0.8756 - val_loss: 14.3230 - val_mae: 2.6382\n",
            "Epoch 183/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.7227 - mae: 0.9457 - val_loss: 12.3402 - val_mae: 2.5390\n",
            "Epoch 184/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.7559 - mae: 0.9186 - val_loss: 13.3861 - val_mae: 2.4942\n",
            "Epoch 185/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.9241 - mae: 0.7177 - val_loss: 12.5151 - val_mae: 2.4235\n",
            "Epoch 186/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.5967 - mae: 0.5617 - val_loss: 13.8022 - val_mae: 2.5025\n",
            "Epoch 187/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.7343 - mae: 0.6454 - val_loss: 13.4267 - val_mae: 2.5723\n",
            "Epoch 188/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.8127 - mae: 0.6683 - val_loss: 12.3837 - val_mae: 2.3825\n",
            "Epoch 189/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.5671 - mae: 0.5596 - val_loss: 13.6863 - val_mae: 2.5582\n",
            "Epoch 190/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.8444 - mae: 0.6982 - val_loss: 13.1927 - val_mae: 2.4982\n",
            "Epoch 191/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.6059 - mae: 0.5864 - val_loss: 12.5030 - val_mae: 2.4359\n",
            "Epoch 192/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.7241 - mae: 0.6268 - val_loss: 12.9265 - val_mae: 2.4334\n",
            "Epoch 193/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.7483 - mae: 0.6601 - val_loss: 13.0278 - val_mae: 2.5527\n",
            "Epoch 194/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.6906 - mae: 0.6369 - val_loss: 13.2729 - val_mae: 2.4249\n",
            "Epoch 195/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.8696 - mae: 0.6942 - val_loss: 12.2787 - val_mae: 2.4216\n",
            "Epoch 196/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.5343 - mae: 0.9277 - val_loss: 12.4250 - val_mae: 2.4385\n",
            "Epoch 197/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.0511 - mae: 0.7555 - val_loss: 12.8408 - val_mae: 2.5166\n",
            "Epoch 198/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.1239 - mae: 0.7663 - val_loss: 12.5194 - val_mae: 2.4604\n",
            "Epoch 199/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.8014 - mae: 0.6608 - val_loss: 13.3617 - val_mae: 2.6302\n",
            "Epoch 200/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.8576 - mae: 0.6751 - val_loss: 12.7587 - val_mae: 2.4704\n",
            "Epoch 201/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.6380 - mae: 0.6167 - val_loss: 13.5373 - val_mae: 2.5122\n",
            "Epoch 202/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.7269 - mae: 0.6284 - val_loss: 13.4878 - val_mae: 2.5864\n",
            "Epoch 203/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.8976 - mae: 0.7127 - val_loss: 13.8872 - val_mae: 2.6567\n",
            "Epoch 204/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.3810 - mae: 0.8351 - val_loss: 13.4630 - val_mae: 2.5099\n",
            "Epoch 205/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.8182 - mae: 0.6683 - val_loss: 11.8905 - val_mae: 2.3841\n",
            "Epoch 206/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.5266 - mae: 0.5589 - val_loss: 12.9901 - val_mae: 2.5212\n",
            "Epoch 207/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.6206 - mae: 0.6020 - val_loss: 12.5599 - val_mae: 2.4924\n",
            "Epoch 208/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.8000 - mae: 0.6497 - val_loss: 13.4916 - val_mae: 2.4926\n",
            "Epoch 209/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.1922 - mae: 0.7798 - val_loss: 13.3400 - val_mae: 2.4840\n",
            "Epoch 210/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.9225 - mae: 0.7259 - val_loss: 13.4662 - val_mae: 2.5512\n",
            "Epoch 211/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.7488 - mae: 0.6271 - val_loss: 12.6997 - val_mae: 2.4422\n",
            "Epoch 212/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.9443 - mae: 0.7017 - val_loss: 12.8638 - val_mae: 2.4436\n",
            "Epoch 213/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.7016 - mae: 0.6269 - val_loss: 11.9043 - val_mae: 2.3548\n",
            "Epoch 214/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.6119 - mae: 0.5810 - val_loss: 13.0183 - val_mae: 2.5025\n",
            "Epoch 215/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.6274 - mae: 0.5716 - val_loss: 12.9537 - val_mae: 2.5132\n",
            "Epoch 216/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.7705 - mae: 0.6545 - val_loss: 13.2129 - val_mae: 2.4505\n",
            "Epoch 217/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.0817 - mae: 0.7984 - val_loss: 12.6805 - val_mae: 2.4957\n",
            "Epoch 218/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.3776 - mae: 0.8830 - val_loss: 12.6753 - val_mae: 2.5278\n",
            "Epoch 219/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.7647 - mae: 0.6809 - val_loss: 12.3259 - val_mae: 2.4110\n",
            "Epoch 220/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.7619 - mae: 0.6569 - val_loss: 12.4213 - val_mae: 2.5121\n",
            "Epoch 221/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.1923 - mae: 0.8342 - val_loss: 12.1911 - val_mae: 2.4688\n",
            "Epoch 222/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.0529 - mae: 0.7743 - val_loss: 12.3590 - val_mae: 2.3971\n",
            "Epoch 223/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.9619 - mae: 0.7149 - val_loss: 13.8605 - val_mae: 2.6136\n",
            "Epoch 224/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.1928 - mae: 0.7712 - val_loss: 13.8352 - val_mae: 2.5544\n",
            "Epoch 225/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.9988 - mae: 0.7446 - val_loss: 13.7976 - val_mae: 2.6160\n",
            "Epoch 226/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.6292 - mae: 0.5792 - val_loss: 13.5045 - val_mae: 2.4811\n",
            "Epoch 227/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.5833 - mae: 0.5783 - val_loss: 13.5483 - val_mae: 2.6095\n",
            "Epoch 228/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.4141 - mae: 0.4804 - val_loss: 13.3509 - val_mae: 2.5102\n",
            "Epoch 229/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.3829 - mae: 0.4596 - val_loss: 13.0312 - val_mae: 2.4530\n",
            "Epoch 230/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.1814 - mae: 0.7913 - val_loss: 15.9350 - val_mae: 2.8384\n",
            "Epoch 231/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.2311 - mae: 0.8000 - val_loss: 12.7738 - val_mae: 2.4080\n",
            "Epoch 232/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.7486 - mae: 0.6621 - val_loss: 13.0817 - val_mae: 2.4528\n",
            "Epoch 233/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.6625 - mae: 0.6155 - val_loss: 13.9088 - val_mae: 2.5987\n",
            "Epoch 234/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.5376 - mae: 0.5448 - val_loss: 13.9322 - val_mae: 2.5727\n",
            "Epoch 235/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.4517 - mae: 0.4944 - val_loss: 12.7070 - val_mae: 2.4543\n",
            "Epoch 236/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.7397 - mae: 0.6605 - val_loss: 13.7152 - val_mae: 2.4982\n",
            "Epoch 237/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.1439 - mae: 0.7945 - val_loss: 13.5688 - val_mae: 2.6912\n",
            "Epoch 238/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.9008 - mae: 0.7408 - val_loss: 12.2052 - val_mae: 2.4268\n",
            "Epoch 239/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.5852 - mae: 0.5855 - val_loss: 12.8501 - val_mae: 2.4471\n",
            "Epoch 240/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.5133 - mae: 0.5213 - val_loss: 13.2589 - val_mae: 2.5286\n",
            "Epoch 241/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.1782 - mae: 0.8004 - val_loss: 13.4560 - val_mae: 2.5180\n",
            "Epoch 242/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.9979 - mae: 0.7255 - val_loss: 13.2720 - val_mae: 2.4707\n",
            "Epoch 243/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.8569 - mae: 0.7155 - val_loss: 12.9701 - val_mae: 2.4616\n",
            "Epoch 244/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.6372 - mae: 0.5882 - val_loss: 12.6152 - val_mae: 2.4381\n",
            "Epoch 245/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.7405 - mae: 0.6275 - val_loss: 12.3568 - val_mae: 2.3770\n",
            "Epoch 246/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.5609 - mae: 0.5690 - val_loss: 12.8003 - val_mae: 2.4636\n",
            "Epoch 247/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.4767 - mae: 0.5217 - val_loss: 13.1179 - val_mae: 2.5409\n",
            "Epoch 248/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.4975 - mae: 0.4847 - val_loss: 13.4279 - val_mae: 2.5283\n",
            "Epoch 249/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.6833 - mae: 0.6431 - val_loss: 14.1814 - val_mae: 2.6242\n",
            "Epoch 250/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.7473 - mae: 0.6568 - val_loss: 12.4924 - val_mae: 2.4359\n",
            "Epoch 251/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.9415 - mae: 0.6882 - val_loss: 14.4112 - val_mae: 2.4880\n",
            "Epoch 252/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.5832 - mae: 0.9315 - val_loss: 12.5592 - val_mae: 2.4389\n",
            "Epoch 253/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.9901 - mae: 0.7161 - val_loss: 13.5667 - val_mae: 2.5533\n",
            "Epoch 254/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 0.6047 - mae: 0.5821 - val_loss: 13.2251 - val_mae: 2.4444\n",
            "Epoch 255/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.6659 - mae: 0.5569 - val_loss: 12.8488 - val_mae: 2.4797\n",
            "Epoch 256/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 0.3699 - mae: 0.4474 - val_loss: 12.7784 - val_mae: 2.4344\n",
            "Epoch 257/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.4382 - mae: 0.4881 - val_loss: 12.8151 - val_mae: 2.5070\n",
            "Epoch 258/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4712 - mae: 0.4998 - val_loss: 12.5316 - val_mae: 2.4174\n",
            "Epoch 259/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.6326 - mae: 0.5655 - val_loss: 12.2944 - val_mae: 2.3951\n",
            "Epoch 260/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.6471 - mae: 0.6057 - val_loss: 13.7088 - val_mae: 2.5799\n",
            "Epoch 261/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.5399 - mae: 0.5684 - val_loss: 12.8699 - val_mae: 2.5071\n",
            "Epoch 262/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.6143 - mae: 0.5785 - val_loss: 13.0759 - val_mae: 2.4801\n",
            "Epoch 263/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4791 - mae: 0.5073 - val_loss: 12.6976 - val_mae: 2.4906\n",
            "Epoch 264/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.8717 - mae: 0.6798 - val_loss: 14.0987 - val_mae: 2.6484\n",
            "Epoch 265/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.2380 - mae: 0.7780 - val_loss: 13.5364 - val_mae: 2.6021\n",
            "Epoch 266/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.6490 - mae: 0.6245 - val_loss: 12.1903 - val_mae: 2.4583\n",
            "Epoch 267/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4693 - mae: 0.5296 - val_loss: 12.5902 - val_mae: 2.4902\n",
            "Epoch 268/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.5219 - mae: 0.5380 - val_loss: 12.7439 - val_mae: 2.4851\n",
            "Epoch 269/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.6141 - mae: 0.5950 - val_loss: 13.1360 - val_mae: 2.4997\n",
            "Epoch 270/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.7796 - mae: 0.6460 - val_loss: 12.5859 - val_mae: 2.5189\n",
            "Epoch 271/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4245 - mae: 0.4797 - val_loss: 12.0633 - val_mae: 2.4101\n",
            "Epoch 272/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.8319 - mae: 0.6786 - val_loss: 12.2507 - val_mae: 2.4842\n",
            "Epoch 273/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.8577 - mae: 0.6660 - val_loss: 12.2772 - val_mae: 2.4200\n",
            "Epoch 274/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.8573 - mae: 0.6439 - val_loss: 11.7361 - val_mae: 2.3792\n",
            "Epoch 275/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.5779 - mae: 0.5627 - val_loss: 13.1601 - val_mae: 2.5581\n",
            "Epoch 276/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4856 - mae: 0.5091 - val_loss: 12.6576 - val_mae: 2.4662\n",
            "Epoch 277/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4414 - mae: 0.4962 - val_loss: 13.3437 - val_mae: 2.5857\n",
            "Epoch 278/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 0.9891 - mae: 0.7337 - val_loss: 13.0040 - val_mae: 2.4745\n",
            "Epoch 279/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.9107 - mae: 0.7065 - val_loss: 12.6272 - val_mae: 2.5250\n",
            "Epoch 280/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.3928 - mae: 0.4653 - val_loss: 12.8217 - val_mae: 2.5654\n",
            "Epoch 281/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 0.3632 - mae: 0.4408 - val_loss: 12.6068 - val_mae: 2.4525\n",
            "Epoch 282/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.3610 - mae: 0.4636 - val_loss: 12.5318 - val_mae: 2.5095\n",
            "Epoch 283/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.4446 - mae: 0.4780 - val_loss: 12.5884 - val_mae: 2.5069\n",
            "Epoch 284/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.3925 - mae: 0.4562 - val_loss: 12.7892 - val_mae: 2.4203\n",
            "Epoch 285/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.6950 - mae: 0.6177 - val_loss: 12.4573 - val_mae: 2.4659\n",
            "Epoch 286/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.5789 - mae: 0.5534 - val_loss: 12.6691 - val_mae: 2.4514\n",
            "Epoch 287/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.7991 - mae: 0.6553 - val_loss: 13.7200 - val_mae: 2.5556\n",
            "Epoch 288/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.9089 - mae: 0.6976 - val_loss: 13.2979 - val_mae: 2.5265\n",
            "Epoch 289/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.3385 - mae: 0.7918 - val_loss: 13.5216 - val_mae: 2.5654\n",
            "Epoch 290/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.3585 - mae: 0.8401 - val_loss: 12.5031 - val_mae: 2.4651\n",
            "Epoch 291/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.0146 - mae: 0.7687 - val_loss: 13.3806 - val_mae: 2.6414\n",
            "Epoch 292/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.7421 - mae: 0.6395 - val_loss: 13.4051 - val_mae: 2.4884\n",
            "Epoch 293/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.6232 - mae: 0.5905 - val_loss: 12.9407 - val_mae: 2.5011\n",
            "Epoch 294/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4716 - mae: 0.5057 - val_loss: 12.4150 - val_mae: 2.4697\n",
            "Epoch 295/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.5080 - mae: 0.5076 - val_loss: 12.8397 - val_mae: 2.5423\n",
            "Epoch 296/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.4127 - mae: 0.4824 - val_loss: 13.1751 - val_mae: 2.5766\n",
            "Epoch 297/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.4023 - mae: 0.4817 - val_loss: 12.6445 - val_mae: 2.4791\n",
            "Epoch 298/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.7315 - mae: 0.6086 - val_loss: 11.0729 - val_mae: 2.3754\n",
            "Epoch 299/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.6922 - mae: 0.9153 - val_loss: 12.6562 - val_mae: 2.4488\n",
            "Epoch 300/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.5691 - mae: 0.5803 - val_loss: 12.7115 - val_mae: 2.4735\n",
            "processing fold # 3\n",
            "Epoch 1/300\n",
            "152/152 [==============================] - 2s 5ms/step - loss: 187.1850 - mae: 9.9655 - val_loss: 43.5587 - val_mae: 4.7280\n",
            "Epoch 2/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 25.6087 - mae: 3.4919 - val_loss: 26.2302 - val_mae: 3.5690\n",
            "Epoch 3/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 17.0295 - mae: 2.8991 - val_loss: 17.3971 - val_mae: 2.9462\n",
            "Epoch 4/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 14.4226 - mae: 2.7080 - val_loss: 16.1870 - val_mae: 2.9210\n",
            "Epoch 5/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 11.8649 - mae: 2.4982 - val_loss: 17.0196 - val_mae: 2.9139\n",
            "Epoch 6/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 11.1252 - mae: 2.4523 - val_loss: 13.9583 - val_mae: 2.7407\n",
            "Epoch 7/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 10.8648 - mae: 2.3421 - val_loss: 15.8382 - val_mae: 2.9184\n",
            "Epoch 8/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 9.8730 - mae: 2.2000 - val_loss: 13.9483 - val_mae: 2.8432\n",
            "Epoch 9/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 10.9288 - mae: 2.3808 - val_loss: 12.8771 - val_mae: 2.5659\n",
            "Epoch 10/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 8.9703 - mae: 2.1644 - val_loss: 13.8163 - val_mae: 2.8202\n",
            "Epoch 11/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 8.9276 - mae: 2.1634 - val_loss: 12.5654 - val_mae: 2.6521\n",
            "Epoch 12/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 8.1855 - mae: 2.0201 - val_loss: 12.0734 - val_mae: 2.5987\n",
            "Epoch 13/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 7.9139 - mae: 2.0370 - val_loss: 14.3945 - val_mae: 2.7895\n",
            "Epoch 14/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 9.2424 - mae: 2.1987 - val_loss: 14.6334 - val_mae: 2.7657\n",
            "Epoch 15/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 8.1775 - mae: 2.0321 - val_loss: 12.2208 - val_mae: 2.6263\n",
            "Epoch 16/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 7.2258 - mae: 1.9256 - val_loss: 12.0249 - val_mae: 2.5064\n",
            "Epoch 17/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 6.8300 - mae: 1.9021 - val_loss: 12.9148 - val_mae: 2.5855\n",
            "Epoch 18/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 7.3885 - mae: 2.0182 - val_loss: 11.7218 - val_mae: 2.4692\n",
            "Epoch 19/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 6.9034 - mae: 1.8723 - val_loss: 11.6544 - val_mae: 2.5222\n",
            "Epoch 20/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 6.7634 - mae: 1.8745 - val_loss: 11.3253 - val_mae: 2.5252\n",
            "Epoch 21/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 6.6884 - mae: 1.8525 - val_loss: 13.8836 - val_mae: 2.5488\n",
            "Epoch 22/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 6.8483 - mae: 1.8902 - val_loss: 11.7911 - val_mae: 2.3867\n",
            "Epoch 23/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 6.5221 - mae: 1.7754 - val_loss: 11.9208 - val_mae: 2.3843\n",
            "Epoch 24/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 6.7963 - mae: 1.8426 - val_loss: 11.9979 - val_mae: 2.3832\n",
            "Epoch 25/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 5.8063 - mae: 1.8119 - val_loss: 11.9070 - val_mae: 2.3894\n",
            "Epoch 26/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 6.0746 - mae: 1.7392 - val_loss: 12.8217 - val_mae: 2.6481\n",
            "Epoch 27/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 5.6566 - mae: 1.7034 - val_loss: 12.2793 - val_mae: 2.4328\n",
            "Epoch 28/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 6.6899 - mae: 1.9639 - val_loss: 10.7416 - val_mae: 2.3775\n",
            "Epoch 29/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 6.3024 - mae: 1.7936 - val_loss: 12.4023 - val_mae: 2.5792\n",
            "Epoch 30/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 5.2327 - mae: 1.6491 - val_loss: 12.5770 - val_mae: 2.3840\n",
            "Epoch 31/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 5.4821 - mae: 1.7004 - val_loss: 11.0502 - val_mae: 2.3888\n",
            "Epoch 32/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 5.6908 - mae: 1.7984 - val_loss: 11.1314 - val_mae: 2.3228\n",
            "Epoch 33/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 5.3155 - mae: 1.6525 - val_loss: 9.9327 - val_mae: 2.2857\n",
            "Epoch 34/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 4.5797 - mae: 1.5646 - val_loss: 11.4975 - val_mae: 2.4557\n",
            "Epoch 35/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 4.3226 - mae: 1.5017 - val_loss: 11.6602 - val_mae: 2.4595\n",
            "Epoch 36/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 5.9548 - mae: 1.7614 - val_loss: 12.3553 - val_mae: 2.5747\n",
            "Epoch 37/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 4.4122 - mae: 1.5508 - val_loss: 12.6832 - val_mae: 2.3813\n",
            "Epoch 38/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 4.4691 - mae: 1.6313 - val_loss: 10.0718 - val_mae: 2.2285\n",
            "Epoch 39/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 4.6406 - mae: 1.5671 - val_loss: 10.8400 - val_mae: 2.3234\n",
            "Epoch 40/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 4.0990 - mae: 1.5274 - val_loss: 9.6838 - val_mae: 2.1955\n",
            "Epoch 41/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 4.0160 - mae: 1.4758 - val_loss: 10.3956 - val_mae: 2.1917\n",
            "Epoch 42/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 4.1517 - mae: 1.4672 - val_loss: 10.6764 - val_mae: 2.2296\n",
            "Epoch 43/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 3.7911 - mae: 1.4091 - val_loss: 11.0786 - val_mae: 2.4341\n",
            "Epoch 44/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 4.8358 - mae: 1.5992 - val_loss: 11.8468 - val_mae: 2.1792\n",
            "Epoch 45/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 4.2069 - mae: 1.5136 - val_loss: 10.1232 - val_mae: 2.1921\n",
            "Epoch 46/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 3.4910 - mae: 1.3868 - val_loss: 12.9587 - val_mae: 2.4137\n",
            "Epoch 47/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 3.8234 - mae: 1.4566 - val_loss: 10.4811 - val_mae: 2.1463\n",
            "Epoch 48/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 3.1365 - mae: 1.3150 - val_loss: 10.6062 - val_mae: 2.3025\n",
            "Epoch 49/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 2.9470 - mae: 1.2922 - val_loss: 11.1983 - val_mae: 2.3631\n",
            "Epoch 50/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 3.6121 - mae: 1.4279 - val_loss: 10.2449 - val_mae: 2.1508\n",
            "Epoch 51/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 4.4388 - mae: 1.5869 - val_loss: 12.5291 - val_mae: 2.4952\n",
            "Epoch 52/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 4.5192 - mae: 1.5855 - val_loss: 10.7207 - val_mae: 2.3356\n",
            "Epoch 53/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 3.1686 - mae: 1.3269 - val_loss: 8.4821 - val_mae: 2.0594\n",
            "Epoch 54/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 3.4710 - mae: 1.3996 - val_loss: 9.8964 - val_mae: 2.1769\n",
            "Epoch 55/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 3.4117 - mae: 1.3855 - val_loss: 10.4948 - val_mae: 2.3486\n",
            "Epoch 56/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 2.8241 - mae: 1.2668 - val_loss: 11.2000 - val_mae: 2.1894\n",
            "Epoch 57/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 3.2241 - mae: 1.3168 - val_loss: 9.8554 - val_mae: 2.1359\n",
            "Epoch 58/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 4.7408 - mae: 1.5003 - val_loss: 9.3519 - val_mae: 2.1678\n",
            "Epoch 59/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 3.3694 - mae: 1.3784 - val_loss: 11.1100 - val_mae: 2.2198\n",
            "Epoch 60/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.8218 - mae: 1.2153 - val_loss: 9.0624 - val_mae: 2.0200\n",
            "Epoch 61/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 3.6357 - mae: 1.3559 - val_loss: 12.2627 - val_mae: 2.4108\n",
            "Epoch 62/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 3.0065 - mae: 1.2532 - val_loss: 11.4155 - val_mae: 2.4012\n",
            "Epoch 63/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 3.3924 - mae: 1.3299 - val_loss: 9.8386 - val_mae: 2.1114\n",
            "Epoch 64/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.4947 - mae: 1.1662 - val_loss: 9.4821 - val_mae: 2.0828\n",
            "Epoch 65/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 2.4562 - mae: 1.1315 - val_loss: 9.6926 - val_mae: 2.1098\n",
            "Epoch 66/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 2.6785 - mae: 1.2165 - val_loss: 9.6504 - val_mae: 2.1831\n",
            "Epoch 67/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 3.1168 - mae: 1.2810 - val_loss: 12.4668 - val_mae: 2.1956\n",
            "Epoch 68/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.8975 - mae: 1.2738 - val_loss: 12.0356 - val_mae: 2.4671\n",
            "Epoch 69/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.7335 - mae: 1.2539 - val_loss: 10.1471 - val_mae: 2.1952\n",
            "Epoch 70/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.7334 - mae: 1.2138 - val_loss: 11.7599 - val_mae: 2.5490\n",
            "Epoch 71/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 3.5387 - mae: 1.3618 - val_loss: 11.7350 - val_mae: 2.1838\n",
            "Epoch 72/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 3.5147 - mae: 1.2588 - val_loss: 10.9737 - val_mae: 2.2897\n",
            "Epoch 73/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.6995 - mae: 1.2594 - val_loss: 11.1031 - val_mae: 2.2754\n",
            "Epoch 74/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.5133 - mae: 1.1511 - val_loss: 11.6375 - val_mae: 2.2579\n",
            "Epoch 75/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.1792 - mae: 1.0873 - val_loss: 10.5212 - val_mae: 2.3134\n",
            "Epoch 76/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 3.2004 - mae: 1.2804 - val_loss: 12.1784 - val_mae: 2.3330\n",
            "Epoch 77/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.6555 - mae: 1.2426 - val_loss: 10.3779 - val_mae: 2.1203\n",
            "Epoch 78/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.0663 - mae: 1.0798 - val_loss: 11.4963 - val_mae: 2.3353\n",
            "Epoch 79/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.8312 - mae: 1.0301 - val_loss: 10.4270 - val_mae: 2.1717\n",
            "Epoch 80/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.4752 - mae: 1.1934 - val_loss: 11.6332 - val_mae: 2.3232\n",
            "Epoch 81/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.4726 - mae: 1.1481 - val_loss: 10.4007 - val_mae: 2.1925\n",
            "Epoch 82/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 3.0226 - mae: 1.2651 - val_loss: 12.4912 - val_mae: 2.4538\n",
            "Epoch 83/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.5363 - mae: 1.2053 - val_loss: 13.0760 - val_mae: 2.6426\n",
            "Epoch 84/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.4536 - mae: 1.1394 - val_loss: 14.7247 - val_mae: 2.8528\n",
            "Epoch 85/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 2.5546 - mae: 1.1671 - val_loss: 10.4067 - val_mae: 2.2372\n",
            "Epoch 86/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.2006 - mae: 1.0549 - val_loss: 12.3684 - val_mae: 2.3789\n",
            "Epoch 87/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.0639 - mae: 1.0818 - val_loss: 13.4151 - val_mae: 2.3026\n",
            "Epoch 88/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.5527 - mae: 1.1235 - val_loss: 12.0056 - val_mae: 2.2777\n",
            "Epoch 89/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.1297 - mae: 1.0211 - val_loss: 9.7743 - val_mae: 2.1331\n",
            "Epoch 90/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.1842 - mae: 1.0653 - val_loss: 12.2535 - val_mae: 2.3184\n",
            "Epoch 91/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 3.0684 - mae: 1.3086 - val_loss: 10.8004 - val_mae: 2.2773\n",
            "Epoch 92/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 3.3520 - mae: 1.2938 - val_loss: 12.8626 - val_mae: 2.6286\n",
            "Epoch 93/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 3.0377 - mae: 1.2450 - val_loss: 13.1384 - val_mae: 2.3339\n",
            "Epoch 94/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 2.7612 - mae: 1.1960 - val_loss: 10.9145 - val_mae: 2.2386\n",
            "Epoch 95/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 2.0609 - mae: 1.0498 - val_loss: 10.4055 - val_mae: 2.1420\n",
            "Epoch 96/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.9057 - mae: 0.9646 - val_loss: 10.9460 - val_mae: 2.3183\n",
            "Epoch 97/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.7691 - mae: 0.9633 - val_loss: 10.2242 - val_mae: 2.2412\n",
            "Epoch 98/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.1609 - mae: 1.0807 - val_loss: 10.8087 - val_mae: 2.1481\n",
            "Epoch 99/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.7045 - mae: 0.9512 - val_loss: 10.5696 - val_mae: 2.0731\n",
            "Epoch 100/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.9368 - mae: 1.0015 - val_loss: 12.4520 - val_mae: 2.4717\n",
            "Epoch 101/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.6724 - mae: 1.2004 - val_loss: 11.1932 - val_mae: 2.1909\n",
            "Epoch 102/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 2.4113 - mae: 1.1395 - val_loss: 13.3065 - val_mae: 2.5069\n",
            "Epoch 103/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.1874 - mae: 1.0239 - val_loss: 10.9647 - val_mae: 2.1936\n",
            "Epoch 104/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.8578 - mae: 0.9998 - val_loss: 11.6818 - val_mae: 2.3577\n",
            "Epoch 105/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 2.1900 - mae: 1.0594 - val_loss: 12.2589 - val_mae: 2.5279\n",
            "Epoch 106/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.8116 - mae: 0.9552 - val_loss: 10.7085 - val_mae: 2.1556\n",
            "Epoch 107/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.6878 - mae: 0.9724 - val_loss: 10.7388 - val_mae: 2.2602\n",
            "Epoch 108/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.5846 - mae: 0.9427 - val_loss: 10.4978 - val_mae: 2.1942\n",
            "Epoch 109/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.6125 - mae: 0.9055 - val_loss: 11.4894 - val_mae: 2.2889\n",
            "Epoch 110/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 3.2097 - mae: 1.3089 - val_loss: 14.3186 - val_mae: 2.8256\n",
            "Epoch 111/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.8300 - mae: 0.9868 - val_loss: 10.5961 - val_mae: 2.2225\n",
            "Epoch 112/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.4265 - mae: 1.1282 - val_loss: 11.9524 - val_mae: 2.3070\n",
            "Epoch 113/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.6806 - mae: 1.1453 - val_loss: 11.9975 - val_mae: 2.3157\n",
            "Epoch 114/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 2.4133 - mae: 1.0963 - val_loss: 10.9267 - val_mae: 2.2267\n",
            "Epoch 115/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.9281 - mae: 0.9759 - val_loss: 15.6480 - val_mae: 2.8716\n",
            "Epoch 116/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.8591 - mae: 0.9742 - val_loss: 10.0941 - val_mae: 2.2057\n",
            "Epoch 117/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.8529 - mae: 0.9725 - val_loss: 11.2836 - val_mae: 2.2945\n",
            "Epoch 118/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.9003 - mae: 0.9669 - val_loss: 11.3414 - val_mae: 2.2805\n",
            "Epoch 119/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.9763 - mae: 0.9899 - val_loss: 11.7428 - val_mae: 2.3457\n",
            "Epoch 120/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.7525 - mae: 0.9781 - val_loss: 10.3979 - val_mae: 2.2770\n",
            "Epoch 121/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.7635 - mae: 0.9724 - val_loss: 14.4125 - val_mae: 2.4270\n",
            "Epoch 122/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.1131 - mae: 1.0700 - val_loss: 10.9703 - val_mae: 2.3343\n",
            "Epoch 123/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.6873 - mae: 0.9172 - val_loss: 12.6573 - val_mae: 2.4279\n",
            "Epoch 124/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.4018 - mae: 0.8583 - val_loss: 10.8577 - val_mae: 2.1702\n",
            "Epoch 125/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.9065 - mae: 0.9769 - val_loss: 10.5784 - val_mae: 2.2305\n",
            "Epoch 126/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.6344 - mae: 0.9584 - val_loss: 11.6382 - val_mae: 2.2635\n",
            "Epoch 127/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.4506 - mae: 0.8383 - val_loss: 13.7475 - val_mae: 2.6232\n",
            "Epoch 128/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.6060 - mae: 0.8851 - val_loss: 10.3647 - val_mae: 2.2431\n",
            "Epoch 129/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.4213 - mae: 0.8698 - val_loss: 10.1340 - val_mae: 2.1789\n",
            "Epoch 130/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.4071 - mae: 0.8361 - val_loss: 11.4640 - val_mae: 2.1985\n",
            "Epoch 131/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.0070 - mae: 1.0460 - val_loss: 9.7723 - val_mae: 2.1423\n",
            "Epoch 132/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.8275 - mae: 0.9640 - val_loss: 12.2769 - val_mae: 2.3390\n",
            "Epoch 133/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 2.7832 - mae: 1.2552 - val_loss: 11.5704 - val_mae: 2.3387\n",
            "Epoch 134/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.6383 - mae: 1.0908 - val_loss: 10.0126 - val_mae: 2.1561\n",
            "Epoch 135/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.6630 - mae: 1.1080 - val_loss: 10.9761 - val_mae: 2.2846\n",
            "Epoch 136/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.4487 - mae: 0.9116 - val_loss: 10.3050 - val_mae: 2.2179\n",
            "Epoch 137/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.6307 - mae: 0.9345 - val_loss: 13.3823 - val_mae: 2.4874\n",
            "Epoch 138/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.9136 - mae: 0.9525 - val_loss: 9.1828 - val_mae: 2.2106\n",
            "Epoch 139/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.4096 - mae: 0.8492 - val_loss: 11.1989 - val_mae: 2.3314\n",
            "Epoch 140/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.3279 - mae: 0.8339 - val_loss: 9.9229 - val_mae: 2.1673\n",
            "Epoch 141/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.0381 - mae: 0.9896 - val_loss: 13.1115 - val_mae: 2.3991\n",
            "Epoch 142/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.3503 - mae: 0.8299 - val_loss: 10.5048 - val_mae: 2.2052\n",
            "Epoch 143/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.3705 - mae: 0.8778 - val_loss: 10.0501 - val_mae: 2.1222\n",
            "Epoch 144/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.7584 - mae: 0.9682 - val_loss: 11.5472 - val_mae: 2.3076\n",
            "Epoch 145/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.2912 - mae: 0.7817 - val_loss: 10.9372 - val_mae: 2.2389\n",
            "Epoch 146/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.5851 - mae: 0.8880 - val_loss: 11.2761 - val_mae: 2.3533\n",
            "Epoch 147/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.3846 - mae: 0.8694 - val_loss: 10.0645 - val_mae: 2.2661\n",
            "Epoch 148/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.8715 - mae: 0.9952 - val_loss: 11.3935 - val_mae: 2.2868\n",
            "Epoch 149/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.3529 - mae: 0.8255 - val_loss: 9.9282 - val_mae: 2.2640\n",
            "Epoch 150/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.1673 - mae: 0.7685 - val_loss: 13.2231 - val_mae: 2.7141\n",
            "Epoch 151/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.5521 - mae: 0.9262 - val_loss: 11.5141 - val_mae: 2.4719\n",
            "Epoch 152/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.3318 - mae: 0.8566 - val_loss: 10.6730 - val_mae: 2.2567\n",
            "Epoch 153/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.0797 - mae: 0.7390 - val_loss: 11.1016 - val_mae: 2.2949\n",
            "Epoch 154/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.9396 - mae: 1.0296 - val_loss: 12.0200 - val_mae: 2.5200\n",
            "Epoch 155/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.6958 - mae: 0.9347 - val_loss: 10.6757 - val_mae: 2.3441\n",
            "Epoch 156/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.4617 - mae: 0.8674 - val_loss: 10.6586 - val_mae: 2.2825\n",
            "Epoch 157/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.3491 - mae: 0.8364 - val_loss: 10.2655 - val_mae: 2.2549\n",
            "Epoch 158/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.4748 - mae: 0.8645 - val_loss: 11.1665 - val_mae: 2.4210\n",
            "Epoch 159/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.4800 - mae: 0.8669 - val_loss: 12.4611 - val_mae: 2.4950\n",
            "Epoch 160/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.4943 - mae: 0.8881 - val_loss: 11.2916 - val_mae: 2.3589\n",
            "Epoch 161/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.8547 - mae: 0.6829 - val_loss: 10.5167 - val_mae: 2.2101\n",
            "Epoch 162/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.1036 - mae: 0.7448 - val_loss: 10.7494 - val_mae: 2.2779\n",
            "Epoch 163/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.3799 - mae: 0.8539 - val_loss: 11.8648 - val_mae: 2.4259\n",
            "Epoch 164/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.2452 - mae: 0.8093 - val_loss: 10.3423 - val_mae: 2.2216\n",
            "Epoch 165/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.0731 - mae: 0.7415 - val_loss: 10.6544 - val_mae: 2.3094\n",
            "Epoch 166/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.2629 - mae: 0.7959 - val_loss: 15.4437 - val_mae: 2.6750\n",
            "Epoch 167/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.9290 - mae: 1.2105 - val_loss: 12.0168 - val_mae: 2.2638\n",
            "Epoch 168/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.2527 - mae: 1.0751 - val_loss: 12.0160 - val_mae: 2.3360\n",
            "Epoch 169/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.7223 - mae: 0.9103 - val_loss: 13.5076 - val_mae: 2.4089\n",
            "Epoch 170/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.4155 - mae: 0.8332 - val_loss: 10.3983 - val_mae: 2.2899\n",
            "Epoch 171/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.4555 - mae: 0.8539 - val_loss: 12.8486 - val_mae: 2.4349\n",
            "Epoch 172/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.9497 - mae: 0.6805 - val_loss: 11.6568 - val_mae: 2.4160\n",
            "Epoch 173/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.1870 - mae: 0.7450 - val_loss: 11.4075 - val_mae: 2.3125\n",
            "Epoch 174/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.1910 - mae: 0.7796 - val_loss: 10.6981 - val_mae: 2.3091\n",
            "Epoch 175/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.2456 - mae: 0.7889 - val_loss: 11.6920 - val_mae: 2.4775\n",
            "Epoch 176/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.1670 - mae: 0.8003 - val_loss: 11.3253 - val_mae: 2.2042\n",
            "Epoch 177/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.9230 - mae: 0.6788 - val_loss: 11.0872 - val_mae: 2.3419\n",
            "Epoch 178/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.9926 - mae: 0.7073 - val_loss: 12.1364 - val_mae: 2.3480\n",
            "Epoch 179/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.2254 - mae: 0.8027 - val_loss: 10.7629 - val_mae: 2.2526\n",
            "Epoch 180/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.5792 - mae: 0.8718 - val_loss: 11.0370 - val_mae: 2.2801\n",
            "Epoch 181/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.1888 - mae: 0.7722 - val_loss: 11.3092 - val_mae: 2.2975\n",
            "Epoch 182/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.1164 - mae: 0.7903 - val_loss: 11.3117 - val_mae: 2.3146\n",
            "Epoch 183/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.4986 - mae: 0.8769 - val_loss: 10.7619 - val_mae: 2.2862\n",
            "Epoch 184/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.4084 - mae: 0.8184 - val_loss: 11.7492 - val_mae: 2.3860\n",
            "Epoch 185/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.4078 - mae: 0.8063 - val_loss: 10.4833 - val_mae: 2.3306\n",
            "Epoch 186/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.3550 - mae: 0.8312 - val_loss: 11.9459 - val_mae: 2.3092\n",
            "Epoch 187/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.4817 - mae: 0.8623 - val_loss: 10.4807 - val_mae: 2.2273\n",
            "Epoch 188/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 0.7999 - mae: 0.6680 - val_loss: 11.4217 - val_mae: 2.2768\n",
            "Epoch 189/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.0572 - mae: 0.7396 - val_loss: 11.3596 - val_mae: 2.3215\n",
            "Epoch 190/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.0929 - mae: 0.7592 - val_loss: 11.6328 - val_mae: 2.4068\n",
            "Epoch 191/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 0.8998 - mae: 0.6706 - val_loss: 10.3206 - val_mae: 2.2292\n",
            "Epoch 192/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.8676 - mae: 0.7338 - val_loss: 11.6062 - val_mae: 2.2983\n",
            "Epoch 193/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.0776 - mae: 0.7666 - val_loss: 11.7459 - val_mae: 2.4632\n",
            "Epoch 194/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.1732 - mae: 0.7804 - val_loss: 9.8684 - val_mae: 2.3160\n",
            "Epoch 195/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.5580 - mae: 0.8786 - val_loss: 11.5716 - val_mae: 2.3548\n",
            "Epoch 196/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.0311 - mae: 0.9829 - val_loss: 11.6908 - val_mae: 2.4284\n",
            "Epoch 197/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 2.4365 - mae: 1.0944 - val_loss: 13.0457 - val_mae: 2.6456\n",
            "Epoch 198/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.4313 - mae: 0.8442 - val_loss: 11.6781 - val_mae: 2.3350\n",
            "Epoch 199/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.1113 - mae: 0.7305 - val_loss: 10.7513 - val_mae: 2.2456\n",
            "Epoch 200/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.0230 - mae: 0.7451 - val_loss: 12.2230 - val_mae: 2.4269\n",
            "Epoch 201/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.9785 - mae: 0.7035 - val_loss: 11.4634 - val_mae: 2.3238\n",
            "Epoch 202/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.9489 - mae: 0.7054 - val_loss: 11.8094 - val_mae: 2.5354\n",
            "Epoch 203/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.3096 - mae: 0.7675 - val_loss: 11.6009 - val_mae: 2.4698\n",
            "Epoch 204/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.8897 - mae: 0.6975 - val_loss: 12.4033 - val_mae: 2.3562\n",
            "Epoch 205/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.9982 - mae: 0.7019 - val_loss: 11.0256 - val_mae: 2.3902\n",
            "Epoch 206/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.8652 - mae: 0.6196 - val_loss: 10.5245 - val_mae: 2.2816\n",
            "Epoch 207/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.9159 - mae: 0.6858 - val_loss: 10.8677 - val_mae: 2.3263\n",
            "Epoch 208/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.1006 - mae: 0.7209 - val_loss: 11.3174 - val_mae: 2.3763\n",
            "Epoch 209/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.9129 - mae: 0.6751 - val_loss: 11.8337 - val_mae: 2.4248\n",
            "Epoch 210/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.9726 - mae: 0.7115 - val_loss: 10.9074 - val_mae: 2.4328\n",
            "Epoch 211/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.2490 - mae: 0.8119 - val_loss: 11.1739 - val_mae: 2.3582\n",
            "Epoch 212/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.0264 - mae: 0.7248 - val_loss: 11.3592 - val_mae: 2.4683\n",
            "Epoch 213/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.8494 - mae: 0.6939 - val_loss: 12.1974 - val_mae: 2.3455\n",
            "Epoch 214/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.1098 - mae: 0.7947 - val_loss: 11.3186 - val_mae: 2.3572\n",
            "Epoch 215/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.0870 - mae: 0.7321 - val_loss: 11.2781 - val_mae: 2.2902\n",
            "Epoch 216/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 1.0715 - mae: 0.7371 - val_loss: 9.9127 - val_mae: 2.2491\n",
            "Epoch 217/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.9857 - mae: 0.6812 - val_loss: 11.0426 - val_mae: 2.3906\n",
            "Epoch 218/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.2092 - mae: 0.7837 - val_loss: 10.7931 - val_mae: 2.3542\n",
            "Epoch 219/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.0874 - mae: 0.7271 - val_loss: 11.6686 - val_mae: 2.3967\n",
            "Epoch 220/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.1825 - mae: 0.7795 - val_loss: 10.0275 - val_mae: 2.2864\n",
            "Epoch 221/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.0626 - mae: 0.7416 - val_loss: 10.6219 - val_mae: 2.3456\n",
            "Epoch 222/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.4542 - mae: 0.8326 - val_loss: 10.6971 - val_mae: 2.3199\n",
            "Epoch 223/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.5904 - mae: 0.8629 - val_loss: 12.4213 - val_mae: 2.3689\n",
            "Epoch 224/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.2023 - mae: 0.7384 - val_loss: 11.4926 - val_mae: 2.3721\n",
            "Epoch 225/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.2495 - mae: 0.7733 - val_loss: 10.3533 - val_mae: 2.3612\n",
            "Epoch 226/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.3727 - mae: 0.8515 - val_loss: 10.6845 - val_mae: 2.2726\n",
            "Epoch 227/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.0236 - mae: 0.7146 - val_loss: 10.4647 - val_mae: 2.3237\n",
            "Epoch 228/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.9431 - mae: 0.6784 - val_loss: 11.8599 - val_mae: 2.3954\n",
            "Epoch 229/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.2124 - mae: 0.7990 - val_loss: 12.2624 - val_mae: 2.4358\n",
            "Epoch 230/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.1964 - mae: 0.7654 - val_loss: 10.8272 - val_mae: 2.3067\n",
            "Epoch 231/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.1140 - mae: 0.7238 - val_loss: 11.4370 - val_mae: 2.4703\n",
            "Epoch 232/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.2139 - mae: 0.7745 - val_loss: 10.2538 - val_mae: 2.3053\n",
            "Epoch 233/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.2378 - mae: 0.7570 - val_loss: 12.3513 - val_mae: 2.5418\n",
            "Epoch 234/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.3976 - mae: 0.8542 - val_loss: 11.6149 - val_mae: 2.3259\n",
            "Epoch 235/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.1509 - mae: 0.7754 - val_loss: 10.4099 - val_mae: 2.2369\n",
            "Epoch 236/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 0.5375 - mae: 0.5143 - val_loss: 10.7731 - val_mae: 2.3723\n",
            "Epoch 237/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 0.7667 - mae: 0.6081 - val_loss: 10.6629 - val_mae: 2.3525\n",
            "Epoch 238/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.7893 - mae: 0.6103 - val_loss: 10.3177 - val_mae: 2.2997\n",
            "Epoch 239/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.7870 - mae: 0.6099 - val_loss: 11.5804 - val_mae: 2.4488\n",
            "Epoch 240/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.9165 - mae: 0.6824 - val_loss: 10.5062 - val_mae: 2.3101\n",
            "Epoch 241/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.5562 - mae: 0.5464 - val_loss: 10.5959 - val_mae: 2.2668\n",
            "Epoch 242/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.5726 - mae: 0.5263 - val_loss: 10.5899 - val_mae: 2.3317\n",
            "Epoch 243/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.7612 - mae: 0.5918 - val_loss: 11.7318 - val_mae: 2.5141\n",
            "Epoch 244/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.1942 - mae: 0.7656 - val_loss: 10.4477 - val_mae: 2.3918\n",
            "Epoch 245/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.0244 - mae: 0.7390 - val_loss: 11.4933 - val_mae: 2.5154\n",
            "Epoch 246/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.9229 - mae: 0.6826 - val_loss: 12.0432 - val_mae: 2.4449\n",
            "Epoch 247/300\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.8421 - mae: 0.6669 - val_loss: 10.3609 - val_mae: 2.3569\n",
            "Epoch 248/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.9781 - mae: 0.6944 - val_loss: 10.1443 - val_mae: 2.3228\n",
            "Epoch 249/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.8845 - mae: 0.6461 - val_loss: 12.1746 - val_mae: 2.3545\n",
            "Epoch 250/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.7926 - mae: 0.6426 - val_loss: 10.3895 - val_mae: 2.3079\n",
            "Epoch 251/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.1536 - mae: 0.7394 - val_loss: 11.5373 - val_mae: 2.3976\n",
            "Epoch 252/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.1907 - mae: 0.7230 - val_loss: 12.7553 - val_mae: 2.5648\n",
            "Epoch 253/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.6180 - mae: 0.8541 - val_loss: 14.6872 - val_mae: 2.6712\n",
            "Epoch 254/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 2.0887 - mae: 0.9826 - val_loss: 11.7651 - val_mae: 2.4070\n",
            "Epoch 255/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.8310 - mae: 0.6527 - val_loss: 13.9226 - val_mae: 2.6130\n",
            "Epoch 256/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.7289 - mae: 0.5997 - val_loss: 11.2043 - val_mae: 2.2712\n",
            "Epoch 257/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.5288 - mae: 0.5119 - val_loss: 11.2477 - val_mae: 2.3145\n",
            "Epoch 258/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.6243 - mae: 0.5335 - val_loss: 11.9245 - val_mae: 2.3757\n",
            "Epoch 259/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.7154 - mae: 0.5748 - val_loss: 10.7234 - val_mae: 2.3331\n",
            "Epoch 260/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.1216 - mae: 0.7425 - val_loss: 12.1986 - val_mae: 2.3984\n",
            "Epoch 261/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.1903 - mae: 0.7812 - val_loss: 11.3348 - val_mae: 2.3266\n",
            "Epoch 262/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.7252 - mae: 0.5749 - val_loss: 11.2965 - val_mae: 2.4089\n",
            "Epoch 263/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 0.8320 - mae: 0.6380 - val_loss: 13.0868 - val_mae: 2.4896\n",
            "Epoch 264/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.8938 - mae: 0.6844 - val_loss: 10.7699 - val_mae: 2.3075\n",
            "Epoch 265/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.5737 - mae: 0.5696 - val_loss: 11.5240 - val_mae: 2.3328\n",
            "Epoch 266/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 0.6211 - mae: 0.5577 - val_loss: 10.5854 - val_mae: 2.2662\n",
            "Epoch 267/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 0.6283 - mae: 0.5636 - val_loss: 11.7865 - val_mae: 2.3338\n",
            "Epoch 268/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.0115 - mae: 0.7024 - val_loss: 11.2218 - val_mae: 2.3035\n",
            "Epoch 269/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.5925 - mae: 0.5309 - val_loss: 11.7363 - val_mae: 2.3127\n",
            "Epoch 270/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.9586 - mae: 0.7050 - val_loss: 10.8855 - val_mae: 2.2989\n",
            "Epoch 271/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.7923 - mae: 0.6367 - val_loss: 12.1029 - val_mae: 2.4586\n",
            "Epoch 272/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.8106 - mae: 0.6488 - val_loss: 11.2346 - val_mae: 2.3392\n",
            "Epoch 273/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.5081 - mae: 0.5246 - val_loss: 10.8013 - val_mae: 2.3467\n",
            "Epoch 274/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.5986 - mae: 0.5306 - val_loss: 11.9397 - val_mae: 2.3729\n",
            "Epoch 275/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.1564 - mae: 0.7497 - val_loss: 10.8080 - val_mae: 2.2596\n",
            "Epoch 276/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.8186 - mae: 0.6627 - val_loss: 12.1977 - val_mae: 2.3725\n",
            "Epoch 277/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.3358 - mae: 0.7619 - val_loss: 12.2159 - val_mae: 2.6343\n",
            "Epoch 278/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 1.2047 - mae: 0.7419 - val_loss: 14.9403 - val_mae: 2.5119\n",
            "Epoch 279/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.8730 - mae: 0.6310 - val_loss: 10.5128 - val_mae: 2.2669\n",
            "Epoch 280/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.6468 - mae: 0.5626 - val_loss: 11.4743 - val_mae: 2.4031\n",
            "Epoch 281/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.0586 - mae: 0.7207 - val_loss: 11.9706 - val_mae: 2.3876\n",
            "Epoch 282/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.8921 - mae: 0.6755 - val_loss: 12.0383 - val_mae: 2.4709\n",
            "Epoch 283/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.6035 - mae: 0.5541 - val_loss: 10.3067 - val_mae: 2.2635\n",
            "Epoch 284/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.8801 - mae: 0.8356 - val_loss: 11.2263 - val_mae: 2.3237\n",
            "Epoch 285/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 0.6455 - mae: 0.5375 - val_loss: 11.3590 - val_mae: 2.3398\n",
            "Epoch 286/300\n",
            "152/152 [==============================] - 1s 6ms/step - loss: 0.6196 - mae: 0.5252 - val_loss: 11.0589 - val_mae: 2.3111\n",
            "Epoch 287/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 0.7747 - mae: 0.5969 - val_loss: 11.1217 - val_mae: 2.3599\n",
            "Epoch 288/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 0.6955 - mae: 0.5755 - val_loss: 11.4435 - val_mae: 2.2896\n",
            "Epoch 289/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 0.5126 - mae: 0.5389 - val_loss: 10.9412 - val_mae: 2.2889\n",
            "Epoch 290/300\n",
            "152/152 [==============================] - 1s 5ms/step - loss: 0.4051 - mae: 0.4368 - val_loss: 12.2295 - val_mae: 2.4381\n",
            "Epoch 291/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.4219 - mae: 0.4684 - val_loss: 13.1389 - val_mae: 2.6330\n",
            "Epoch 292/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.8207 - mae: 0.6497 - val_loss: 11.5535 - val_mae: 2.3826\n",
            "Epoch 293/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.0264 - mae: 0.7471 - val_loss: 12.1629 - val_mae: 2.3775\n",
            "Epoch 294/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.1151 - mae: 0.7455 - val_loss: 10.1185 - val_mae: 2.2241\n",
            "Epoch 295/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.6712 - mae: 0.5923 - val_loss: 11.3463 - val_mae: 2.3464\n",
            "Epoch 296/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.8636 - mae: 0.6250 - val_loss: 11.0933 - val_mae: 2.3018\n",
            "Epoch 297/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.8950 - mae: 0.6455 - val_loss: 11.2070 - val_mae: 2.3714\n",
            "Epoch 298/300\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.7014 - mae: 0.5990 - val_loss: 11.3102 - val_mae: 2.3213\n",
            "Epoch 299/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.5799 - mae: 0.4998 - val_loss: 11.4885 - val_mae: 2.4518\n",
            "Epoch 300/300\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.6856 - mae: 0.5954 - val_loss: 11.1663 - val_mae: 2.3804\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 300 \n",
        "all_mae_histories = []\n",
        "for i in range(k):\n",
        "  print('processing fold #', i)\n",
        "  val_data = train_data[i * num_val_samples : (i + 1) * num_val_samples]\n",
        "  val_targets = train_targets[i * num_val_samples : (i + 1) * num_val_samples]\n",
        "  partial_train_data = np.concatenate([train_data[:i * num_val_samples], train_data[(i + 1) * num_val_samples:]], axis=0)\n",
        "  partial_train_targets = np.concatenate([train_targets[:i * num_val_samples], train_targets[(i + 1) * num_val_samples:]], axis=0)\n",
        "  model = build_model()\n",
        "  history = model.fit(\n",
        "      partial_train_data, partial_train_targets, \n",
        "      validation_data=(val_data, val_targets), \n",
        "      epochs=num_epochs, batch_size=2, verbose=1\n",
        "  )\n",
        "  mae_history = history.history['val_mae']\n",
        "  all_mae_histories.append(mae_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naIUJXjZeL6-",
        "outputId": "cdd7cbd3-dadb-4422-eca2-f9c0bee9149c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.6426777839660645, 4.809749603271484, 3.7315738201141357, 4.727965831756592]"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "[x[0] for x in all_mae_histories]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0Rj40-seNTo"
      },
      "outputs": [],
      "source": [
        "average_mae_history = [np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "X9bWycPtffOn",
        "outputId": "b1e05608-648f-4b16-b240-57aa9c9c1223"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(range(1, len(average_mae_history) + 1), average_mae_history)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation MAE')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToEBYL3rfwdw",
        "outputId": "85808247-8a6a-4d49-8f9e-042017026d13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "202/202 [==============================] - 1s 2ms/step - loss: 157.5936 - mae: 8.6189\n",
            "Epoch 2/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 20.1051 - mae: 3.1574\n",
            "Epoch 3/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 15.5126 - mae: 2.8014\n",
            "Epoch 4/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 13.7757 - mae: 2.6546\n",
            "Epoch 5/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 12.6388 - mae: 2.5171\n",
            "Epoch 6/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 10.6981 - mae: 2.4000\n",
            "Epoch 7/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 11.6667 - mae: 2.4590\n",
            "Epoch 8/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 9.7826 - mae: 2.1971\n",
            "Epoch 9/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 10.2715 - mae: 2.3370\n",
            "Epoch 10/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 8.8407 - mae: 2.1868\n",
            "Epoch 11/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 8.8670 - mae: 2.0830\n",
            "Epoch 12/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 7.7069 - mae: 2.0056\n",
            "Epoch 13/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 9.5047 - mae: 2.2112\n",
            "Epoch 14/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 8.5328 - mae: 2.1279\n",
            "Epoch 15/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 7.9972 - mae: 2.0529\n",
            "Epoch 16/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 7.1398 - mae: 1.9303\n",
            "Epoch 17/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 6.9764 - mae: 1.9093\n",
            "Epoch 18/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 6.6507 - mae: 1.8868\n",
            "Epoch 19/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 6.9501 - mae: 1.9348\n",
            "Epoch 20/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 8.0581 - mae: 2.1307\n",
            "Epoch 21/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 6.1399 - mae: 1.8431\n",
            "Epoch 22/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 5.5589 - mae: 1.7791\n",
            "Epoch 23/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 5.3153 - mae: 1.7546\n",
            "Epoch 24/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 6.8700 - mae: 1.8846\n",
            "Epoch 25/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 5.6316 - mae: 1.7521\n",
            "Epoch 26/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 4.7828 - mae: 1.6621\n",
            "Epoch 27/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 5.0054 - mae: 1.6467\n",
            "Epoch 28/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 4.8732 - mae: 1.6865\n",
            "Epoch 29/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 5.3417 - mae: 1.6800\n",
            "Epoch 30/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 4.2722 - mae: 1.5868\n",
            "Epoch 31/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 4.8264 - mae: 1.5786\n",
            "Epoch 32/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 5.0437 - mae: 1.6710\n",
            "Epoch 33/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 4.0665 - mae: 1.5351\n",
            "Epoch 34/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 4.2889 - mae: 1.5682\n",
            "Epoch 35/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 4.4852 - mae: 1.5934\n",
            "Epoch 36/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 4.4424 - mae: 1.5818\n",
            "Epoch 37/300\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 4.1684 - mae: 1.5158\n",
            "Epoch 38/300\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 3.5795 - mae: 1.4280\n",
            "Epoch 39/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 4.1033 - mae: 1.5215\n",
            "Epoch 40/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 3.6278 - mae: 1.4484\n",
            "Epoch 41/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 3.3780 - mae: 1.4019\n",
            "Epoch 42/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 3.8562 - mae: 1.4711\n",
            "Epoch 43/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 3.8389 - mae: 1.4568\n",
            "Epoch 44/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 3.3402 - mae: 1.3853\n",
            "Epoch 45/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 5.2671 - mae: 1.6541\n",
            "Epoch 46/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 3.5619 - mae: 1.4038\n",
            "Epoch 47/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 4.0626 - mae: 1.4957\n",
            "Epoch 48/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 3.7200 - mae: 1.4273\n",
            "Epoch 49/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 4.4569 - mae: 1.5400\n",
            "Epoch 50/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 4.6848 - mae: 1.5803\n",
            "Epoch 51/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 3.1467 - mae: 1.3411\n",
            "Epoch 52/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 3.1312 - mae: 1.3375\n",
            "Epoch 53/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 3.7116 - mae: 1.4399\n",
            "Epoch 54/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 3.1760 - mae: 1.3307\n",
            "Epoch 55/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.9875 - mae: 1.3371\n",
            "Epoch 56/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 3.3485 - mae: 1.4193\n",
            "Epoch 57/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.8777 - mae: 1.3054\n",
            "Epoch 58/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 3.2174 - mae: 1.3210\n",
            "Epoch 59/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 3.6979 - mae: 1.4210\n",
            "Epoch 60/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 3.3908 - mae: 1.3677\n",
            "Epoch 61/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 2.9313 - mae: 1.2888\n",
            "Epoch 62/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.6079 - mae: 1.1918\n",
            "Epoch 63/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.5515 - mae: 1.1988\n",
            "Epoch 64/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 2.5881 - mae: 1.2146\n",
            "Epoch 65/300\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 2.6340 - mae: 1.2178\n",
            "Epoch 66/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 2.7624 - mae: 1.2505\n",
            "Epoch 67/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 2.8057 - mae: 1.2506\n",
            "Epoch 68/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.4611 - mae: 1.1457\n",
            "Epoch 69/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.5524 - mae: 1.2205\n",
            "Epoch 70/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.6265 - mae: 1.2138\n",
            "Epoch 71/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.9750 - mae: 1.2745\n",
            "Epoch 72/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.5030 - mae: 1.1912\n",
            "Epoch 73/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.5167 - mae: 1.1720\n",
            "Epoch 74/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 3.1376 - mae: 1.3301\n",
            "Epoch 75/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.7491 - mae: 1.2346\n",
            "Epoch 76/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.2580 - mae: 1.1220\n",
            "Epoch 77/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 3.3464 - mae: 1.3102\n",
            "Epoch 78/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 3.0147 - mae: 1.2728\n",
            "Epoch 79/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.1182 - mae: 1.0873\n",
            "Epoch 80/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.2451 - mae: 1.1219\n",
            "Epoch 81/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.3552 - mae: 1.1370\n",
            "Epoch 82/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.2174 - mae: 1.1534\n",
            "Epoch 83/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.0172 - mae: 1.0835\n",
            "Epoch 84/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.0184 - mae: 1.0589\n",
            "Epoch 85/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.1498 - mae: 1.0829\n",
            "Epoch 86/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.2305 - mae: 1.1189\n",
            "Epoch 87/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.4867 - mae: 1.1596\n",
            "Epoch 88/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.1737 - mae: 1.1284\n",
            "Epoch 89/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.7048 - mae: 0.9994\n",
            "Epoch 90/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.5286 - mae: 1.1877\n",
            "Epoch 91/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.1989 - mae: 1.1161\n",
            "Epoch 92/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 2.5875 - mae: 1.1871\n",
            "Epoch 93/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 2.7310 - mae: 1.2111\n",
            "Epoch 94/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 2.1748 - mae: 1.1206\n",
            "Epoch 95/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 1.9844 - mae: 1.0737\n",
            "Epoch 96/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 1.7757 - mae: 1.0050\n",
            "Epoch 97/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.9085 - mae: 1.0471\n",
            "Epoch 98/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.7076 - mae: 0.9804\n",
            "Epoch 99/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.0574 - mae: 1.0794\n",
            "Epoch 100/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.9262 - mae: 1.0341\n",
            "Epoch 101/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.7785 - mae: 1.1694\n",
            "Epoch 102/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 3.1842 - mae: 1.2099\n",
            "Epoch 103/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.2457 - mae: 1.1421\n",
            "Epoch 104/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.7343 - mae: 0.9782\n",
            "Epoch 105/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.7228 - mae: 0.9735\n",
            "Epoch 106/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.6053 - mae: 0.9472\n",
            "Epoch 107/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.6985 - mae: 0.9611\n",
            "Epoch 108/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.7931 - mae: 0.9718\n",
            "Epoch 109/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.0046 - mae: 1.0490\n",
            "Epoch 110/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.5559 - mae: 0.9235\n",
            "Epoch 111/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.7147 - mae: 0.9517\n",
            "Epoch 112/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.9462 - mae: 1.0359\n",
            "Epoch 113/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.1139 - mae: 1.0985\n",
            "Epoch 114/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.1691 - mae: 1.0472\n",
            "Epoch 115/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.8739 - mae: 1.0211\n",
            "Epoch 116/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.7929 - mae: 1.0155\n",
            "Epoch 117/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.3649 - mae: 1.1182\n",
            "Epoch 118/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.3247 - mae: 1.1387\n",
            "Epoch 119/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.6580 - mae: 0.9367\n",
            "Epoch 120/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 1.4011 - mae: 0.8967\n",
            "Epoch 121/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 1.9555 - mae: 1.0016\n",
            "Epoch 122/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 1.6027 - mae: 0.9282\n",
            "Epoch 123/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 1.5753 - mae: 0.9285\n",
            "Epoch 124/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 1.6945 - mae: 0.9532\n",
            "Epoch 125/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.7853 - mae: 0.9327\n",
            "Epoch 126/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.6973 - mae: 0.9744\n",
            "Epoch 127/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.7926 - mae: 0.9681\n",
            "Epoch 128/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.8953 - mae: 0.9988\n",
            "Epoch 129/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.9384 - mae: 1.0113\n",
            "Epoch 130/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.6529 - mae: 0.9509\n",
            "Epoch 131/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.4348 - mae: 0.9130\n",
            "Epoch 132/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.4766 - mae: 0.9096\n",
            "Epoch 133/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.1398 - mae: 0.7800\n",
            "Epoch 134/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.6310 - mae: 0.9399\n",
            "Epoch 135/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.4629 - mae: 0.8692\n",
            "Epoch 136/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.4835 - mae: 0.8462\n",
            "Epoch 137/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.5221 - mae: 0.9402\n",
            "Epoch 138/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.4417 - mae: 0.8732\n",
            "Epoch 139/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.6355 - mae: 0.9402\n",
            "Epoch 140/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.4951 - mae: 0.8897\n",
            "Epoch 141/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.6929 - mae: 0.9845\n",
            "Epoch 142/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.4049 - mae: 0.8917\n",
            "Epoch 143/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.4820 - mae: 0.8934\n",
            "Epoch 144/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.3345 - mae: 0.8530\n",
            "Epoch 145/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.5925 - mae: 0.9291\n",
            "Epoch 146/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.6567 - mae: 0.9254\n",
            "Epoch 147/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.4856 - mae: 0.9042\n",
            "Epoch 148/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 1.1587 - mae: 0.7510\n",
            "Epoch 149/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 1.6575 - mae: 0.9625\n",
            "Epoch 150/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 1.5474 - mae: 0.8868\n",
            "Epoch 151/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 1.2273 - mae: 0.8075\n",
            "Epoch 152/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 1.5408 - mae: 0.8826\n",
            "Epoch 153/300\n",
            "202/202 [==============================] - 1s 2ms/step - loss: 1.3790 - mae: 0.8647\n",
            "Epoch 154/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.1095 - mae: 0.7698\n",
            "Epoch 155/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.3471 - mae: 0.8846\n",
            "Epoch 156/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.7452 - mae: 0.9836\n",
            "Epoch 157/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.9495 - mae: 1.0225\n",
            "Epoch 158/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.9818 - mae: 0.9785\n",
            "Epoch 159/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.7031 - mae: 0.9298\n",
            "Epoch 160/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.3342 - mae: 0.8313\n",
            "Epoch 161/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.3182 - mae: 0.8603\n",
            "Epoch 162/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.2424 - mae: 0.7967\n",
            "Epoch 163/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.0829 - mae: 0.7361\n",
            "Epoch 164/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.0898 - mae: 0.7897\n",
            "Epoch 165/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.2908 - mae: 0.8215\n",
            "Epoch 166/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.3740 - mae: 0.8377\n",
            "Epoch 167/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.3080 - mae: 0.8758\n",
            "Epoch 168/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.0790 - mae: 0.7613\n",
            "Epoch 169/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.4593 - mae: 0.8729\n",
            "Epoch 170/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.0533 - mae: 0.7611\n",
            "Epoch 171/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.3054 - mae: 0.8607\n",
            "Epoch 172/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.0438 - mae: 0.7632\n",
            "Epoch 173/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.2675 - mae: 0.8022\n",
            "Epoch 174/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.0934 - mae: 0.7271\n",
            "Epoch 175/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.0433 - mae: 0.7488\n",
            "Epoch 176/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.3561 - mae: 0.8392\n",
            "Epoch 177/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.8929 - mae: 0.7005\n",
            "Epoch 178/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 1.0742 - mae: 0.7589\n",
            "Epoch 179/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 1.8032 - mae: 0.9222\n",
            "Epoch 180/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 1.5918 - mae: 0.9118\n",
            "Epoch 181/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 1.2962 - mae: 0.8073\n",
            "Epoch 182/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.0592 - mae: 0.7707\n",
            "Epoch 183/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.9256 - mae: 0.7159\n",
            "Epoch 184/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.0047 - mae: 0.7212\n",
            "Epoch 185/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.1255 - mae: 0.7898\n",
            "Epoch 186/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.1979 - mae: 0.7823\n",
            "Epoch 187/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.9803 - mae: 0.7245\n",
            "Epoch 188/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.3115 - mae: 0.8103\n",
            "Epoch 189/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.5606 - mae: 0.9152\n",
            "Epoch 190/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.5420 - mae: 0.8890\n",
            "Epoch 191/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.9865 - mae: 0.7167\n",
            "Epoch 192/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.0070 - mae: 0.7356\n",
            "Epoch 193/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.0551 - mae: 0.7418\n",
            "Epoch 194/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.0919 - mae: 0.7102\n",
            "Epoch 195/300\n",
            "202/202 [==============================] - 1s 2ms/step - loss: 1.7435 - mae: 0.9490\n",
            "Epoch 196/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.1605 - mae: 0.7570\n",
            "Epoch 197/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.3196 - mae: 0.8032\n",
            "Epoch 198/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.3535 - mae: 0.7993\n",
            "Epoch 199/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.2416 - mae: 0.7731\n",
            "Epoch 200/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.0619 - mae: 0.7165\n",
            "Epoch 201/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.0389 - mae: 0.7060\n",
            "Epoch 202/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.0744 - mae: 0.7138\n",
            "Epoch 203/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.9887 - mae: 0.7222\n",
            "Epoch 204/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 1.3557 - mae: 0.8384\n",
            "Epoch 205/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.9040 - mae: 0.7150\n",
            "Epoch 206/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 1.0376 - mae: 0.7358\n",
            "Epoch 207/300\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 1.0550 - mae: 0.7495\n",
            "Epoch 208/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.0674 - mae: 0.7682\n",
            "Epoch 209/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.3081 - mae: 0.8140\n",
            "Epoch 210/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.0412 - mae: 0.7538\n",
            "Epoch 211/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.9410 - mae: 0.7201\n",
            "Epoch 212/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.0533 - mae: 0.7153\n",
            "Epoch 213/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.9263 - mae: 0.6837\n",
            "Epoch 214/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.0998 - mae: 0.7670\n",
            "Epoch 215/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.9479 - mae: 0.7157\n",
            "Epoch 216/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.0221 - mae: 0.7642\n",
            "Epoch 217/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.9915 - mae: 0.7343\n",
            "Epoch 218/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.9531 - mae: 0.7196\n",
            "Epoch 219/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.2483 - mae: 0.7921\n",
            "Epoch 220/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.9814 - mae: 0.7339\n",
            "Epoch 221/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.9080 - mae: 0.6855\n",
            "Epoch 222/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.9473 - mae: 0.6852\n",
            "Epoch 223/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.0148 - mae: 0.7405\n",
            "Epoch 224/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.9204 - mae: 0.6803\n",
            "Epoch 225/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.9129 - mae: 0.6710\n",
            "Epoch 226/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.1873 - mae: 0.7884\n",
            "Epoch 227/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.9745 - mae: 0.6784\n",
            "Epoch 228/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.0265 - mae: 0.7585\n",
            "Epoch 229/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.5855 - mae: 0.8803\n",
            "Epoch 230/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 1.2074 - mae: 0.7816\n",
            "Epoch 231/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.9517 - mae: 0.6741\n",
            "Epoch 232/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.7936 - mae: 0.6137\n",
            "Epoch 233/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.7671 - mae: 0.6111\n",
            "Epoch 234/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.9401 - mae: 0.7124\n",
            "Epoch 235/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 1.0356 - mae: 0.7338\n",
            "Epoch 236/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.9145 - mae: 0.7093\n",
            "Epoch 237/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.7674 - mae: 0.6201\n",
            "Epoch 238/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.8388 - mae: 0.6510\n",
            "Epoch 239/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.1912 - mae: 0.7498\n",
            "Epoch 240/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.9031 - mae: 0.6748\n",
            "Epoch 241/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.1629 - mae: 0.7393\n",
            "Epoch 242/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.1870 - mae: 0.8064\n",
            "Epoch 243/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.2792 - mae: 0.7710\n",
            "Epoch 244/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.0617 - mae: 0.6944\n",
            "Epoch 245/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.9400 - mae: 0.6635\n",
            "Epoch 246/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.2282 - mae: 0.7874\n",
            "Epoch 247/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.8575 - mae: 0.6547\n",
            "Epoch 248/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.8777 - mae: 0.6594\n",
            "Epoch 249/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.8860 - mae: 0.6923\n",
            "Epoch 250/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.9570 - mae: 0.6923\n",
            "Epoch 251/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.7362 - mae: 0.6292\n",
            "Epoch 252/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.6390 - mae: 0.5698\n",
            "Epoch 253/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.8703 - mae: 0.6565\n",
            "Epoch 254/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.7946 - mae: 0.6446\n",
            "Epoch 255/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.2223 - mae: 0.7634\n",
            "Epoch 256/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.9069 - mae: 0.6841\n",
            "Epoch 257/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.8886 - mae: 0.6774\n",
            "Epoch 258/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.8020 - mae: 0.6131\n",
            "Epoch 259/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.7569 - mae: 0.6465\n",
            "Epoch 260/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.6341 - mae: 0.5730\n",
            "Epoch 261/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.5595 - mae: 0.5377\n",
            "Epoch 262/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.8214 - mae: 0.6732\n",
            "Epoch 263/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 1.0404 - mae: 0.7309\n",
            "Epoch 264/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.0497 - mae: 0.7204\n",
            "Epoch 265/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.7520 - mae: 0.6406\n",
            "Epoch 266/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.9414 - mae: 0.6775\n",
            "Epoch 267/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.7011 - mae: 0.5958\n",
            "Epoch 268/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.6755 - mae: 0.5961\n",
            "Epoch 269/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.6282 - mae: 0.5678\n",
            "Epoch 270/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.7883 - mae: 0.6045\n",
            "Epoch 271/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.8396 - mae: 0.6213\n",
            "Epoch 272/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.0412 - mae: 0.7208\n",
            "Epoch 273/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.7825 - mae: 0.6392\n",
            "Epoch 274/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.6959 - mae: 0.5808\n",
            "Epoch 275/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.7918 - mae: 0.6128\n",
            "Epoch 276/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.9480 - mae: 0.6664\n",
            "Epoch 277/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.6419 - mae: 0.5716\n",
            "Epoch 278/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.8177 - mae: 0.6430\n",
            "Epoch 279/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.8371 - mae: 0.6613\n",
            "Epoch 280/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.7165 - mae: 0.5756\n",
            "Epoch 281/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.9501 - mae: 0.6668\n",
            "Epoch 282/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.1628 - mae: 0.7800\n",
            "Epoch 283/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.7665 - mae: 0.6252\n",
            "Epoch 284/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.6318 - mae: 0.5625\n",
            "Epoch 285/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.6444 - mae: 0.5544\n",
            "Epoch 286/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.6576 - mae: 0.5594\n",
            "Epoch 287/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.7388 - mae: 0.6252\n",
            "Epoch 288/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.8894 - mae: 0.6775\n",
            "Epoch 289/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.7840 - mae: 0.6377\n",
            "Epoch 290/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.7216 - mae: 0.6266\n",
            "Epoch 291/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.7981 - mae: 0.6525\n",
            "Epoch 292/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.7544 - mae: 0.5615\n",
            "Epoch 293/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.8561 - mae: 0.6740\n",
            "Epoch 294/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.9275 - mae: 0.6767\n",
            "Epoch 295/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.9487 - mae: 0.6865\n",
            "Epoch 296/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.7049 - mae: 0.6064\n",
            "Epoch 297/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.7830 - mae: 0.6230\n",
            "Epoch 298/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.7759 - mae: 0.6025\n",
            "Epoch 299/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.7459 - mae: 0.6258\n",
            "Epoch 300/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.3895 - mae: 0.8219\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 12.5677 - mae: 2.4378\n"
          ]
        }
      ],
      "source": [
        "model = build_model()\n",
        "# Train it on the entirety of the data.\n",
        "model.fit(train_data, train_targets, epochs=300, batch_size=2, verbose=1)\n",
        "test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H49K6EoUgg-b",
        "outputId": "87c172e5-7df7-4a1c-e44b-8735c1f5f895"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "202/202 [==============================] - 2s 3ms/step - loss: 207.1656 - mae: 10.2267\n",
            "Epoch 2/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 24.4332 - mae: 3.5358\n",
            "Epoch 3/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 16.8046 - mae: 2.8686\n",
            "Epoch 4/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 12.7748 - mae: 2.5645\n",
            "Epoch 5/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 11.5592 - mae: 2.4444\n",
            "Epoch 6/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 10.8105 - mae: 2.3311\n",
            "Epoch 7/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 11.1148 - mae: 2.4246\n",
            "Epoch 8/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 10.0274 - mae: 2.3054\n",
            "Epoch 9/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 9.0549 - mae: 2.2348\n",
            "Epoch 10/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 8.6634 - mae: 2.1273\n",
            "Epoch 11/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 8.2501 - mae: 2.0718\n",
            "Epoch 12/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 8.2828 - mae: 2.0615\n",
            "Epoch 13/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 7.5947 - mae: 2.0787\n",
            "Epoch 14/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 7.6665 - mae: 1.9491\n",
            "Epoch 15/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 6.8783 - mae: 2.0365\n",
            "Epoch 16/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 7.1179 - mae: 1.9399\n",
            "Epoch 17/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 7.0619 - mae: 1.8864\n",
            "Epoch 18/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 6.5525 - mae: 1.8921\n",
            "Epoch 19/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 6.2005 - mae: 1.8241\n",
            "Epoch 20/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 5.8890 - mae: 1.8126\n",
            "Epoch 21/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 5.8710 - mae: 1.7917\n",
            "Epoch 22/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 5.9299 - mae: 1.7862\n",
            "Epoch 23/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 5.3413 - mae: 1.7201\n",
            "Epoch 24/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 5.7207 - mae: 1.7219\n",
            "Epoch 25/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 5.0983 - mae: 1.6338\n",
            "Epoch 26/300\n",
            "202/202 [==============================] - 1s 4ms/step - loss: 4.6553 - mae: 1.6106\n",
            "Epoch 27/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 5.1017 - mae: 1.6971\n",
            "Epoch 28/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 5.0354 - mae: 1.6819\n",
            "Epoch 29/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 4.7768 - mae: 1.6516\n",
            "Epoch 30/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 4.4183 - mae: 1.5896\n",
            "Epoch 31/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 4.8524 - mae: 1.6249\n",
            "Epoch 32/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 4.4909 - mae: 1.5666\n",
            "Epoch 33/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 4.5701 - mae: 1.5965\n",
            "Epoch 34/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 5.0202 - mae: 1.6757\n",
            "Epoch 35/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 4.5336 - mae: 1.6220\n",
            "Epoch 36/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 4.0293 - mae: 1.5273\n",
            "Epoch 37/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 3.8042 - mae: 1.4732\n",
            "Epoch 38/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 3.6843 - mae: 1.4196\n",
            "Epoch 39/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 3.9510 - mae: 1.4885\n",
            "Epoch 40/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 4.1487 - mae: 1.5167\n",
            "Epoch 41/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 3.5184 - mae: 1.4163\n",
            "Epoch 42/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 3.7751 - mae: 1.4531\n",
            "Epoch 43/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 4.2167 - mae: 1.5386\n",
            "Epoch 44/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 3.7608 - mae: 1.4598\n",
            "Epoch 45/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 3.6253 - mae: 1.4353\n",
            "Epoch 46/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 3.4085 - mae: 1.4038\n",
            "Epoch 47/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 3.1987 - mae: 1.3716\n",
            "Epoch 48/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 4.8373 - mae: 1.5923\n",
            "Epoch 49/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 3.5539 - mae: 1.4027\n",
            "Epoch 50/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 3.4093 - mae: 1.3528\n",
            "Epoch 51/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 3.2073 - mae: 1.3258\n",
            "Epoch 52/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.9605 - mae: 1.2847\n",
            "Epoch 53/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 3.2302 - mae: 1.3381\n",
            "Epoch 54/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 3.2708 - mae: 1.3402\n",
            "Epoch 55/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 2.5968 - mae: 1.2265\n",
            "Epoch 56/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 2.8020 - mae: 1.2229\n",
            "Epoch 57/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 3.3227 - mae: 1.3863\n",
            "Epoch 58/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 3.8369 - mae: 1.4311\n",
            "Epoch 59/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 3.0201 - mae: 1.3119\n",
            "Epoch 60/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.7719 - mae: 1.2454\n",
            "Epoch 61/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 3.6908 - mae: 1.3975\n",
            "Epoch 62/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.7856 - mae: 1.2588\n",
            "Epoch 63/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.9196 - mae: 1.2608\n",
            "Epoch 64/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.5170 - mae: 1.2048\n",
            "Epoch 65/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.8742 - mae: 1.2935\n",
            "Epoch 66/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.9472 - mae: 1.2480\n",
            "Epoch 67/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.4958 - mae: 1.1869\n",
            "Epoch 68/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.4062 - mae: 1.1617\n",
            "Epoch 69/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.7131 - mae: 1.2258\n",
            "Epoch 70/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.2706 - mae: 1.1258\n",
            "Epoch 71/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 3.1288 - mae: 1.3007\n",
            "Epoch 72/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 3.4901 - mae: 1.3402\n",
            "Epoch 73/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.7689 - mae: 1.2388\n",
            "Epoch 74/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.3382 - mae: 1.1223\n",
            "Epoch 75/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.6819 - mae: 1.2146\n",
            "Epoch 76/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.4025 - mae: 1.1524\n",
            "Epoch 77/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.7274 - mae: 1.2054\n",
            "Epoch 78/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.6399 - mae: 1.2280\n",
            "Epoch 79/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.2356 - mae: 1.1588\n",
            "Epoch 80/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.4643 - mae: 1.1471\n",
            "Epoch 81/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.6335 - mae: 1.2243\n",
            "Epoch 82/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.7419 - mae: 1.2389\n",
            "Epoch 83/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 2.3784 - mae: 1.1323\n",
            "Epoch 84/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 2.7393 - mae: 1.1892\n",
            "Epoch 85/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 2.3467 - mae: 1.0973\n",
            "Epoch 86/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 2.3116 - mae: 1.1690\n",
            "Epoch 87/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 2.5386 - mae: 1.1461\n",
            "Epoch 88/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 3.0780 - mae: 1.2427\n",
            "Epoch 89/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.7297 - mae: 0.9783\n",
            "Epoch 90/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.8809 - mae: 1.0329\n",
            "Epoch 91/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.9662 - mae: 1.0216\n",
            "Epoch 92/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.9247 - mae: 0.9951\n",
            "Epoch 93/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.3267 - mae: 1.1303\n",
            "Epoch 94/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.1060 - mae: 1.0563\n",
            "Epoch 95/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.6642 - mae: 1.1492\n",
            "Epoch 96/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.7528 - mae: 0.9860\n",
            "Epoch 97/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.0238 - mae: 1.0377\n",
            "Epoch 98/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.3940 - mae: 1.1239\n",
            "Epoch 99/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.9690 - mae: 0.9758\n",
            "Epoch 100/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.9590 - mae: 1.0378\n",
            "Epoch 101/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.0384 - mae: 1.0564\n",
            "Epoch 102/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.9137 - mae: 1.0034\n",
            "Epoch 103/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.7613 - mae: 0.9664\n",
            "Epoch 104/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.4694 - mae: 1.0966\n",
            "Epoch 105/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.8130 - mae: 0.9895\n",
            "Epoch 106/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.6074 - mae: 0.9583\n",
            "Epoch 107/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.9867 - mae: 0.9953\n",
            "Epoch 108/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.9068 - mae: 1.0328\n",
            "Epoch 109/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.0137 - mae: 1.0208\n",
            "Epoch 110/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.0576 - mae: 1.0059\n",
            "Epoch 111/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.1082 - mae: 1.0738\n",
            "Epoch 112/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 1.8692 - mae: 0.9966\n",
            "Epoch 113/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 2.2220 - mae: 1.0861\n",
            "Epoch 114/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 1.9284 - mae: 1.0152\n",
            "Epoch 115/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 1.9024 - mae: 0.9730\n",
            "Epoch 116/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 1.3964 - mae: 0.8405\n",
            "Epoch 117/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.5873 - mae: 0.9260\n",
            "Epoch 118/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.5801 - mae: 0.9483\n",
            "Epoch 119/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.5014 - mae: 0.8726\n",
            "Epoch 120/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.3787 - mae: 0.8609\n",
            "Epoch 121/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.8272 - mae: 0.9945\n",
            "Epoch 122/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.7023 - mae: 0.9423\n",
            "Epoch 123/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.5854 - mae: 0.9198\n",
            "Epoch 124/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.5609 - mae: 0.9230\n",
            "Epoch 125/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.4863 - mae: 0.8597\n",
            "Epoch 126/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.6329 - mae: 1.0819\n",
            "Epoch 127/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.7919 - mae: 0.9359\n",
            "Epoch 128/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.6727 - mae: 0.9259\n",
            "Epoch 129/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.3678 - mae: 0.8736\n",
            "Epoch 130/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.4385 - mae: 0.8964\n",
            "Epoch 131/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.6150 - mae: 0.9381\n",
            "Epoch 132/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.3310 - mae: 0.8286\n",
            "Epoch 133/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.7864 - mae: 0.9890\n",
            "Epoch 134/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.2750 - mae: 0.8020\n",
            "Epoch 135/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.5947 - mae: 0.9340\n",
            "Epoch 136/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.4563 - mae: 0.8745\n",
            "Epoch 137/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.5158 - mae: 0.8946\n",
            "Epoch 138/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.7571 - mae: 0.9561\n",
            "Epoch 139/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.8128 - mae: 0.9846\n",
            "Epoch 140/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 1.9920 - mae: 1.0182\n",
            "Epoch 141/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 1.6058 - mae: 0.9175\n",
            "Epoch 142/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 1.4942 - mae: 0.8948\n",
            "Epoch 143/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 1.3294 - mae: 0.8464\n",
            "Epoch 144/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 1.4500 - mae: 0.8830\n",
            "Epoch 145/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.3545 - mae: 0.8880\n",
            "Epoch 146/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.2088 - mae: 0.7848\n",
            "Epoch 147/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.3146 - mae: 0.8337\n",
            "Epoch 148/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.5747 - mae: 0.9136\n",
            "Epoch 149/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.7659 - mae: 0.9635\n",
            "Epoch 150/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.6754 - mae: 0.9420\n",
            "Epoch 151/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.7069 - mae: 0.9461\n",
            "Epoch 152/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.2359 - mae: 0.8280\n",
            "Epoch 153/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.1212 - mae: 0.7882\n",
            "Epoch 154/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.3053 - mae: 0.8059\n",
            "Epoch 155/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.6365 - mae: 0.9429\n",
            "Epoch 156/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.1989 - mae: 1.0779\n",
            "Epoch 157/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.8763 - mae: 0.9846\n",
            "Epoch 158/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.3603 - mae: 0.8364\n",
            "Epoch 159/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.4378 - mae: 0.8664\n",
            "Epoch 160/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.3210 - mae: 0.8127\n",
            "Epoch 161/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.1055 - mae: 0.7397\n",
            "Epoch 162/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.2289 - mae: 0.7964\n",
            "Epoch 163/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.3868 - mae: 0.8846\n",
            "Epoch 164/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.5110 - mae: 0.9194\n",
            "Epoch 165/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.2093 - mae: 0.8030\n",
            "Epoch 166/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.3506 - mae: 0.8406\n",
            "Epoch 167/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.1420 - mae: 1.0272\n",
            "Epoch 168/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 1.2749 - mae: 0.8168\n",
            "Epoch 169/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 1.4586 - mae: 0.8724\n",
            "Epoch 170/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 1.0287 - mae: 0.7336\n",
            "Epoch 171/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 1.3868 - mae: 0.8726\n",
            "Epoch 172/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 2.1487 - mae: 1.0765\n",
            "Epoch 173/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.8551 - mae: 0.9847\n",
            "Epoch 174/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.1948 - mae: 0.7482\n",
            "Epoch 175/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.2786 - mae: 0.8331\n",
            "Epoch 176/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.0447 - mae: 0.7323\n",
            "Epoch 177/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.0432 - mae: 0.7343\n",
            "Epoch 178/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.2662 - mae: 0.8073\n",
            "Epoch 179/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.3178 - mae: 0.8681\n",
            "Epoch 180/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.1514 - mae: 0.7636\n",
            "Epoch 181/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.2100 - mae: 0.7994\n",
            "Epoch 182/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.2052 - mae: 0.7912\n",
            "Epoch 183/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.2398 - mae: 0.7746\n",
            "Epoch 184/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.2652 - mae: 0.8337\n",
            "Epoch 185/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.9272 - mae: 0.6893\n",
            "Epoch 186/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.2302 - mae: 0.7941\n",
            "Epoch 187/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.5212 - mae: 0.9209\n",
            "Epoch 188/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.4153 - mae: 0.8527\n",
            "Epoch 189/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.8567 - mae: 0.6724\n",
            "Epoch 190/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.9655 - mae: 0.7132\n",
            "Epoch 191/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.0226 - mae: 0.7602\n",
            "Epoch 192/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 2.1233 - mae: 1.0632\n",
            "Epoch 193/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.0506 - mae: 0.7595\n",
            "Epoch 194/300\n",
            "202/202 [==============================] - 1s 2ms/step - loss: 1.4284 - mae: 0.8291\n",
            "Epoch 195/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 1.1322 - mae: 0.7627\n",
            "Epoch 196/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 1.2247 - mae: 0.7816\n",
            "Epoch 197/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 1.0216 - mae: 0.7470\n",
            "Epoch 198/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.8422 - mae: 0.6421\n",
            "Epoch 199/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 1.1756 - mae: 0.7789\n",
            "Epoch 200/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.2142 - mae: 0.8362\n",
            "Epoch 201/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.1403 - mae: 0.7421\n",
            "Epoch 202/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.9773 - mae: 0.7427\n",
            "Epoch 203/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.4556 - mae: 0.8574\n",
            "Epoch 204/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.4349 - mae: 0.8283\n",
            "Epoch 205/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.2686 - mae: 0.8263\n",
            "Epoch 206/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.1155 - mae: 0.7542\n",
            "Epoch 207/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.8786 - mae: 0.6783\n",
            "Epoch 208/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.9457 - mae: 0.6920\n",
            "Epoch 209/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.9356 - mae: 0.7371\n",
            "Epoch 210/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.0031 - mae: 0.7021\n",
            "Epoch 211/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.3315 - mae: 0.8495\n",
            "Epoch 212/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.9460 - mae: 0.7263\n",
            "Epoch 213/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.9527 - mae: 0.7067\n",
            "Epoch 214/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.0448 - mae: 0.7543\n",
            "Epoch 215/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.2013 - mae: 0.7592\n",
            "Epoch 216/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.4005 - mae: 0.8218\n",
            "Epoch 217/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.9199 - mae: 0.6809\n",
            "Epoch 218/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.7622 - mae: 0.6399\n",
            "Epoch 219/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.2258 - mae: 0.7811\n",
            "Epoch 220/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.2541 - mae: 0.8024\n",
            "Epoch 221/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.8421 - mae: 0.6674\n",
            "Epoch 222/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.7887 - mae: 0.6437\n",
            "Epoch 223/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.9694 - mae: 0.7339\n",
            "Epoch 224/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.9123 - mae: 0.6849\n",
            "Epoch 225/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.9296 - mae: 0.7107\n",
            "Epoch 226/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 1.0772 - mae: 0.7325\n",
            "Epoch 227/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.3865 - mae: 0.8537\n",
            "Epoch 228/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.9710 - mae: 0.7074\n",
            "Epoch 229/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.8841 - mae: 0.6828\n",
            "Epoch 230/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.8872 - mae: 0.6742\n",
            "Epoch 231/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.3842 - mae: 0.8381\n",
            "Epoch 232/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.9108 - mae: 0.7157\n",
            "Epoch 233/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.8574 - mae: 0.6306\n",
            "Epoch 234/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.9478 - mae: 0.6614\n",
            "Epoch 235/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.0555 - mae: 0.7299\n",
            "Epoch 236/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.0346 - mae: 0.7312\n",
            "Epoch 237/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.1675 - mae: 0.7333\n",
            "Epoch 238/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.1205 - mae: 0.7727\n",
            "Epoch 239/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.5211 - mae: 0.8896\n",
            "Epoch 240/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.8286 - mae: 0.6461\n",
            "Epoch 241/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.0893 - mae: 0.7206\n",
            "Epoch 242/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.3962 - mae: 0.8143\n",
            "Epoch 243/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.0273 - mae: 0.7007\n",
            "Epoch 244/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.7418 - mae: 0.6317\n",
            "Epoch 245/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.8351 - mae: 0.6775\n",
            "Epoch 246/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.6952 - mae: 0.6096\n",
            "Epoch 247/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.7116 - mae: 0.6030\n",
            "Epoch 248/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.1363 - mae: 0.7235\n",
            "Epoch 249/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.0114 - mae: 0.6984\n",
            "Epoch 250/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.7923 - mae: 0.6607\n",
            "Epoch 251/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.8366 - mae: 0.6483\n",
            "Epoch 252/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 1.1226 - mae: 0.7530\n",
            "Epoch 253/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 1.3833 - mae: 0.8510\n",
            "Epoch 254/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.8360 - mae: 0.6495\n",
            "Epoch 255/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.6946 - mae: 0.5691\n",
            "Epoch 256/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.8196 - mae: 0.6466\n",
            "Epoch 257/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.9550 - mae: 0.6962\n",
            "Epoch 258/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.7389 - mae: 0.6150\n",
            "Epoch 259/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.7125 - mae: 0.6122\n",
            "Epoch 260/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.7254 - mae: 0.5892\n",
            "Epoch 261/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.3122 - mae: 0.7664\n",
            "Epoch 262/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.0572 - mae: 0.7335\n",
            "Epoch 263/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.9095 - mae: 0.6778\n",
            "Epoch 264/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.6640 - mae: 0.5786\n",
            "Epoch 265/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.7451 - mae: 0.6339\n",
            "Epoch 266/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.5861 - mae: 0.5559\n",
            "Epoch 267/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.7638 - mae: 0.6520\n",
            "Epoch 268/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.8139 - mae: 0.6474\n",
            "Epoch 269/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.8987 - mae: 0.6940\n",
            "Epoch 270/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.2528 - mae: 0.8487\n",
            "Epoch 271/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.7539 - mae: 0.6230\n",
            "Epoch 272/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.7373 - mae: 0.6319\n",
            "Epoch 273/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.9690 - mae: 0.6930\n",
            "Epoch 274/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.9883 - mae: 0.7356\n",
            "Epoch 275/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.8663 - mae: 0.6829\n",
            "Epoch 276/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.8075 - mae: 0.6706\n",
            "Epoch 277/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.7277 - mae: 0.5981\n",
            "Epoch 278/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.9062 - mae: 0.6785\n",
            "Epoch 279/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.7066 - mae: 0.5881\n",
            "Epoch 280/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.7533 - mae: 0.6289\n",
            "Epoch 281/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.6326 - mae: 0.5719\n",
            "Epoch 282/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.6437 - mae: 0.5779\n",
            "Epoch 283/300\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.7359 - mae: 0.6007\n",
            "Epoch 284/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.6889 - mae: 0.6155\n",
            "Epoch 285/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.6992 - mae: 0.6333\n",
            "Epoch 286/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.9880 - mae: 0.7061\n",
            "Epoch 287/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.6963 - mae: 0.6023\n",
            "Epoch 288/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.6700 - mae: 0.5935\n",
            "Epoch 289/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.7251 - mae: 0.6368\n",
            "Epoch 290/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.2175 - mae: 0.7571\n",
            "Epoch 291/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.0303 - mae: 0.7012\n",
            "Epoch 292/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.6014 - mae: 0.5526\n",
            "Epoch 293/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.6051 - mae: 0.5642\n",
            "Epoch 294/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.6454 - mae: 0.5923\n",
            "Epoch 295/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.8137 - mae: 0.6185\n",
            "Epoch 296/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 1.1301 - mae: 0.7625\n",
            "Epoch 297/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.5549 - mae: 0.5619\n",
            "Epoch 298/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.5968 - mae: 0.5536\n",
            "Epoch 299/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.6657 - mae: 0.6156\n",
            "Epoch 300/300\n",
            "202/202 [==============================] - 0s 2ms/step - loss: 0.7596 - mae: 0.6496\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f86402a2950>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "mean = train_data.mean(axis=0)\n",
        "train_data -= mean\n",
        "std = train_data.std(axis=0)\n",
        "train_data /= std\n",
        "\n",
        "best_model = build_model()\n",
        "best_model.fit(train_data, train_targets, epochs=300, batch_size=2, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXlNUJ0n49tb",
        "outputId": "7db6e6a6-cac6-4363-d74f-814a7ac2117b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 3ms/step\n"
          ]
        }
      ],
      "source": [
        "test_data -= mean\n",
        "test_data /= std\n",
        "\n",
        "pred = best_model.predict(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "syGzIj0MjtPr",
        "outputId": "4c7ec223-90f2-40f3-a84b-f2f69439c1b0"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.hist(np.sort(train_targets), bins=30)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "FRdANA1OjgnC",
        "outputId": "14999e6d-0e6a-46f9-d453-eea9bdc55d6a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.hist(np.sort(pred), bins=30)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary:\n",
        "\n",
        "In this practical project I chose the Boston house dataset.\n",
        "I tried different options to improve the model. I tried several optimizers: Adam and RMSprop with default laerning rate and learning rate = 0.0001. I tried different batch sizes: 1/2/3/6. I also added a few Dense Layers.\n",
        "\n",
        "The lowest loss and mae we I managed to achieve are: loss: 0.7596, mae:  0.6496."
      ],
      "metadata": {
        "id": "fuRBK8Q_mpuv"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNPPito6Fj46hg2V4TLIq+a",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}